# Rob Monroe - Individual Assessment Report

## Employee Information
- **Name**: Rob Monroe
- **Department**: Product-Management
- **Level**: Staff Practitioner
- **Team**: Enablement
- **Project**: Overhead
- **Assessment Period**: 2025 EOY
- **Tier Assignment**: A (Solid Performer)

---

## Overall Scores

- **Peers Average**: 4.60 (based on 50 ratings)
- **Response Rate**: 5/5 peer reviewers (100%)
- **Self Average**: 4.09
- **Delta (Self - Peers)**: -0.51 üü¢ (Humble)
- **Delta (Self - Level)**: -0.27 üü¢ (Humble) (vs Level Average 4.36)
- **Delta (Self - Team)**: -0.14 üü¢ (Humble) (vs Team Average 4.23)
- **Delta (Self - Department)**: -0.08 üü° (Well-calibrated) (vs Department Average 4.17)
- **Delta (Self - Project)**: -0.04 üü° (Well-calibrated) (vs Project Average 4.13)

---

## Accomplishments Review (Self-Assessment Question 13)

### Synthesized Summary

*[AI synthesis needed - invoke rise8-assessment-reviewer agent with accomplishments text]*

<details>
<summary>View Raw Accomplishments Text</summary>

**1) Outcome in Prod (OIP) Quality (Achieved)**
- **Context**: at the end of 2024, outcomes in prod submissions had the following quality performance stats that showed Delivery teams were not working in outcome-oriented ways:
   - **~80%** had redundant outcome results in their impact results
   - **76%** needed revisioning
   - **42%** required multiple revision rounds
   - **35%** had quantitative metrics 
- **SMART Goal**: To improve these quality stats, by November 2025, **100% of delivery teams who have passed their inception milestone will demonstrate outcome-oriented ways of working**, defined as each team having the following:
   - Adoption of value stream mapping (VSM) and impact mapping artifacts
   - A clearly defined and measurable one mission metric that matters
   - An outcome-oriented roadmap (OOR) with outcome in prod experiments defined for at least 12 months
   - A commitment to including qualitative and quantitative metrics
- **Activities and Outputs:** I partnered with peers and leadership to introduce the following
   - Standardized and launched VSMs, Impact Maps and OOR templates and RiseU resources
   - Provided training and feedback sessions to improve resources
   - Introduced definition-of-done quality checks
   - Produced RiseU content on metrics and experiment methods
   - Launched Gemini Gem to assist in designing and refining outcome in prod hypothesis experiments
- **Results**
   - **100%** of delivery teams have adopted our standards
   - **100%** of teams have at least 12 month OOR
   - Redundant outcome<>impact submissions dropped quarter over quarter from **80%** (2024) -> **76%** (1Q25) -> **62%** (2Q25) -> **40%** (3Q25) -> **~10%** (4Q25)
   - **78%** of submissions are accepted on their first attempt
   - **~81%** of submissions use both qualitative and quantitative metrics
   - Randomly selected Riser PMs who received the Gemini Gem were asked if anything changed in their approach with their teams after within 3 weeks
      - *"Before I was kind of boiling the ocean. With the recommended updates [from the Gem] I've broken my experiments down into smaller chunks that proceed in logical progression."*
      - *"I really appreciated how it guided me on a path to building my roadmap."*
      - *"I appreciate the prioritize recommendations that it gave so I know where to start with my personal improvement."* 
      - *"The Gem kept digging into my answers and forced me to think really hard on what I can actually measure and segment well, as well as how to design smaller tests where appropriate."*








**2) Hire & retain A-players, respectfully move B-players faster (Mostly Achieved)**
- **SMART Goal:** By November, 2025, I will strengthen our Product talent and standards in order to improve customer satisfaction with Rise8 delivery team performance:
   - Achieving **‚â•97% retention** of **A-players**.
   - Ensuring that **100% of new hires** into Product roles are assessed as **A-players at hire**.
   - Reducing B-players within 30 days of confirming their player status, by giving each B-player either:
      - a PIP with clear get to A-player status and decision date.
      - or a respectful, timely transition out.
   - To validate this goal, I will partner with HR, as well as Sr and above PMs to
      - maintain a talent calibration roster sheet
      - track an A-player retention KPI
      - introduce formal PIP plans
      - adjust our skills assessment interview process
- **Results:** 
   - PM skill assessment interview adjustments
      - **Candidate rejection rate increased from 22% to 90%**; increased confidence with contingent offers
      - **Eliminated salary compensation negotiation** because of clear performance feedback
      - Normalized **average salary band penetration from 88% to 65%**
   - **95% of A-players were retained; avoided <90% result**
      - We unfortunately lost Cody Ray in 3Q25 siting lack of career path clarity and didn't feel valued based on engagement placement
      - Art Tovar confirmed he accepted an offer at USAA, but then turned it down after I spoke with him - learning from our experience with Cody Ray
         - *The mission of Rise8 to make a real difference in the world is why I want to be here*
         - *Im really appreciative of how you (rob) gave me chances to prove I could make the journey*
         - *If i were to go somewhere else I think i might become bored - there's still so much to always learn and grow here at Rise8*
         - *I feel so relieved to finally make this decision*
   - 100% of confirmed B-players were removed, **but took longer than 30 days to accomplish**
   - **>50% of Delivery Lead positions are held by PMs**.








**3) PM‚ÄìDesign relationships & skillsets (Partially Achieved)**
- **SMART Goal**: Materially improve PM‚ÄìDesign collaboration and skills in 2025 by 
1. Running at least **6 joint PM‚ÄìDesign practice sessions or workshops** (e.g., discovery, hypothesis writing, outcome mapping, experiment design).
2. Ensuring that **100% of PM‚ÄìDesigner pairs** on Delivery accounts **co-create discovery artifacts and outcome-based experiments** using resources I publish and teach.
3. **Improving average PM‚ÄìDesign partnership satisfaction scores by at least 1 point on a 5-point scale**, using a lightweight **quarterly pulse survey** compared to a **Q1 2025 baseline**. 
- **Results:** 
   - Only pulled off **3 join PM-Design workshops**, including the off-site in Austin (this was IC-led; I only coached and supported when asked)
      - Off-site was on budget with no additional finance support asks
   - **100% of PM‚ÄìDesigner pairs** on Delivery accounts **did co-create** discovery artifacts and outcome-based experiments **using resources I published or taught**.
   - **I did not formally measure Designer<>PM satisfaction scores**
      - PM and Designer feedback from the off-site concluded the opportunity to learn from Dale Carnegie and Karen Martin were invaluable, and well worth the pro dev money spent
      - ~10% of Design/PM practitioners still question if VSMs are the right tool for Rise8

</details>

---

## Per-Question Breakdown

### Question 1: Be Bold

**Basic Scores:**
- **Peers Average**: 4.80 (based on 5 ratings)
- **Response Rate**: 5/5 peer reviewers (100%)
- **Self Score**: 4.0
- **Median Score**: 5.00

**Self-Awareness Deltas:**
- **Delta (Self - Peers)**: -0.80 üü¢ (Humble)
- **Delta (Self - Level)**: -0.28 üü¢ (Humble)
- **Delta (Self - Team)**: -0.07 üü° (Well-calibrated)
- **Delta (Self - Department)**: -0.20 üü¢ (Humble)
- **Delta (Self - Project)**: -0.07 üü° (Well-calibrated)

**Performance Comparisons (Peer Avg vs Groups):**
- **vs Team Average**: +0.73 (Team avg: 4.07) - Above team
- **vs Project Average**: +0.73 (Project avg: 4.07) - Above project
- **vs Department Average**: +0.60 (Department avg: 4.20) - Above department
- **vs Company Average**: +0.77 (Company avg: 4.03) - Above company

**Statistical Analysis:**
- **Standard Deviation**: 0.40 (Moderate agreement)
- **Percentile Rank**: 96.8th percentile
- **Score Range**: 4.0 - 5.0 (spread: 1.0)

**Interpretation:**
- Scores in the **96th percentile** on Be Bold company-wide (top 3%)
- Peer average (4.80) is **+0.77 above company average**
- **Moderate agreement** among reviewers (SD: 0.40)
- Score range (4.0-5.0) shows reasonable consistency in reviewer perceptions

### Question 2: Do The Right Thing

**Basic Scores:**
- **Peers Average**: 4.60 (based on 5 ratings)
- **Response Rate**: 5/5 peer reviewers (100%)
- **Self Score**: 5.0
- **Median Score**: 5.00

**Self-Awareness Deltas:**
- **Delta (Self - Peers)**: +0.40 üî¥ (Overconfident)
- **Delta (Self - Level)**: +0.52 üî¥ (Overconfident)
- **Delta (Self - Team)**: +0.72 üî¥ (Overconfident)
- **Delta (Self - Department)**: +0.69 üî¥ (Overconfident)
- **Delta (Self - Project)**: +0.68 üî¥ (Overconfident)

**Performance Comparisons (Peer Avg vs Groups):**
- **vs Team Average**: +0.32 (Team avg: 4.28) - Above team
- **vs Project Average**: +0.28 (Project avg: 4.32) - Above project
- **vs Department Average**: +0.29 (Department avg: 4.31) - Above department
- **vs Company Average**: +0.38 (Company avg: 4.22) - Above company

**Statistical Analysis:**
- **Standard Deviation**: 0.80 (Mixed opinions)
- **Percentile Rank**: 78.3th percentile
- **Score Range**: 3.0 - 5.0 (spread: 2.0)

**Interpretation:**
- Scores in the **78th percentile** on Do The Right Thing company-wide (top 22%)
- Peer average (4.60) is **+0.38 above company average**
- **Mixed opinions** among reviewers (SD: 0.80)
- Score range (3.0-5.0) shows notable variability in reviewer perceptions

### Question 3: Do What Works

**Basic Scores:**
- **Peers Average**: 4.60 (based on 5 ratings)
- **Response Rate**: 5/5 peer reviewers (100%)
- **Self Score**: 3.0
- **Median Score**: 5.00

**Self-Awareness Deltas:**
- **Delta (Self - Peers)**: -1.60 üü¢ (Humble)
- **Delta (Self - Level)**: -1.25 üü¢ (Humble)
- **Delta (Self - Team)**: -1.08 üü¢ (Humble)
- **Delta (Self - Department)**: -1.03 üü¢ (Humble)
- **Delta (Self - Project)**: -1.00 üü¢ (Humble)

**Performance Comparisons (Peer Avg vs Groups):**
- **vs Team Average**: +0.52 (Team avg: 4.08) - Above team
- **vs Project Average**: +0.60 (Project avg: 4.00) - Above project
- **vs Department Average**: +0.57 (Department avg: 4.03) - Above department
- **vs Company Average**: +0.63 (Company avg: 3.97) - Above company

**Statistical Analysis:**
- **Standard Deviation**: 0.80 (Mixed opinions)
- **Percentile Rank**: 92.3th percentile
- **Score Range**: 3.0 - 5.0 (spread: 2.0)

**Interpretation:**
- Scores in the **92th percentile** on Do What Works company-wide (top 8%)
- Peer average (4.60) is **+0.63 above company average**
- **Mixed opinions** among reviewers (SD: 0.80)
- Score range (3.0-5.0) shows notable variability in reviewer perceptions

### Question 4: Do What is Required

**Basic Scores:**
- **Peers Average**: 4.20 (based on 5 ratings)
- **Response Rate**: 5/5 peer reviewers (100%)
- **Self Score**: 4.0
- **Median Score**: 4.00

**Self-Awareness Deltas:**
- **Delta (Self - Peers)**: -0.20 üü¢ (Humble)
- **Delta (Self - Level)**: -0.28 üü¢ (Humble)
- **Delta (Self - Team)**: -0.09 üü° (Well-calibrated)
- **Delta (Self - Department)**: -0.08 üü° (Well-calibrated)
- **Delta (Self - Project)**: -0.15 üü¢ (Humble)

**Performance Comparisons (Peer Avg vs Groups):**
- **vs Team Average**: +0.11 (Team avg: 4.09) - Above team
- **vs Project Average**: +0.05 (Project avg: 4.15) - Above project
- **vs Department Average**: +0.12 (Department avg: 4.08) - Above department
- **vs Company Average**: +0.10 (Company avg: 4.10) - Above company

**Statistical Analysis:**
- **Standard Deviation**: 0.75 (Mixed opinions)
- **Percentile Rank**: 57.4th percentile
- **Score Range**: 3.0 - 5.0 (spread: 2.0)

**Interpretation:**
- Scores in the **57th percentile** on Do What is Required company-wide (top 43%)
- Peer average (4.20) is **+0.12 above department average**
- **Mixed opinions** among reviewers (SD: 0.75)
- Score range (3.0-5.0) shows notable variability in reviewer perceptions

### Question 5: Always Be Kind

**Basic Scores:**
- **Peers Average**: 3.80 (based on 5 ratings)
- **Response Rate**: 5/5 peer reviewers (100%)
- **Self Score**: 4.0
- **Median Score**: 4.00

**Self-Awareness Deltas:**
- **Delta (Self - Peers)**: +0.20 üî¥ (Overconfident)
- **Delta (Self - Level)**: -0.32 üü¢ (Humble)
- **Delta (Self - Team)**: -0.11 üü¢ (Humble)
- **Delta (Self - Department)**: -0.20 üü¢ (Humble)
- **Delta (Self - Project)**: -0.23 üü¢ (Humble)

**Performance Comparisons (Peer Avg vs Groups):**
- **vs Team Average**: -0.31 (Team avg: 4.11) - Below team
- **vs Project Average**: -0.43 (Project avg: 4.23) - Below project
- **vs Department Average**: -0.40 (Department avg: 4.20) - Below department
- **vs Company Average**: -0.34 (Company avg: 4.14) - Below company

**Statistical Analysis:**
- **Standard Deviation**: 0.75 (Mixed opinions)
- **Percentile Rank**: 22.7th percentile
- **Score Range**: 3.0 - 5.0 (spread: 2.0)

**Interpretation:**
- Scores in the **22th percentile** on Always Be Kind company-wide (top 77%)
- Peer average (3.80) is **-0.43 below project average**
- **Mixed opinions** among reviewers (SD: 0.75)
- Score range (3.0-5.0) shows notable variability in reviewer perceptions

### Question 6: Keep it Real

**Basic Scores:**
- **Peers Average**: 4.60 (based on 5 ratings)
- **Response Rate**: 5/5 peer reviewers (100%)
- **Self Score**: 4.0
- **Median Score**: 5.00

**Self-Awareness Deltas:**
- **Delta (Self - Peers)**: -0.60 üü¢ (Humble)
- **Delta (Self - Level)**: -0.34 üü¢ (Humble)
- **Delta (Self - Team)**: -0.21 üü¢ (Humble)
- **Delta (Self - Department)**: -0.25 üü¢ (Humble)
- **Delta (Self - Project)**: -0.20 üü¢ (Humble)

**Performance Comparisons (Peer Avg vs Groups):**
- **vs Team Average**: +0.39 (Team avg: 4.21) - Above team
- **vs Project Average**: +0.40 (Project avg: 4.20) - Above project
- **vs Department Average**: +0.35 (Department avg: 4.25) - Above department
- **vs Company Average**: +0.43 (Company avg: 4.17) - Above company

**Statistical Analysis:**
- **Standard Deviation**: 0.80 (Mixed opinions)
- **Percentile Rank**: 85.3th percentile
- **Score Range**: 3.0 - 5.0 (spread: 2.0)

**Interpretation:**
- Scores in the **85th percentile** on Keep it Real company-wide (top 15%)
- Peer average (4.60) is **+0.43 above company average**
- **Mixed opinions** among reviewers (SD: 0.80)
- Score range (3.0-5.0) shows notable variability in reviewer perceptions

### Question 7: Outcomes in Production

**Basic Scores:**
- **Peers Average**: 4.80 (based on 5 ratings)
- **Response Rate**: 5/5 peer reviewers (100%)
- **Self Score**: 5.0
- **Median Score**: 5.00

**Self-Awareness Deltas:**
- **Delta (Self - Peers)**: +0.20 üî¥ (Overconfident)
- **Delta (Self - Level)**: +0.85 üî¥ (Overconfident)
- **Delta (Self - Team)**: +0.84 üî¥ (Overconfident)
- **Delta (Self - Department)**: +0.95 üî¥ (Overconfident)
- **Delta (Self - Project)**: +1.00 üî¥ (Overconfident)

**Performance Comparisons (Peer Avg vs Groups):**
- **vs Team Average**: +0.64 (Team avg: 4.16) - Above team
- **vs Project Average**: +0.80 (Project avg: 4.00) - Above project
- **vs Department Average**: +0.75 (Department avg: 4.05) - Above department
- **vs Company Average**: +0.82 (Company avg: 3.98) - Above company

**Statistical Analysis:**
- **Standard Deviation**: 0.40 (Moderate agreement)
- **Percentile Rank**: 98.2th percentile
- **Score Range**: 4.0 - 5.0 (spread: 1.0)

**Interpretation:**
- Scores in the **98th percentile** on Outcomes in Production company-wide (top 2%)
- Peer average (4.80) is **+0.82 above company average**
- **Moderate agreement** among reviewers (SD: 0.40)
- Score range (4.0-5.0) shows reasonable consistency in reviewer perceptions

### Question 8: Grit

**Basic Scores:**
- **Peers Average**: 5.00 (based on 5 ratings)
- **Response Rate**: 5/5 peer reviewers (100%)
- **Self Score**: 4.0
- **Median Score**: 5.00

**Self-Awareness Deltas:**
- **Delta (Self - Peers)**: -1.00 üü¢ (Humble)
- **Delta (Self - Level)**: -0.38 üü¢ (Humble)
- **Delta (Self - Team)**: -0.25 üü¢ (Humble)
- **Delta (Self - Department)**: -0.20 üü¢ (Humble)
- **Delta (Self - Project)**: -0.27 üü¢ (Humble)

**Performance Comparisons (Peer Avg vs Groups):**
- **vs Team Average**: +0.75 (Team avg: 4.25) - Above team
- **vs Project Average**: +0.73 (Project avg: 4.27) - Above project
- **vs Department Average**: +0.80 (Department avg: 4.20) - Above department
- **vs Company Average**: +0.84 (Company avg: 4.16) - Above company

**Statistical Analysis:**
- **Standard Deviation**: 0.00 (High consensus)
- **Percentile Rank**: 97.9th percentile
- **Score Range**: 5.0 - 5.0 (spread: 0.0)

*Perfect consensus - all reviewers gave identical scores*

### Question 9: Growth Mindset

**Basic Scores:**
- **Peers Average**: 4.80 (based on 5 ratings)
- **Response Rate**: 5/5 peer reviewers (100%)
- **Self Score**: 4.0
- **Median Score**: 5.00

**Self-Awareness Deltas:**
- **Delta (Self - Peers)**: -0.80 üü¢ (Humble)
- **Delta (Self - Level)**: -0.38 üü¢ (Humble)
- **Delta (Self - Team)**: -0.33 üü¢ (Humble)
- **Delta (Self - Department)**: -0.17 üü¢ (Humble)
- **Delta (Self - Project)**: -0.24 üü¢ (Humble)

**Performance Comparisons (Peer Avg vs Groups):**
- **vs Team Average**: +0.47 (Team avg: 4.33) - Above team
- **vs Project Average**: +0.56 (Project avg: 4.24) - Above project
- **vs Department Average**: +0.63 (Department avg: 4.17) - Above department
- **vs Company Average**: +0.61 (Company avg: 4.19) - Above company

**Statistical Analysis:**
- **Standard Deviation**: 0.40 (Moderate agreement)
- **Percentile Rank**: 94.1th percentile
- **Score Range**: 4.0 - 5.0 (spread: 1.0)

**Interpretation:**
- Scores in the **94th percentile** on Growth Mindset company-wide (top 6%)
- Peer average (4.80) is **+0.63 above department average**
- **Moderate agreement** among reviewers (SD: 0.40)
- Score range (4.0-5.0) shows reasonable consistency in reviewer perceptions

### Question 10: No Unnecessary Rules

**Basic Scores:**
- **Peers Average**: 4.40 (based on 5 ratings)
- **Response Rate**: 5/5 peer reviewers (100%)
- **Self Score**: 3.0
- **Median Score**: 4.00

**Self-Awareness Deltas:**
- **Delta (Self - Peers)**: -1.40 üü¢ (Humble)
- **Delta (Self - Level)**: -1.36 üü¢ (Humble)
- **Delta (Self - Team)**: -1.28 üü¢ (Humble)
- **Delta (Self - Department)**: -1.22 üü¢ (Humble)
- **Delta (Self - Project)**: -1.16 üü¢ (Humble)

**Performance Comparisons (Peer Avg vs Groups):**
- **vs Team Average**: +0.12 (Team avg: 4.28) - Above team
- **vs Project Average**: +0.24 (Project avg: 4.16) - Above project
- **vs Department Average**: +0.18 (Department avg: 4.22) - Above department
- **vs Company Average**: +0.29 (Company avg: 4.11) - Above company

**Statistical Analysis:**
- **Standard Deviation**: 0.49 (Moderate agreement)
- **Percentile Rank**: 68.9th percentile
- **Score Range**: 4.0 - 5.0 (spread: 1.0)

**Interpretation:**
- Scores in the **68th percentile** on No Unnecessary Rules company-wide (top 31%)
- Peer average (4.40) is **+0.29 above company average**
- **Moderate agreement** among reviewers (SD: 0.49)
- Score range (4.0-5.0) shows reasonable consistency in reviewer perceptions

### Question 11: eNPS (Employee Net Promoter Score)

**Basic Scores:**
- **Peers Average**: 5.00 (based on 5 ratings)
- **Response Rate**: 5/5 peer reviewers (100%)
- **Self Score**: 5.0
- **Median Score**: 5.00

**Self-Awareness Deltas:**
- **Delta (Self - Peers)**: +0.00 üü° (Well-calibrated)
- **Delta (Self - Level)**: +0.17 üî¥ (Overconfident)
- **Delta (Self - Team)**: +0.25 üî¥ (Overconfident)
- **Delta (Self - Department)**: +0.30 üî¥ (Overconfident)
- **Delta (Self - Project)**: +0.36 üî¥ (Overconfident)

**Performance Comparisons (Peer Avg vs Groups):**
- **vs Team Average**: +0.25 (Team avg: 4.75) - Above team
- **vs Project Average**: +0.36 (Project avg: 4.64) - Above project
- **vs Department Average**: +0.30 (Department avg: 4.70) - Above department
- **vs Company Average**: +0.33 (Company avg: 4.67) - Above company

**Statistical Analysis:**
- **Standard Deviation**: 0.00 (High consensus)
- **Percentile Rank**: 86.1th percentile
- **Score Range**: 5.0 - 5.0 (spread: 0.0)

*Perfect consensus - all reviewers gave identical scores*

---

## Question 11: eNPS - Peer Comments Summary

### Synthesized Summary

*[AI synthesis needed - invoke rise8-assessment-reviewer agent with eNPS comments]*

<details>
<summary>View Raw eNPS Comments</summary>

**Jennifer Van Hove:**
Rob is an incredible resource for PMs of all skill levels.  I'm really excited to see how his expertise can be articulated and presented via Enablement within Rise8 and the industry at large.  For a lot of the criteria above, Rob not only has demonstrated the value implicitly, but there are often concrete examples.  Certainly for growth, and grit, and doing what is required, Rob will absolutely dig in to make things happen.  And he set the standards for outcome oriented project management.  It has been great to have him on Prod Hall to help clarify standards and help teams better express the impact of their outcomes.  I'm kind of curious whether the rules around outcomes could be simpler.  I dream of a world where we don't need a team of experts to adjudicate every submission.  But I have really enjoyed working with Rob as a DPL - his logic, clarity, and rigor has really pushed the PM practice forward and I look forward to seeing that expertise operate at scale.

**Brian Jennings:**
Rob lives out the Rise8 core values and expects that of his peers too. He's able to easily navigate between the strategic high level as well as tactically supporting initiatives and peers. Rob cares deeply about both the work he does and the people he supports in the PM department.

**Jeff Wills:**
Rob has probably had the biggest impact on getting teams to report Outcomes.  The work he did with Drumbeats, Lattice Goals, VSMs, and Outcome-Oriented Roadmaps really set teams up to think about the outcomes they wanted and the follow-through to document them in the Employee site.




I would have rated Rob higher on do hard things and do right by the customer.  I feel like we needed to execute some PM swaps more quickly than we did.  Which impacted team performance where PM fits weren't good.




I think the Lattice Goal Tracker was a great idea, but it doesn't feel like an organic place for that.  The Goal tool is definitely built for this kind of stuff, but Lattice itself seemed to be the issue.  I would have liked to see this done in the employee site instead, as all things outcomes happen there.  Could be me but I didn't get value from not sure if teams were either.  I knew it was there but not how it was being used was it in test, did we move away from it, or should I have been more diligent in using it?




Perhaps this was a result of some performance in the PM side but some of the PM population seemed unsure, or carried the stress about what Rob would think.  Probably appropriate, given the performance issues. Despite going to enablement, I think it would be good for Rob to reflect on ways to still be direct but create just the right amount of stress. I could be way off here but I didn't get the same vibe from PE folks who were on PIP.

**Bryon Kroger:**
Three areas I think you could work on if you really want to be A++:
Alignment... I think sometimes your urgency and bias for action cause you to skip the alignment. Sometimes the up front part of rolling out something new, but then especially on the reiteration of the why along the way. Taking the time to really dig in with people on why will be a huge unlock for your leadership.
Focusing on Activities and Outputs when needed... this became a huge top-down focus in 2024/2025, but knowing when you can let someone run with an outcome versus when you need to give them a lesson in how to achieve one is key. It's not always micromanagement to teach the how... in many contexts that's a positive thing called coaching. On the flip side, "empowerment" without enablement is neglect. You have both skills, you just have to get confident in assessing which to employ. 
Kindness and making others feel cared for. I think you do this well when there's a clear separation of intention... like if someone comes to you specifically for that. You clearly care about people. But when you are in problem solving mode, you often lose that to the point of people feeling not only not cared for, but sometimes attacked or hurt. It's something to be mindful of. Aggression is good. I don't think we can get much done without it. So I wouldn't say to put it away or you will lose your edge and something that makes you great. It's just integrating it and avoiding the shadow forms. A big thing that might help you, specifically, is speech tone and patterns. Your tone, and sometimes volume, can get pretty harsh along with tempo/pacing. Fixing those two things will drastically lower that perception (that you don't care on a personal level when you challenge directly... obnoxious aggression in radical candor).

**Roshni Patel:**
Rob is an exceptional PM practice lead‚Äîextremely intelligent, thoughtful, and always willing to help. He brings deep expertise and a strategic perspective that elevates the work of everyone on the team. I genuinely appreciate how approachable he is and how generous he is with his time and guidance. His mentorship and willingness to support the team make him an invaluable leader.


</details>

---

## Question 12: Start/Stop/Keep Recommendations

### Synthesized Summary

**START:**
*[AI synthesis needed - invoke rise8-assessment-reviewer agent with START feedback]*

**STOP:**
*[AI synthesis needed - invoke rise8-assessment-reviewer agent with STOP feedback]*

**KEEP:**
*[AI synthesis needed - invoke rise8-assessment-reviewer agent with KEEP feedback]*

<details>
<summary>View Raw Start/Stop/Keep Feedback</summary>

**Jennifer Van Hove:**
Start: Passing on positive comments as often as possible.  




Continue: Clearly articulating PM standards and practices; offering support and pairing when needed; grappling with the practical application of general standards; collecting feedback from CSMs and addressing it and being a thoughtful and conscientious presence in the Delivery org.  Don't disappear entirely into the Enablement bubble!  The conversations are all happening out here!

**Brian Jennings:**
Continue: Asking for feedback from the PMs on the initiatives you are driving to understand what has/hasn't been effective and continue to tailor and tweak our understanding based on learnings. You drive a lot of broad initiatives across the PM department, continue to learn and iterate as you drive work and practice consistency to adapt to how implementation is going.




Start: In your new Enablement Lead role, you'll no longer have PMs reporting to you and your levers for driving change will be influence and credibility. Start to find ways to create feedback loops and check-in points for yourself on your ability to influence others so you can adapt as needed. With the EL role being so new, I'm not seeing a problem here per-se but something I would watch for in the new year knowing how things change when you no longer have direct supervisor authority.

**Jeff Wills:**
Keep crushing it on the PM practice items; it is making a difference.

**Bryon Kroger:**
Start waking up every morning and thinking about how you can make Rise8 the best company in the world at govtech product management, and make progress each day. This is a powerful frame.
Keep being such a strong advocate for ways of working, culture, and leading by example when it comes to grit and growth mindset!

**Roshni Patel:**
**Start:**
- Start providing feedback with a clearer definition of ‚Äúdone‚Äù or specific criteria for completion. This would help reduce the need for multiple iterations and make it easier for the team to align quickly.




**Continue:**
- Continue being incredibly supportive, intelligent, and approachable. Your mentorship and guidance consistently help the team grow and deliver stronger outcomes.
- Continue sharing your strategic perspective‚Äîit adds a lot of value to planning and decision-making across the team.


</details>

---

## Report Metadata

- **Generated**: 2025-12-04 17:48:05
- **Script Version**: 1.0.0
- **Data Sources**:
  - Assessment File: `assessments/Product-Management/Rob_Monroe.md`
  - Team Mapping: `LatticeAPI/lattice_api_client/team_map.json`
  - Comprehensive Data: `docs/analysis-results/riser_data_detailed.csv`
  - Tier Assignments: `docs/analysis-results/tier_assignments.csv`
