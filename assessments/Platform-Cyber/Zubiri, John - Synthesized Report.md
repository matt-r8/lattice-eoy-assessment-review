# John Zubiri - Individual Assessment Report

## Employee Information
- **Name**: John Zubiri
- **Department**: Platform-Cyber
- **Level**: Senior Practitioner
- **Team**: SecRel
- **Project**: VA PTEMS Lighthouse (Deloitte)
- **Assessment Period**: 2025 EOY
- **Tier Assignment**: B (Developing)

---

## Overall Scores

- **Peers Average**: 4.26 (based on 66 ratings)
- **Response Rate**: 6/6 peer reviewers (100%)
- **Self Average**: 3.55
- **Delta (Self - Peers)**: -0.71 ðŸŸ¢ (Humble)
- **Delta (Self - Level)**: -0.54 ðŸŸ¢ (Humble) (vs Level Average 4.09)
- **Delta (Self - Team)**: -0.74 ðŸŸ¢ (Humble) (vs Team Average 4.29)
- **Delta (Self - Department)**: -0.62 ðŸŸ¢ (Humble) (vs Department Average 4.17)
- **Delta (Self - Project)**: -0.57 ðŸŸ¢ (Humble) (vs Project Average 4.12)

---

## Accomplishments Review (Self-Assessment Question 13)

### Synthesized Summary

*[AI synthesis needed - invoke rise8-assessment-reviewer agent with accomplishments text]*

<details>
<summary>View Raw Accomplishments Text</summary>

Helped develop and architect our PowerBI runtime assessment dashboard that assessors use.  This dashboard is still a work in progress but it is a functioning tool that the assessors use as an overview of the state of tenants security. They appreciate the dashboard and the stakeholders appreciate the dashboard for measuring platform accepted risk.




I led the engineering work to decommission Snyk and migrate our pipeline to using CodeQL without affecting tenants. The transition went smoothly and as a result our team had an outcome. We have submitted quite a few outcomes. I believe roughly 14 if I track correctly. Stakeholders and leadership are very pleased with us. There is a desire to keep Rise8 on the Lighthouse program. This is one accomplishment I'm proud of is leading this work and seeing it be successful, smooth, and well received.




Our team had a bit of turnover this year and as someone with the most experience I helped train new members to be valuable contributors to the project. That led us to work smoothly and without interruptions.

</details>

---

## Per-Question Breakdown

### Question 1: Be Bold

**Basic Scores:**
- **Peers Average**: 3.67 (based on 6 ratings)
- **Response Rate**: 6/6 peer reviewers (100%)
- **Self Score**: 3.0
- **Median Score**: 3.50

**Self-Awareness Deltas:**
- **Delta (Self - Peers)**: -0.67 ðŸŸ¢ (Humble)
- **Delta (Self - Level)**: -1.04 ðŸŸ¢ (Humble)
- **Delta (Self - Team)**: -1.19 ðŸŸ¢ (Humble)
- **Delta (Self - Department)**: -1.07 ðŸŸ¢ (Humble)
- **Delta (Self - Project)**: -1.02 ðŸŸ¢ (Humble)

**Performance Comparisons (Peer Avg vs Groups):**
- **vs Team Average**: -0.52 (Team avg: 4.19) - Below team
- **vs Project Average**: -0.36 (Project avg: 4.02) - Below project
- **vs Department Average**: -0.41 (Department avg: 4.07) - Below department
- **vs Company Average**: -0.36 (Company avg: 4.03) - Below company

**Statistical Analysis:**
- **Standard Deviation**: 0.75 (Mixed opinions)
- **Percentile Rank**: 22.5th percentile
- **Score Range**: 3.0 - 5.0 (spread: 2.0)

**Interpretation:**
- Scores in the **22th percentile** on Be Bold company-wide (top 78%)
- Peer average (3.67) is **-0.52 below team average**
- **Mixed opinions** among reviewers (SD: 0.75)
- Score range (3.0-5.0) shows notable variability in reviewer perceptions

### Question 2: Do The Right Thing

**Basic Scores:**
- **Peers Average**: 4.17 (based on 6 ratings)
- **Response Rate**: 6/6 peer reviewers (100%)
- **Self Score**: 4.0
- **Median Score**: 4.50

**Self-Awareness Deltas:**
- **Delta (Self - Peers)**: -0.17 ðŸŸ¢ (Humble)
- **Delta (Self - Level)**: -0.18 ðŸŸ¢ (Humble)
- **Delta (Self - Team)**: -0.34 ðŸŸ¢ (Humble)
- **Delta (Self - Department)**: -0.25 ðŸŸ¢ (Humble)
- **Delta (Self - Project)**: -0.20 ðŸŸ¢ (Humble)

**Performance Comparisons (Peer Avg vs Groups):**
- **vs Team Average**: -0.18 (Team avg: 4.34) - Below team
- **vs Project Average**: -0.03 (Project avg: 4.20) - At project
- **vs Department Average**: -0.08 (Department avg: 4.25) - Below department
- **vs Company Average**: -0.05 (Company avg: 4.22) - Below company

**Statistical Analysis:**
- **Standard Deviation**: 0.90 (Mixed opinions)
- **Percentile Rank**: 39.5th percentile
- **Score Range**: 3.0 - 5.0 (spread: 2.0)

**Interpretation:**
- Scores in the **39th percentile** on Do The Right Thing company-wide (top 60%)
- Peer average (4.17) is **-0.18 below team average**
- **Mixed opinions** among reviewers (SD: 0.90)
- Score range (3.0-5.0) shows notable variability in reviewer perceptions

### Question 3: Do What Works

**Basic Scores:**
- **Peers Average**: 3.83 (based on 6 ratings)
- **Response Rate**: 6/6 peer reviewers (100%)
- **Self Score**: 3.0
- **Median Score**: 3.50

**Self-Awareness Deltas:**
- **Delta (Self - Peers)**: -0.83 ðŸŸ¢ (Humble)
- **Delta (Self - Level)**: -0.97 ðŸŸ¢ (Humble)
- **Delta (Self - Team)**: -1.17 ðŸŸ¢ (Humble)
- **Delta (Self - Department)**: -1.09 ðŸŸ¢ (Humble)
- **Delta (Self - Project)**: -1.12 ðŸŸ¢ (Humble)

**Performance Comparisons (Peer Avg vs Groups):**
- **vs Team Average**: -0.33 (Team avg: 4.17) - Below team
- **vs Project Average**: -0.29 (Project avg: 4.12) - Below project
- **vs Department Average**: -0.26 (Department avg: 4.09) - Below department
- **vs Company Average**: -0.14 (Company avg: 3.97) - Below company

**Statistical Analysis:**
- **Standard Deviation**: 0.90 (Mixed opinions)
- **Percentile Rank**: 37.4th percentile
- **Score Range**: 3.0 - 5.0 (spread: 2.0)

**Interpretation:**
- Scores in the **37th percentile** on Do What Works company-wide (top 63%)
- Peer average (3.83) is **-0.33 below team average**
- **Mixed opinions** among reviewers (SD: 0.90)
- Score range (3.0-5.0) shows notable variability in reviewer perceptions

### Question 4: Do What is Required

**Basic Scores:**
- **Peers Average**: 4.50 (based on 6 ratings)
- **Response Rate**: 6/6 peer reviewers (100%)
- **Self Score**: 4.0
- **Median Score**: 5.00

**Self-Awareness Deltas:**
- **Delta (Self - Peers)**: -0.50 ðŸŸ¢ (Humble)
- **Delta (Self - Level)**: -0.09 ðŸŸ¡ (Well-calibrated)
- **Delta (Self - Team)**: -0.33 ðŸŸ¢ (Humble)
- **Delta (Self - Department)**: -0.19 ðŸŸ¢ (Humble)
- **Delta (Self - Project)**: -0.10 ðŸŸ¢ (Humble)

**Performance Comparisons (Peer Avg vs Groups):**
- **vs Team Average**: +0.17 (Team avg: 4.33) - Above team
- **vs Project Average**: +0.40 (Project avg: 4.10) - Above project
- **vs Department Average**: +0.31 (Department avg: 4.19) - Above department
- **vs Company Average**: +0.40 (Company avg: 4.10) - Above company

**Statistical Analysis:**
- **Standard Deviation**: 0.76 (Mixed opinions)
- **Percentile Rank**: 77.1th percentile
- **Score Range**: 3.0 - 5.0 (spread: 2.0)

**Interpretation:**
- Scores in the **77th percentile** on Do What is Required company-wide (top 23%)
- Peer average (4.50) is **+0.40 above company average**
- **Mixed opinions** among reviewers (SD: 0.76)
- Score range (3.0-5.0) shows notable variability in reviewer perceptions

### Question 5: Always Be Kind

**Basic Scores:**
- **Peers Average**: 4.33 (based on 6 ratings)
- **Response Rate**: 6/6 peer reviewers (100%)
- **Self Score**: 3.0
- **Median Score**: 4.50

**Self-Awareness Deltas:**
- **Delta (Self - Peers)**: -1.33 ðŸŸ¢ (Humble)
- **Delta (Self - Level)**: -1.11 ðŸŸ¢ (Humble)
- **Delta (Self - Team)**: -1.30 ðŸŸ¢ (Humble)
- **Delta (Self - Department)**: -1.22 ðŸŸ¢ (Humble)
- **Delta (Self - Project)**: -1.26 ðŸŸ¢ (Humble)

**Performance Comparisons (Peer Avg vs Groups):**
- **vs Team Average**: +0.04 (Team avg: 4.30) - At team
- **vs Project Average**: +0.07 (Project avg: 4.26) - Above project
- **vs Department Average**: +0.12 (Department avg: 4.22) - Above department
- **vs Company Average**: +0.19 (Company avg: 4.14) - Above company

**Statistical Analysis:**
- **Standard Deviation**: 0.75 (Mixed opinions)
- **Percentile Rank**: 65.0th percentile
- **Score Range**: 3.0 - 5.0 (spread: 2.0)

**Interpretation:**
- Scores in the **65th percentile** on Always Be Kind company-wide (top 35%)
- Peer average (4.33) is **+0.19 above company average**
- **Mixed opinions** among reviewers (SD: 0.75)
- Score range (3.0-5.0) shows notable variability in reviewer perceptions

### Question 6: Keep it Real

**Basic Scores:**
- **Peers Average**: 4.50 (based on 6 ratings)
- **Response Rate**: 6/6 peer reviewers (100%)
- **Self Score**: 4.0
- **Median Score**: 5.00

**Self-Awareness Deltas:**
- **Delta (Self - Peers)**: -0.50 ðŸŸ¢ (Humble)
- **Delta (Self - Level)**: -0.17 ðŸŸ¢ (Humble)
- **Delta (Self - Team)**: -0.35 ðŸŸ¢ (Humble)
- **Delta (Self - Department)**: -0.30 ðŸŸ¢ (Humble)
- **Delta (Self - Project)**: -0.30 ðŸŸ¢ (Humble)

**Performance Comparisons (Peer Avg vs Groups):**
- **vs Team Average**: +0.15 (Team avg: 4.35) - Above team
- **vs Project Average**: +0.20 (Project avg: 4.30) - Above project
- **vs Department Average**: +0.20 (Department avg: 4.30) - Above department
- **vs Company Average**: +0.33 (Company avg: 4.17) - Above company

**Statistical Analysis:**
- **Standard Deviation**: 0.76 (Mixed opinions)
- **Percentile Rank**: 76.2th percentile
- **Score Range**: 3.0 - 5.0 (spread: 2.0)

**Interpretation:**
- Scores in the **76th percentile** on Keep it Real company-wide (top 24%)
- Peer average (4.50) is **+0.33 above company average**
- **Mixed opinions** among reviewers (SD: 0.76)
- Score range (3.0-5.0) shows notable variability in reviewer perceptions

### Question 7: Outcomes in Production

**Basic Scores:**
- **Peers Average**: 4.33 (based on 6 ratings)
- **Response Rate**: 6/6 peer reviewers (100%)
- **Self Score**: 4.0
- **Median Score**: 4.50

**Self-Awareness Deltas:**
- **Delta (Self - Peers)**: -0.33 ðŸŸ¢ (Humble)
- **Delta (Self - Level)**: +0.02 ðŸŸ¡ (Well-calibrated)
- **Delta (Self - Team)**: -0.23 ðŸŸ¢ (Humble)
- **Delta (Self - Department)**: +0.01 ðŸŸ¡ (Well-calibrated)
- **Delta (Self - Project)**: -0.02 ðŸŸ¡ (Well-calibrated)

**Performance Comparisons (Peer Avg vs Groups):**
- **vs Team Average**: +0.11 (Team avg: 4.23) - Above team
- **vs Project Average**: +0.31 (Project avg: 4.02) - Above project
- **vs Department Average**: +0.34 (Department avg: 3.99) - Above department
- **vs Company Average**: +0.35 (Company avg: 3.98) - Above company

**Statistical Analysis:**
- **Standard Deviation**: 0.75 (Mixed opinions)
- **Percentile Rank**: 76.6th percentile
- **Score Range**: 3.0 - 5.0 (spread: 2.0)

**Interpretation:**
- Scores in the **76th percentile** on Outcomes in Production company-wide (top 23%)
- Peer average (4.33) is **+0.35 above company average**
- **Mixed opinions** among reviewers (SD: 0.75)
- Score range (3.0-5.0) shows notable variability in reviewer perceptions

### Question 8: Grit

**Basic Scores:**
- **Peers Average**: 4.33 (based on 6 ratings)
- **Response Rate**: 6/6 peer reviewers (100%)
- **Self Score**: 3.0
- **Median Score**: 5.00

**Self-Awareness Deltas:**
- **Delta (Self - Peers)**: -1.33 ðŸŸ¢ (Humble)
- **Delta (Self - Level)**: -1.12 ðŸŸ¢ (Humble)
- **Delta (Self - Team)**: -1.30 ðŸŸ¢ (Humble)
- **Delta (Self - Department)**: -1.20 ðŸŸ¢ (Humble)
- **Delta (Self - Project)**: -1.18 ðŸŸ¢ (Humble)

**Performance Comparisons (Peer Avg vs Groups):**
- **vs Team Average**: +0.03 (Team avg: 4.30) - At team
- **vs Project Average**: +0.15 (Project avg: 4.18) - Above project
- **vs Department Average**: +0.13 (Department avg: 4.20) - Above department
- **vs Company Average**: +0.18 (Company avg: 4.16) - Above company

**Statistical Analysis:**
- **Standard Deviation**: 0.94 (Mixed opinions)
- **Percentile Rank**: 61.9th percentile
- **Score Range**: 3.0 - 5.0 (spread: 2.0)

**Interpretation:**
- Scores in the **61th percentile** on Grit company-wide (top 38%)
- Peer average (4.33) is **+0.18 above company average**
- **Mixed opinions** among reviewers (SD: 0.94)
- Score range (3.0-5.0) shows notable variability in reviewer perceptions

### Question 9: Growth Mindset

**Basic Scores:**
- **Peers Average**: 4.00 (based on 6 ratings)
- **Response Rate**: 6/6 peer reviewers (100%)
- **Self Score**: 3.0
- **Median Score**: 4.00

**Self-Awareness Deltas:**
- **Delta (Self - Peers)**: -1.00 ðŸŸ¢ (Humble)
- **Delta (Self - Level)**: -1.14 ðŸŸ¢ (Humble)
- **Delta (Self - Team)**: -1.34 ðŸŸ¢ (Humble)
- **Delta (Self - Department)**: -1.26 ðŸŸ¢ (Humble)
- **Delta (Self - Project)**: -1.26 ðŸŸ¢ (Humble)

**Performance Comparisons (Peer Avg vs Groups):**
- **vs Team Average**: -0.34 (Team avg: 4.34) - Below team
- **vs Project Average**: -0.26 (Project avg: 4.26) - Below project
- **vs Department Average**: -0.26 (Department avg: 4.26) - Below department
- **vs Company Average**: -0.19 (Company avg: 4.19) - Below company

**Statistical Analysis:**
- **Standard Deviation**: 0.82 (Mixed opinions)
- **Percentile Rank**: 33.7th percentile
- **Score Range**: 3.0 - 5.0 (spread: 2.0)

**Interpretation:**
- Scores in the **33th percentile** on Growth Mindset company-wide (top 66%)
- Peer average (4.00) is **-0.34 below team average**
- **Mixed opinions** among reviewers (SD: 0.82)
- Score range (3.0-5.0) shows notable variability in reviewer perceptions

### Question 10: No Unnecessary Rules

**Basic Scores:**
- **Peers Average**: 4.17 (based on 6 ratings)
- **Response Rate**: 6/6 peer reviewers (100%)
- **Self Score**: 4.0
- **Median Score**: 4.50

**Self-Awareness Deltas:**
- **Delta (Self - Peers)**: -0.17 ðŸŸ¢ (Humble)
- **Delta (Self - Level)**: -0.09 ðŸŸ¡ (Well-calibrated)
- **Delta (Self - Team)**: -0.30 ðŸŸ¢ (Humble)
- **Delta (Self - Department)**: -0.16 ðŸŸ¢ (Humble)
- **Delta (Self - Project)**: -0.04 ðŸŸ¡ (Well-calibrated)

**Performance Comparisons (Peer Avg vs Groups):**
- **vs Team Average**: -0.14 (Team avg: 4.30) - Below team
- **vs Project Average**: +0.13 (Project avg: 4.04) - Above project
- **vs Department Average**: +0.00 (Department avg: 4.16) - At department
- **vs Company Average**: +0.05 (Company avg: 4.11) - Above company

**Statistical Analysis:**
- **Standard Deviation**: 0.90 (Mixed opinions)
- **Percentile Rank**: 51.0th percentile
- **Score Range**: 3.0 - 5.0 (spread: 2.0)

**Interpretation:**
- Scores in the **51th percentile** on No Unnecessary Rules company-wide (top 49%)
- Peer average (4.17) is **-0.14 below team average**
- **Mixed opinions** among reviewers (SD: 0.90)
- Score range (3.0-5.0) shows notable variability in reviewer perceptions

### Question 11: eNPS (Employee Net Promoter Score)

**Basic Scores:**
- **Peers Average**: 5.00 (based on 6 ratings)
- **Response Rate**: 6/6 peer reviewers (100%)
- **Self Score**: 4.0
- **Median Score**: 5.00

**Self-Awareness Deltas:**
- **Delta (Self - Peers)**: -1.00 ðŸŸ¢ (Humble)
- **Delta (Self - Level)**: -0.67 ðŸŸ¢ (Humble)
- **Delta (Self - Team)**: -0.77 ðŸŸ¢ (Humble)
- **Delta (Self - Department)**: -0.67 ðŸŸ¢ (Humble)
- **Delta (Self - Project)**: -0.61 ðŸŸ¢ (Humble)

**Performance Comparisons (Peer Avg vs Groups):**
- **vs Team Average**: +0.23 (Team avg: 4.77) - Above team
- **vs Project Average**: +0.39 (Project avg: 4.61) - Above project
- **vs Department Average**: +0.33 (Department avg: 4.67) - Above department
- **vs Company Average**: +0.33 (Company avg: 4.67) - Above company

**Statistical Analysis:**
- **Standard Deviation**: 0.00 (High consensus)
- **Percentile Rank**: 86.1th percentile
- **Score Range**: 5.0 - 5.0 (spread: 0.0)

*Perfect consensus - all reviewers gave identical scores*

---

## Question 11: eNPS - Peer Comments Summary

### Synthesized Summary

*[AI synthesis needed - invoke rise8-assessment-reviewer agent with eNPS comments]*

<details>
<summary>View Raw eNPS Comments</summary>

**Luke Strebel:**
John is one of the **most competent Engineers** the team has had the privilege of working with. He is going to get the story done, whether it is well-written or not, and he isn't going to complain about it. Instead, he gives **constructive, team-first feedback** in retro or speedback. As the most senior engineer on the team, he is in a great position to help the team improve.
His decision to turn down the anchor role helped me re-align this expectation/ratings based on being a "Best in Grade" *developer*. He has **best-in-grade contributor**. A key example is his external awarenessâ€”surfacing concerns about the platform team, Andrew Bunker, and the GitHub migration. This is a Top 1% skill, but it's feedback that is often only shared in retros or 1-on-1s, rather than proactively.




The things that would take John to the "next level" a year from now (or if he wanted to be an anchor) are about "closing the loop." He's great at seeing potential issues; the next step is helping to track them and define the action items. A specific area for this is to be more proactive with **tech debt**; as the most senior dev, his help is needed in managing this, especially with the GitHub migration.




The other key "next level" item is to **help write and own *outcomes*.** He needs to be part of the collaboration to push back and ask, "Why are we doing this? How is this helping the user?" Right now, the dev team needs to have more accountability and ownership of that final outcome, including presenting it. Lastly, it's unclear what his current personal growth goal is, and that's a key part of his continued development.

**Branden Van Derbur:**
John's a critical asset to this team and it shows in everything he does.

**Scott Carlson:**
John is a critical team member and leader. I frequently look to him for guidance and for evaluating impact of architectural decisions. He always does right by the team and customer. He always speaks up in group discussions. Heâ€™s very chill and easy to work with.

**Dylan Doub:**
John brings a vast amount of expertise and thoughtfulness to the team which makes working with him easy and a great learning experience as well.

**Sally Yoo:**
I would enthusiastically rehire John. He is a valuable and highly supportive team member who is consistently helpful, patient, and insightful. He has already begun stepping up to co-lead Tech Lead tasks with Scott**** and is a reliable teammate who will always "say it as it is" when things need to be changed.

**Jeremy Arzuaga:**
Can't say enough great things about John. Wish we got to pair more over the last few months. He's easy to work with and determined to ship valuable features that improve security of LH. He takes initiative and does what's required. I think he handles uncertainty really well especially when it came to evaluating new security products


</details>

---

## Question 12: Start/Stop/Keep Recommendations

### Synthesized Summary

**START:**
*[AI synthesis needed - invoke rise8-assessment-reviewer agent with START feedback]*

**STOP:**
*[AI synthesis needed - invoke rise8-assessment-reviewer agent with STOP feedback]*

**KEEP:**
*[AI synthesis needed - invoke rise8-assessment-reviewer agent with KEEP feedback]*

<details>
<summary>View Raw Start/Stop/Keep Feedback</summary>

**Luke Strebel:**
- **Start:** Proactively tracking and surfacing tech debt and platform concerns (not just identifying them) and helping to define the action items.
- **Start:** Helping to write, own, and present the *outcomes* for your stories, and pushing back on the "why."
- **Start:** Sharing your "outside the story" insights (like the platform risk) proactively (e.g., pre-ipm, ipm, uat), not just in retro.
- **Start:** Sharing your personal growth goals so the team can help you close that gap.
- **Start:** Make an conscious effort to make sure our newer engineers and (especially Scott) have deep context about how our app is designed. Help us know where the skeletons in the closet are so we can prioritize fixing them!
- **Keep:** Your "Best in Grade" competency. You are one of the most reliable engineers on the team.
- **Keep:** Your constructive, team-first feedback in retro.
- **Keep:** That external awareness (platform risks, etc.). It's a top-tier skill.

**Branden Van Derbur:**
Start:
- Encouraging insight from newer teammates during domain design meetings such as IPM, etc to keep them included and focusing on broader pictures
Stop:
- No Notes
Keep:
- Encouraging top quality work
- Being a great mentor for the team
- Being a great fella to work with
- Bringing a great vibe to the team

**Scott Carlson:**
**Start/Stop**: At the beginning of a pair swap, maybe talk about approach on how we want to pair for the story. One pairing session felt a bit directionless on how we're going to implement and also how to share the driving (I'm also to blame for that). We have some team members that need to be a bit more bold and have a bias for action. Sometimes identifying expectations for the pair will help for these people.




**Keep**: I rely heavily on John's experience and depth of knowledge in the VA Lighthouse space. He steps up and speaks out during IPM and huddles to make sure we're doing the right thing the right way. Keep that up! John also is great at making sure the team doesn't have silos. John is great at going with the flow and pivoting on the spot if needed.

**Dylan Doub:**
Start: Bringing more of your knowledge and thoughts as a senior member of the team to the table. You can be a little quiet sometimes, but when you speak up, your input is incredibly valuable.
Stop: There are no behaviors that I believe you should stop.
Keep: Diving into problems trying to understand everything

**Sally Yoo:**
**Keep:**
- Keep giving insightful feedback to the team and being direct in your communication
- Maintain your helpful and patient approach when explaining things to new people.

**Jeremy Arzuaga:**
Start
- would love to see if you be the anchor. I think it's a crucial next step for growth and showing your leadership skills




Continue
- Leading stories and making sure they get across the finish line
- Providing your perspective during pre-ipm and ipm 
- being a great peer to work with


</details>

---

## Report Metadata

- **Generated**: 2025-12-04 17:48:03
- **Script Version**: 1.0.0
- **Data Sources**:
  - Assessment File: `assessments/Platform-Cyber/John_Zubiri.md`
  - Team Mapping: `LatticeAPI/lattice_api_client/team_map.json`
  - Comprehensive Data: `docs/analysis-results/riser_data_detailed.csv`
  - Tier Assignments: `docs/analysis-results/tier_assignments.csv`
