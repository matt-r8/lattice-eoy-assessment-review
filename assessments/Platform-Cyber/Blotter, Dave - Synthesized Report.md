# Dave Blotter - Individual Assessment Report

## Employee Information
- **Name**: Dave Blotter
- **Department**: Platform-Cyber
- **Level**: Senior Practitioner
- **Team**: IT Services
- **Project**: SSC/SNGF FORGE (AP IDIQ)
- **Assessment Period**: 2025 EOY
- **Tier Assignment**: C (Needs Immediate Improvement)

---

## Overall Scores

- **Peers Average**: 3.87 (based on 52 ratings)
- **Response Rate**: 5/5 peer reviewers (100%)
- **Self Average**: 4.36
- **Delta (Self - Peers)**: +0.49 ðŸ”´ (Overconfident)
- **Delta (Self - Level)**: +0.27 ðŸ”´ (Overconfident) (vs Level Average 4.09)
- **Delta (Self - Team)**: +0.31 ðŸ”´ (Overconfident) (vs Team Average 4.05)
- **Delta (Self - Department)**: +0.19 ðŸ”´ (Overconfident) (vs Department Average 4.17)
- **Delta (Self - Project)**: +0.19 ðŸ”´ (Overconfident) (vs Project Average 4.17)

---

## Accomplishments Review (Self-Assessment Question 13)

### Synthesized Summary

*[AI synthesis needed - invoke rise8-assessment-reviewer agent with accomplishments text]*

<details>
<summary>View Raw Accomplishments Text</summary>

**De-risking Program Delivery Through Strategic Analysis:** I proactively initiated and delivered a comprehensive analysis of the FORGE Managed IT Services program. I synthesized complex contractual documents (PWS), operational plans (roadmaps), and SLOs to identify high-impact risks to sustainable delivery, including staffing, 24/7 on-call, and scope-creep. This analysis provides leadership with a clear feasibility assessment and actionable recommendations, ensuring our team's long-term health and our ability to reliably deliver on our contractual commitments to the customer.




**Enabling Secure Velocity with IAM Automation (IaC):** I demonstrated adaptability and initiative by quickly learning IaC to author and implement automation for IAM user management. This directly supports Rise8's mission by replacing a manual, error-prone process with one that is fast, repeatable, and secure. The impact *is* a significant increase in provisioning speed, a reduction in manual toil, and a strengthened security and compliance posture for the program.




**Establishing the Foundation for Delivery (MVP Scope):** I played a critical role in defining the IT Services MVP scope by translating broad PWS requirements into a concrete, phased set of tasks and foundational processes. By mapping our team's activities to contractual obligations, I established the initial framework for core services. This work was essential for bringing clarity to our team's objectives, unblocking them from analysis paralysis, and enabling them to begin delivering value to the customer.

</details>

---

## Per-Question Breakdown

### Question 1: Be Bold

**Basic Scores:**
- **Peers Average**: 3.80 (based on 5 ratings)
- **Response Rate**: 5/5 peer reviewers (100%)
- **Self Score**: 4.0
- **Median Score**: 4.00

**Self-Awareness Deltas:**
- **Delta (Self - Peers)**: +0.20 ðŸ”´ (Overconfident)
- **Delta (Self - Level)**: -0.04 ðŸŸ¡ (Well-calibrated)
- **Delta (Self - Team)**: +0.02 ðŸŸ¡ (Well-calibrated)
- **Delta (Self - Department)**: -0.07 ðŸŸ¡ (Well-calibrated)
- **Delta (Self - Project)**: -0.06 ðŸŸ¡ (Well-calibrated)

**Performance Comparisons (Peer Avg vs Groups):**
- **vs Team Average**: -0.18 (Team avg: 3.98) - Below team
- **vs Project Average**: -0.26 (Project avg: 4.06) - Below project
- **vs Department Average**: -0.27 (Department avg: 4.07) - Below department
- **vs Company Average**: -0.23 (Company avg: 4.03) - Below company

**Statistical Analysis:**
- **Standard Deviation**: 0.75 (Mixed opinions)
- **Percentile Rank**: 33.1th percentile
- **Score Range**: 3.0 - 5.0 (spread: 2.0)

**Interpretation:**
- Scores in the **33th percentile** on Be Bold company-wide (top 67%)
- Peer average (3.80) is **-0.27 below department average**
- **Mixed opinions** among reviewers (SD: 0.75)
- Score range (3.0-5.0) shows notable variability in reviewer perceptions

### Question 2: Do The Right Thing

**Basic Scores:**
- **Peers Average**: 4.40 (based on 5 ratings)
- **Response Rate**: 5/5 peer reviewers (100%)
- **Self Score**: 5.0
- **Median Score**: 5.00

**Self-Awareness Deltas:**
- **Delta (Self - Peers)**: +0.60 ðŸ”´ (Overconfident)
- **Delta (Self - Level)**: +0.82 ðŸ”´ (Overconfident)
- **Delta (Self - Team)**: +0.60 ðŸ”´ (Overconfident)
- **Delta (Self - Department)**: +0.75 ðŸ”´ (Overconfident)
- **Delta (Self - Project)**: +0.78 ðŸ”´ (Overconfident)

**Performance Comparisons (Peer Avg vs Groups):**
- **vs Team Average**: +0.00 (Team avg: 4.40) - At team
- **vs Project Average**: +0.18 (Project avg: 4.22) - Above project
- **vs Department Average**: +0.15 (Department avg: 4.25) - Above department
- **vs Company Average**: +0.18 (Company avg: 4.22) - Above company

**Statistical Analysis:**
- **Standard Deviation**: 0.80 (Mixed opinions)
- **Percentile Rank**: 58.4th percentile
- **Score Range**: 3.0 - 5.0 (spread: 2.0)

**Interpretation:**
- Scores in the **58th percentile** on Do The Right Thing company-wide (top 42%)
- Peer average (4.40) is **+0.18 above company average**
- **Mixed opinions** among reviewers (SD: 0.80)
- Score range (3.0-5.0) shows notable variability in reviewer perceptions

### Question 3: Do What Works

**Basic Scores:**
- **Peers Average**: 3.50 (based on 4 ratings)
- **Response Rate**: 4/5 peer reviewers (80%)
- **Self Score**: 4.0
- **Median Score**: 3.00

**Self-Awareness Deltas:**
- **Delta (Self - Peers)**: +0.50 ðŸ”´ (Overconfident)
- **Delta (Self - Level)**: +0.03 ðŸŸ¡ (Well-calibrated)
- **Delta (Self - Team)**: +0.17 ðŸ”´ (Overconfident)
- **Delta (Self - Department)**: -0.09 ðŸŸ¡ (Well-calibrated)
- **Delta (Self - Project)**: -0.06 ðŸŸ¡ (Well-calibrated)

**Performance Comparisons (Peer Avg vs Groups):**
- **vs Team Average**: -0.33 (Team avg: 3.83) - Below team
- **vs Project Average**: -0.56 (Project avg: 4.06) - Below project
- **vs Department Average**: -0.59 (Department avg: 4.09) - Below department
- **vs Company Average**: -0.47 (Company avg: 3.97) - Below company

**Statistical Analysis:**
- **Standard Deviation**: 0.87 (Mixed opinions)
- **Percentile Rank**: 16.4th percentile
- **Score Range**: 3.0 - 5.0 (spread: 2.0)

**Interpretation:**
- Scores in the **16th percentile** on Do What Works company-wide (top 84%)
- Peer average (3.50) is **-0.59 below department average**
- **Mixed opinions** among reviewers (SD: 0.87)
- Score range (3.0-5.0) shows notable variability in reviewer perceptions

### Question 4: Do What is Required

**Basic Scores:**
- **Peers Average**: 3.60 (based on 5 ratings)
- **Response Rate**: 5/5 peer reviewers (100%)
- **Self Score**: 5.0
- **Median Score**: 3.00

**Self-Awareness Deltas:**
- **Delta (Self - Peers)**: +1.40 ðŸ”´ (Overconfident)
- **Delta (Self - Level)**: +0.91 ðŸ”´ (Overconfident)
- **Delta (Self - Team)**: +1.13 ðŸ”´ (Overconfident)
- **Delta (Self - Department)**: +0.81 ðŸ”´ (Overconfident)
- **Delta (Self - Project)**: +0.82 ðŸ”´ (Overconfident)

**Performance Comparisons (Peer Avg vs Groups):**
- **vs Team Average**: -0.27 (Team avg: 3.87) - Below team
- **vs Project Average**: -0.58 (Project avg: 4.18) - Below project
- **vs Department Average**: -0.59 (Department avg: 4.19) - Below department
- **vs Company Average**: -0.50 (Company avg: 4.10) - Below company

**Statistical Analysis:**
- **Standard Deviation**: 0.80 (Mixed opinions)
- **Percentile Rank**: 13.7th percentile
- **Score Range**: 3.0 - 5.0 (spread: 2.0)

**Interpretation:**
- Scores in the **13th percentile** on Do What is Required company-wide (top 86%)
- Peer average (3.60) is **-0.59 below department average**
- **Mixed opinions** among reviewers (SD: 0.80)
- Score range (3.0-5.0) shows notable variability in reviewer perceptions

### Question 5: Always Be Kind

**Basic Scores:**
- **Peers Average**: 4.20 (based on 5 ratings)
- **Response Rate**: 5/5 peer reviewers (100%)
- **Self Score**: 5.0
- **Median Score**: 4.00

**Self-Awareness Deltas:**
- **Delta (Self - Peers)**: +0.80 ðŸ”´ (Overconfident)
- **Delta (Self - Level)**: +0.89 ðŸ”´ (Overconfident)
- **Delta (Self - Team)**: +0.80 ðŸ”´ (Overconfident)
- **Delta (Self - Department)**: +0.78 ðŸ”´ (Overconfident)
- **Delta (Self - Project)**: +0.93 ðŸ”´ (Overconfident)

**Performance Comparisons (Peer Avg vs Groups):**
- **vs Team Average**: +0.00 (Team avg: 4.20) - At team
- **vs Project Average**: +0.13 (Project avg: 4.07) - Above project
- **vs Department Average**: -0.02 (Department avg: 4.22) - At department
- **vs Company Average**: +0.06 (Company avg: 4.14) - Above company

**Statistical Analysis:**
- **Standard Deviation**: 0.75 (Mixed opinions)
- **Percentile Rank**: 51.4th percentile
- **Score Range**: 3.0 - 5.0 (spread: 2.0)

**Interpretation:**
- Scores in the **51th percentile** on Always Be Kind company-wide (top 49%)
- Peer average (4.20) is **+0.13 above project average**
- **Mixed opinions** among reviewers (SD: 0.75)
- Score range (3.0-5.0) shows notable variability in reviewer perceptions

### Question 6: Keep it Real

**Basic Scores:**
- **Peers Average**: 4.25 (based on 4 ratings)
- **Response Rate**: 4/5 peer reviewers (80%)
- **Self Score**: 4.0
- **Median Score**: 4.50

**Self-Awareness Deltas:**
- **Delta (Self - Peers)**: -0.25 ðŸŸ¢ (Humble)
- **Delta (Self - Level)**: -0.17 ðŸŸ¢ (Humble)
- **Delta (Self - Team)**: -0.22 ðŸŸ¢ (Humble)
- **Delta (Self - Department)**: -0.30 ðŸŸ¢ (Humble)
- **Delta (Self - Project)**: -0.25 ðŸŸ¢ (Humble)

**Performance Comparisons (Peer Avg vs Groups):**
- **vs Team Average**: +0.03 (Team avg: 4.22) - At team
- **vs Project Average**: -0.00 (Project avg: 4.25) - At project
- **vs Department Average**: -0.05 (Department avg: 4.30) - At department
- **vs Company Average**: +0.08 (Company avg: 4.17) - Above company

**Statistical Analysis:**
- **Standard Deviation**: 0.83 (Mixed opinions)
- **Percentile Rank**: 53.5th percentile
- **Score Range**: 3.0 - 5.0 (spread: 2.0)

**Interpretation:**
- Scores in the **53th percentile** on Keep it Real company-wide (top 46%)
- Peer average (4.25) is **+0.08 above company average**
- **Mixed opinions** among reviewers (SD: 0.83)
- Score range (3.0-5.0) shows notable variability in reviewer perceptions

### Question 7: Outcomes in Production

**Basic Scores:**
- **Peers Average**: 3.75 (based on 4 ratings)
- **Response Rate**: 4/5 peer reviewers (80%)
- **Self Score**: 4.0
- **Median Score**: 3.50

**Self-Awareness Deltas:**
- **Delta (Self - Peers)**: +0.25 ðŸ”´ (Overconfident)
- **Delta (Self - Level)**: +0.02 ðŸŸ¡ (Well-calibrated)
- **Delta (Self - Team)**: +0.04 ðŸŸ¡ (Well-calibrated)
- **Delta (Self - Department)**: +0.01 ðŸŸ¡ (Well-calibrated)
- **Delta (Self - Project)**: -0.00 ðŸŸ¡ (Well-calibrated)

**Performance Comparisons (Peer Avg vs Groups):**
- **vs Team Average**: -0.21 (Team avg: 3.96) - Below team
- **vs Project Average**: -0.25 (Project avg: 4.00) - Below project
- **vs Department Average**: -0.24 (Department avg: 3.99) - Below department
- **vs Company Average**: -0.23 (Company avg: 3.98) - Below company

**Statistical Analysis:**
- **Standard Deviation**: 0.83 (Mixed opinions)
- **Percentile Rank**: 29.1th percentile
- **Score Range**: 3.0 - 5.0 (spread: 2.0)

**Interpretation:**
- Scores in the **29th percentile** on Outcomes in Production company-wide (top 71%)
- Peer average (3.75) is **-0.25 below project average**
- **Mixed opinions** among reviewers (SD: 0.83)
- Score range (3.0-5.0) shows notable variability in reviewer perceptions

### Question 8: Grit

**Basic Scores:**
- **Peers Average**: 4.00 (based on 5 ratings)
- **Response Rate**: 5/5 peer reviewers (100%)
- **Self Score**: 4.0
- **Median Score**: 4.00

**Self-Awareness Deltas:**
- **Delta (Self - Peers)**: +0.00 ðŸŸ¡ (Well-calibrated)
- **Delta (Self - Level)**: -0.12 ðŸŸ¢ (Humble)
- **Delta (Self - Team)**: +0.00 ðŸŸ¡ (Well-calibrated)
- **Delta (Self - Department)**: -0.20 ðŸŸ¢ (Humble)
- **Delta (Self - Project)**: -0.16 ðŸŸ¢ (Humble)

**Performance Comparisons (Peer Avg vs Groups):**
- **vs Team Average**: +0.00 (Team avg: 4.00) - At team
- **vs Project Average**: -0.16 (Project avg: 4.16) - Below project
- **vs Department Average**: -0.20 (Department avg: 4.20) - Below department
- **vs Company Average**: -0.16 (Company avg: 4.16) - Below company

**Statistical Analysis:**
- **Standard Deviation**: 0.63 (Mixed opinions)
- **Percentile Rank**: 35.7th percentile
- **Score Range**: 3.0 - 5.0 (spread: 2.0)

**Interpretation:**
- Scores in the **35th percentile** on Grit company-wide (top 64%)
- Peer average (4.00) is **-0.20 below department average**
- **Mixed opinions** among reviewers (SD: 0.63)
- Score range (3.0-5.0) shows notable variability in reviewer perceptions

### Question 9: Growth Mindset

**Basic Scores:**
- **Peers Average**: 3.60 (based on 5 ratings)
- **Response Rate**: 5/5 peer reviewers (100%)
- **Self Score**: 4.0
- **Median Score**: 4.00

**Self-Awareness Deltas:**
- **Delta (Self - Peers)**: +0.40 ðŸ”´ (Overconfident)
- **Delta (Self - Level)**: -0.14 ðŸŸ¢ (Humble)
- **Delta (Self - Team)**: -0.15 ðŸŸ¢ (Humble)
- **Delta (Self - Department)**: -0.26 ðŸŸ¢ (Humble)
- **Delta (Self - Project)**: -0.25 ðŸŸ¢ (Humble)

**Performance Comparisons (Peer Avg vs Groups):**
- **vs Team Average**: -0.55 (Team avg: 4.15) - Below team
- **vs Project Average**: -0.65 (Project avg: 4.25) - Below project
- **vs Department Average**: -0.66 (Department avg: 4.26) - Below department
- **vs Company Average**: -0.59 (Company avg: 4.19) - Below company

**Statistical Analysis:**
- **Standard Deviation**: 0.49 (Moderate agreement)
- **Percentile Rank**: 11.8th percentile
- **Score Range**: 3.0 - 4.0 (spread: 1.0)

**Interpretation:**
- Scores in the **11th percentile** on Growth Mindset company-wide (top 88%)
- Peer average (3.60) is **-0.66 below department average**
- **Moderate agreement** among reviewers (SD: 0.49)
- Score range (3.0-4.0) shows reasonable consistency in reviewer perceptions

### Question 10: No Unnecessary Rules

**Basic Scores:**
- **Peers Average**: 3.50 (based on 4 ratings)
- **Response Rate**: 4/5 peer reviewers (80%)
- **Self Score**: 5.0
- **Median Score**: 3.00

**Self-Awareness Deltas:**
- **Delta (Self - Peers)**: +1.50 ðŸ”´ (Overconfident)
- **Delta (Self - Level)**: +0.91 ðŸ”´ (Overconfident)
- **Delta (Self - Team)**: +1.17 ðŸ”´ (Overconfident)
- **Delta (Self - Department)**: +0.84 ðŸ”´ (Overconfident)
- **Delta (Self - Project)**: +0.86 ðŸ”´ (Overconfident)

**Performance Comparisons (Peer Avg vs Groups):**
- **vs Team Average**: -0.33 (Team avg: 3.83) - Below team
- **vs Project Average**: -0.64 (Project avg: 4.14) - Below project
- **vs Department Average**: -0.66 (Department avg: 4.16) - Below department
- **vs Company Average**: -0.61 (Company avg: 4.11) - Below company

**Statistical Analysis:**
- **Standard Deviation**: 0.87 (Mixed opinions)
- **Percentile Rank**: 9.8th percentile
- **Score Range**: 3.0 - 5.0 (spread: 2.0)

**Interpretation:**
- Scores in the **bottom 91%** on No Unnecessary Rules company-wide (top 10%)
- Peer average (3.50) is **-0.66 below department average**
- **Mixed opinions** among reviewers (SD: 0.87)
- Score range (3.0-5.0) shows notable variability in reviewer perceptions

### Question 11: eNPS (Employee Net Promoter Score)

**Basic Scores:**
- **Peers Average**: 4.20 (based on 5 ratings)
- **Response Rate**: 5/5 peer reviewers (100%)
- **Self Score**: 4.0
- **Median Score**: 4.00

**Self-Awareness Deltas:**
- **Delta (Self - Peers)**: -0.20 ðŸŸ¢ (Humble)
- **Delta (Self - Level)**: -0.67 ðŸŸ¢ (Humble)
- **Delta (Self - Team)**: -0.47 ðŸŸ¢ (Humble)
- **Delta (Self - Department)**: -0.67 ðŸŸ¢ (Humble)
- **Delta (Self - Project)**: -0.73 ðŸŸ¢ (Humble)

**Performance Comparisons (Peer Avg vs Groups):**
- **vs Team Average**: -0.27 (Team avg: 4.47) - Below team
- **vs Project Average**: -0.53 (Project avg: 4.73) - Below project
- **vs Department Average**: -0.47 (Department avg: 4.67) - Below department
- **vs Company Average**: -0.47 (Company avg: 4.67) - Below company

**Statistical Analysis:**
- **Standard Deviation**: 0.40 (Moderate agreement)
- **Percentile Rank**: 10.1th percentile
- **Score Range**: 4.0 - 5.0 (spread: 1.0)

**Interpretation:**
- Scores in the **10th percentile** on eNPS (Employee Net Promoter Score) company-wide (top 90%)
- Peer average (4.20) is **-0.53 below project average**
- **Moderate agreement** among reviewers (SD: 0.40)
- Score range (4.0-5.0) shows reasonable consistency in reviewer perceptions

---

## Question 11: eNPS - Peer Comments Summary

### Synthesized Summary

*[AI synthesis needed - invoke rise8-assessment-reviewer agent with eNPS comments]*

<details>
<summary>View Raw eNPS Comments</summary>

**Ann Kung:**
You took the initiative to dive deep into complex topics like Ansible, Kerberos, and IDM integration, effectively laying the foundational architecture for automated user management. You consistently apply technical expertise with an architectural mindset and proactively define team governance and best practices (e.g., drafting the team's code review process and coding standards).

**Chase Cast:**
Dave is an **exceptionally skilled and experienced** member of the team whose **critical thinking drives innovation** by consistently asking the hard, necessary questions. They are also a **great source of motivation and support** for their colleagues.

**David Alvarado:**
I didn't have too many opportunities to work directly with Dave since we're two separate teams, hence some of my "Haven't had the opportunity to observe" answers to the above questions.  On the few times i did have a chance to, I enjoyed the time and felt the he's a strong teammate within his team.

**Jeremy Steinbeck:**
In an effort to balance customer needs with completing a large number of reviews, I am prioritizing written feedback for the people I worked most closely with this year

**Steven Bair:**
Dave embodies the value of Do What is Required by taking the time to deep-dive into critical project and contract documentationâ€”such as the PWS, White Paper, and MDPAF guides. This ensures that he, and the team, are not just working hard, but working on the right things that align with our contractual commitments.
Dave also champions Do What Works through his focus on automation, specifically utilizing Ansible for user creation and onboarding, and his creation of high-value documentation (IRP, platform best practices). Culturally, he exemplifies Keep It Real and Be Bold; he provides timely, critical feedback to leadership regarding potential risks, demonstrating a strong desire to protect the mission and ensure the programâ€™s success.


</details>

---

## Question 12: Start/Stop/Keep Recommendations

### Synthesized Summary

**START:**
*[AI synthesis needed - invoke rise8-assessment-reviewer agent with START feedback]*

**STOP:**
*[AI synthesis needed - invoke rise8-assessment-reviewer agent with STOP feedback]*

**KEEP:**
*[AI synthesis needed - invoke rise8-assessment-reviewer agent with KEEP feedback]*

<details>
<summary>View Raw Start/Stop/Keep Feedback</summary>

**Ann Kung:**
- Continue driving the development of complex, centralized automation (Ansible/IDM): This is your biggest technical win. You are successfully building automation for user provisioning, monitoring, and reporting and integrating ITSM with IAM workflows.
- Elevate cross-functional influence by proactively managing technical relationships: As the anchor, you should be the proactive force that inspires cross-team collaboration and builds those relationships before you need something from them. You've noticed that sometimes it feels like the team gets "cold shouldered". To mitigate this, try taking the lead in reaching out early and often. Instead of letting others be the ones to send meeting invites, try taking the action item yourself so you can ensure it gets done on the timeline you want.
- Target documentation and analysis for impact, not output: Your ability to deep-dive and attention to detail is amazing. We have a difference in opinion on this, but I believe the resulting documents should be concise and targeted to the audience to ensure they are consumed and acted upon, especially in a timely manner. Part of the Sr. Information Technologist role is to adapt messaging to different audiences and influence team direction with compelling rationale.

**David Alvarado:**
I look forward to working with him more often in the future.

**Jeremy Steinbeck:**
In an effort to balance customer needs with completing a large number of reviews, I am prioritizing written feedback for the people I worked most closely with this year

**Steven Bair:**
- Keep working closely with leadership and other delivery teams. Your initiative to schedule meetings for quick reviews and feedback loops is vital.
- Keep voicing your thoughts and concerns. In our idea meritocracy, your perspective is essential for identifying risks early. Ensure your voice continues to be heard so we can navigate challenges and find success together.
- Keep working closely with your PM and leadership regarding roles and responsibilities, and prioritization of tasks. By ensuring work is documented and aligned with the project plan, you help the team avoid ambiguity and focus on delivering outcomes.


</details>

---

## Report Metadata

- **Generated**: 2025-12-04 17:48:01
- **Script Version**: 1.0.0
- **Data Sources**:
  - Assessment File: `assessments/Platform-Cyber/Dave_Blotter.md`
  - Team Mapping: `LatticeAPI/lattice_api_client/team_map.json`
  - Comprehensive Data: `docs/analysis-results/riser_data_detailed.csv`
  - Tier Assignments: `docs/analysis-results/tier_assignments.csv`
