# Nick Luckey - Individual Assessment Report

## Employee Information
- **Name**: Nick Luckey
- **Department**: Platform-Cyber
- **Level**: Practitioner III
- **Team**: Platform
- **Project**: SSC/SNGF FORGE (AP IDIQ)
- **Assessment Period**: 2025 EOY
- **Tier Assignment**: C (Needs Immediate Improvement)

---

## Overall Scores

- **Peers Average**: 3.52 (based on 61 ratings)
- **Response Rate**: 6/6 peer reviewers (100%)
- **Self Average**: 4.00
- **Delta (Self - Peers)**: +0.48 ðŸ”´ (Overconfident)
- **Delta (Self - Level)**: +0.00 ðŸŸ¡ (Well-calibrated) (vs Level Average 4.00)
- **Delta (Self - Team)**: -0.16 ðŸŸ¢ (Humble) (vs Team Average 4.16)
- **Delta (Self - Department)**: -0.17 ðŸŸ¢ (Humble) (vs Department Average 4.17)
- **Delta (Self - Project)**: -0.17 ðŸŸ¢ (Humble) (vs Project Average 4.17)

---

## Accomplishments Review (Self-Assessment Question 13)

### Synthesized Summary

*[AI synthesis needed - invoke rise8-assessment-reviewer agent with accomplishments text]*

<details>
<summary>View Raw Accomplishments Text</summary>

I designed and automated the process for creating dedicated clusters for tenants in designated VPCs. This step was critical for not only creating the environments tenants will use but also enabling the ability for the platform team to scale the platform for more users.




I helped design and implement ArgoCD as well as the repository structure we plan to use so that we can manage services across clusters using ArgoCD. This is a critical step in creating the platform because ArgoCD will be one of the primary ways users will interface with the platform to manage their applications. I was meticulous in designing this particular configuration so that Applications in the ArgoCD UI were organized in an intuitive way, making it significantly easier for all users to manage many services across many clusters.




Worked closely with the FORGE Enablement team to help them setup their mock applications in their dedicated environments using ArgoCD and other platform services. Helping the Enablement team setup more quickly not only allowed them to get a head start on their own team's work, but it was helpful for the platform team to validate users would be able to use the platform to deploy applications and that they would have an easy time doing so.

</details>

---

## Per-Question Breakdown

### Question 1: Be Bold

**Basic Scores:**
- **Peers Average**: 3.17 (based on 6 ratings)
- **Response Rate**: 6/6 peer reviewers (100%)
- **Self Score**: 4.0
- **Median Score**: 3.00

**Self-Awareness Deltas:**
- **Delta (Self - Peers)**: +0.83 ðŸ”´ (Overconfident)
- **Delta (Self - Level)**: +0.17 ðŸ”´ (Overconfident)
- **Delta (Self - Team)**: +0.10 ðŸ”´ (Overconfident)
- **Delta (Self - Department)**: -0.07 ðŸŸ¡ (Well-calibrated)
- **Delta (Self - Project)**: -0.06 ðŸŸ¡ (Well-calibrated)

**Performance Comparisons (Peer Avg vs Groups):**
- **vs Team Average**: -0.73 (Team avg: 3.90) - Below team
- **vs Project Average**: -0.90 (Project avg: 4.06) - Below project
- **vs Department Average**: -0.91 (Department avg: 4.07) - Below department
- **vs Company Average**: -0.86 (Company avg: 4.03) - Below company

**Statistical Analysis:**
- **Standard Deviation**: 0.37 (Moderate agreement)
- **Percentile Rank**: 3.9th percentile
- **Score Range**: 3.0 - 4.0 (spread: 1.0)

**Interpretation:**
- Scores in the **bottom 97%** on Be Bold company-wide (top 4%)
- Peer average (3.17) is **-0.91 below department average**
- **Moderate agreement** among reviewers (SD: 0.37)
- Score range (3.0-4.0) shows reasonable consistency in reviewer perceptions

### Question 2: Do The Right Thing

**Basic Scores:**
- **Peers Average**: 3.60 (based on 5 ratings)
- **Response Rate**: 5/6 peer reviewers (83%)
- **Self Score**: 4.0
- **Median Score**: 4.00

**Self-Awareness Deltas:**
- **Delta (Self - Peers)**: +0.40 ðŸ”´ (Overconfident)
- **Delta (Self - Level)**: -0.15 ðŸŸ¢ (Humble)
- **Delta (Self - Team)**: -0.14 ðŸŸ¢ (Humble)
- **Delta (Self - Department)**: -0.25 ðŸŸ¢ (Humble)
- **Delta (Self - Project)**: -0.22 ðŸŸ¢ (Humble)

**Performance Comparisons (Peer Avg vs Groups):**
- **vs Team Average**: -0.54 (Team avg: 4.14) - Below team
- **vs Project Average**: -0.62 (Project avg: 4.22) - Below project
- **vs Department Average**: -0.65 (Department avg: 4.25) - Below department
- **vs Company Average**: -0.62 (Company avg: 4.22) - Below company

**Statistical Analysis:**
- **Standard Deviation**: 0.49 (Moderate agreement)
- **Percentile Rank**: 11.2th percentile
- **Score Range**: 3.0 - 4.0 (spread: 1.0)

**Interpretation:**
- Scores in the **11th percentile** on Do The Right Thing company-wide (top 89%)
- Peer average (3.60) is **-0.65 below department average**
- **Moderate agreement** among reviewers (SD: 0.49)
- Score range (3.0-4.0) shows reasonable consistency in reviewer perceptions

### Question 3: Do What Works

**Basic Scores:**
- **Peers Average**: 3.50 (based on 6 ratings)
- **Response Rate**: 6/6 peer reviewers (100%)
- **Self Score**: 4.0
- **Median Score**: 3.50

**Self-Awareness Deltas:**
- **Delta (Self - Peers)**: +0.50 ðŸ”´ (Overconfident)
- **Delta (Self - Level)**: +0.21 ðŸ”´ (Overconfident)
- **Delta (Self - Team)**: -0.17 ðŸŸ¢ (Humble)
- **Delta (Self - Department)**: -0.09 ðŸŸ¡ (Well-calibrated)
- **Delta (Self - Project)**: -0.06 ðŸŸ¡ (Well-calibrated)

**Performance Comparisons (Peer Avg vs Groups):**
- **vs Team Average**: -0.67 (Team avg: 4.17) - Below team
- **vs Project Average**: -0.56 (Project avg: 4.06) - Below project
- **vs Department Average**: -0.59 (Department avg: 4.09) - Below department
- **vs Company Average**: -0.47 (Company avg: 3.97) - Below company

**Statistical Analysis:**
- **Standard Deviation**: 0.50 (Moderate agreement)
- **Percentile Rank**: 16.4th percentile
- **Score Range**: 3.0 - 4.0 (spread: 1.0)

**Interpretation:**
- Scores in the **16th percentile** on Do What Works company-wide (top 84%)
- Peer average (3.50) is **-0.67 below team average**
- **Moderate agreement** among reviewers (SD: 0.50)
- Score range (3.0-4.0) shows reasonable consistency in reviewer perceptions

### Question 4: Do What is Required

**Basic Scores:**
- **Peers Average**: 3.80 (based on 5 ratings)
- **Response Rate**: 5/6 peer reviewers (83%)
- **Self Score**: 4.0
- **Median Score**: 4.00

**Self-Awareness Deltas:**
- **Delta (Self - Peers)**: +0.20 ðŸ”´ (Overconfident)
- **Delta (Self - Level)**: -0.03 ðŸŸ¡ (Well-calibrated)
- **Delta (Self - Team)**: -0.17 ðŸŸ¢ (Humble)
- **Delta (Self - Department)**: -0.19 ðŸŸ¢ (Humble)
- **Delta (Self - Project)**: -0.18 ðŸŸ¢ (Humble)

**Performance Comparisons (Peer Avg vs Groups):**
- **vs Team Average**: -0.37 (Team avg: 4.17) - Below team
- **vs Project Average**: -0.38 (Project avg: 4.18) - Below project
- **vs Department Average**: -0.39 (Department avg: 4.19) - Below department
- **vs Company Average**: -0.30 (Company avg: 4.10) - Below company

**Statistical Analysis:**
- **Standard Deviation**: 0.75 (Mixed opinions)
- **Percentile Rank**: 26.1th percentile
- **Score Range**: 3.0 - 5.0 (spread: 2.0)

**Interpretation:**
- Scores in the **26th percentile** on Do What is Required company-wide (top 74%)
- Peer average (3.80) is **-0.39 below department average**
- **Mixed opinions** among reviewers (SD: 0.75)
- Score range (3.0-5.0) shows notable variability in reviewer perceptions

### Question 5: Always Be Kind

**Basic Scores:**
- **Peers Average**: 3.75 (based on 4 ratings)
- **Response Rate**: 4/6 peer reviewers (67%)
- **Self Score**: 4.0
- **Median Score**: 3.50

**Self-Awareness Deltas:**
- **Delta (Self - Peers)**: +0.25 ðŸ”´ (Overconfident)
- **Delta (Self - Level)**: -0.11 ðŸŸ¢ (Humble)
- **Delta (Self - Team)**: -0.20 ðŸŸ¢ (Humble)
- **Delta (Self - Department)**: -0.22 ðŸŸ¢ (Humble)
- **Delta (Self - Project)**: -0.07 ðŸŸ¡ (Well-calibrated)

**Performance Comparisons (Peer Avg vs Groups):**
- **vs Team Average**: -0.45 (Team avg: 4.20) - Below team
- **vs Project Average**: -0.32 (Project avg: 4.07) - Below project
- **vs Department Average**: -0.47 (Department avg: 4.22) - Below department
- **vs Company Average**: -0.39 (Company avg: 4.14) - Below company

**Statistical Analysis:**
- **Standard Deviation**: 0.83 (Mixed opinions)
- **Percentile Rank**: 19.6th percentile
- **Score Range**: 3.0 - 5.0 (spread: 2.0)

**Interpretation:**
- Scores in the **19th percentile** on Always Be Kind company-wide (top 80%)
- Peer average (3.75) is **-0.47 below department average**
- **Mixed opinions** among reviewers (SD: 0.83)
- Score range (3.0-5.0) shows notable variability in reviewer perceptions

### Question 6: Keep it Real

**Basic Scores:**
- **Peers Average**: 3.80 (based on 5 ratings)
- **Response Rate**: 5/6 peer reviewers (83%)
- **Self Score**: 4.0
- **Median Score**: 4.00

**Self-Awareness Deltas:**
- **Delta (Self - Peers)**: +0.20 ðŸ”´ (Overconfident)
- **Delta (Self - Level)**: -0.11 ðŸŸ¢ (Humble)
- **Delta (Self - Team)**: -0.31 ðŸŸ¢ (Humble)
- **Delta (Self - Department)**: -0.30 ðŸŸ¢ (Humble)
- **Delta (Self - Project)**: -0.25 ðŸŸ¢ (Humble)

**Performance Comparisons (Peer Avg vs Groups):**
- **vs Team Average**: -0.51 (Team avg: 4.31) - Below team
- **vs Project Average**: -0.45 (Project avg: 4.25) - Below project
- **vs Department Average**: -0.50 (Department avg: 4.30) - Below department
- **vs Company Average**: -0.37 (Company avg: 4.17) - Below company

**Statistical Analysis:**
- **Standard Deviation**: 0.75 (Mixed opinions)
- **Percentile Rank**: 21.0th percentile
- **Score Range**: 3.0 - 5.0 (spread: 2.0)

**Interpretation:**
- Scores in the **21th percentile** on Keep it Real company-wide (top 79%)
- Peer average (3.80) is **-0.51 below team average**
- **Mixed opinions** among reviewers (SD: 0.75)
- Score range (3.0-5.0) shows notable variability in reviewer perceptions

### Question 7: Outcomes in Production

**Basic Scores:**
- **Peers Average**: 4.00 (based on 2 ratings)
- **Response Rate**: 2/6 peer reviewers (33%)
- **Self Score**: 3.0
- **Median Score**: 4.00

**Self-Awareness Deltas:**
- **Delta (Self - Peers)**: -1.00 ðŸŸ¢ (Humble)
- **Delta (Self - Level)**: -0.89 ðŸŸ¢ (Humble)
- **Delta (Self - Team)**: -1.10 ðŸŸ¢ (Humble)
- **Delta (Self - Department)**: -0.99 ðŸŸ¢ (Humble)
- **Delta (Self - Project)**: -1.00 ðŸŸ¢ (Humble)

**Performance Comparisons (Peer Avg vs Groups):**
- **vs Team Average**: -0.10 (Team avg: 4.10) - Below team
- **vs Project Average**: -0.00 (Project avg: 4.00) - At project
- **vs Department Average**: +0.01 (Department avg: 3.99) - At department
- **vs Company Average**: +0.02 (Company avg: 3.98) - At company

**Statistical Analysis:**
- **Standard Deviation**: 1.00 (Mixed opinions)
- **Percentile Rank**: 49.3th percentile
- **Score Range**: 3.0 - 5.0 (spread: 2.0)

*Insufficient data for interpretation (minimum 3 responses needed)*

### Question 8: Grit

**Basic Scores:**
- **Peers Average**: 3.80 (based on 5 ratings)
- **Response Rate**: 5/6 peer reviewers (83%)
- **Self Score**: 4.0
- **Median Score**: 4.00

**Self-Awareness Deltas:**
- **Delta (Self - Peers)**: +0.20 ðŸ”´ (Overconfident)
- **Delta (Self - Level)**: -0.04 ðŸŸ¡ (Well-calibrated)
- **Delta (Self - Team)**: -0.10 ðŸŸ¡ (Well-calibrated)
- **Delta (Self - Department)**: -0.20 ðŸŸ¢ (Humble)
- **Delta (Self - Project)**: -0.16 ðŸŸ¢ (Humble)

**Performance Comparisons (Peer Avg vs Groups):**
- **vs Team Average**: -0.30 (Team avg: 4.10) - Below team
- **vs Project Average**: -0.36 (Project avg: 4.16) - Below project
- **vs Department Average**: -0.40 (Department avg: 4.20) - Below department
- **vs Company Average**: -0.36 (Company avg: 4.16) - Below company

**Statistical Analysis:**
- **Standard Deviation**: 0.75 (Mixed opinions)
- **Percentile Rank**: 23.4th percentile
- **Score Range**: 3.0 - 5.0 (spread: 2.0)

**Interpretation:**
- Scores in the **23th percentile** on Grit company-wide (top 77%)
- Peer average (3.80) is **-0.40 below department average**
- **Mixed opinions** among reviewers (SD: 0.75)
- Score range (3.0-5.0) shows notable variability in reviewer perceptions

### Question 9: Growth Mindset

**Basic Scores:**
- **Peers Average**: 4.00 (based on 5 ratings)
- **Response Rate**: 5/6 peer reviewers (83%)
- **Self Score**: 4.0
- **Median Score**: 4.00

**Self-Awareness Deltas:**
- **Delta (Self - Peers)**: +0.00 ðŸŸ¡ (Well-calibrated)
- **Delta (Self - Level)**: -0.16 ðŸŸ¢ (Humble)
- **Delta (Self - Team)**: -0.40 ðŸŸ¢ (Humble)
- **Delta (Self - Department)**: -0.26 ðŸŸ¢ (Humble)
- **Delta (Self - Project)**: -0.25 ðŸŸ¢ (Humble)

**Performance Comparisons (Peer Avg vs Groups):**
- **vs Team Average**: -0.40 (Team avg: 4.40) - Below team
- **vs Project Average**: -0.25 (Project avg: 4.25) - Below project
- **vs Department Average**: -0.26 (Department avg: 4.26) - Below department
- **vs Company Average**: -0.19 (Company avg: 4.19) - Below company

**Statistical Analysis:**
- **Standard Deviation**: 0.89 (Mixed opinions)
- **Percentile Rank**: 33.7th percentile
- **Score Range**: 3.0 - 5.0 (spread: 2.0)

**Interpretation:**
- Scores in the **33th percentile** on Growth Mindset company-wide (top 66%)
- Peer average (4.00) is **-0.40 below team average**
- **Mixed opinions** among reviewers (SD: 0.89)
- Score range (3.0-5.0) shows notable variability in reviewer perceptions

### Question 10: No Unnecessary Rules

**Basic Scores:**
- **Peers Average**: 3.83 (based on 6 ratings)
- **Response Rate**: 6/6 peer reviewers (100%)
- **Self Score**: 4.0
- **Median Score**: 3.50

**Self-Awareness Deltas:**
- **Delta (Self - Peers)**: +0.17 ðŸ”´ (Overconfident)
- **Delta (Self - Level)**: -0.03 ðŸŸ¡ (Well-calibrated)
- **Delta (Self - Team)**: -0.09 ðŸŸ¡ (Well-calibrated)
- **Delta (Self - Department)**: -0.16 ðŸŸ¢ (Humble)
- **Delta (Self - Project)**: -0.14 ðŸŸ¢ (Humble)

**Performance Comparisons (Peer Avg vs Groups):**
- **vs Team Average**: -0.26 (Team avg: 4.09) - Below team
- **vs Project Average**: -0.31 (Project avg: 4.14) - Below project
- **vs Department Average**: -0.33 (Department avg: 4.16) - Below department
- **vs Company Average**: -0.28 (Company avg: 4.11) - Below company

**Statistical Analysis:**
- **Standard Deviation**: 0.90 (Mixed opinions)
- **Percentile Rank**: 28.7th percentile
- **Score Range**: 3.0 - 5.0 (spread: 2.0)

**Interpretation:**
- Scores in the **28th percentile** on No Unnecessary Rules company-wide (top 71%)
- Peer average (3.83) is **-0.33 below department average**
- **Mixed opinions** among reviewers (SD: 0.90)
- Score range (3.0-5.0) shows notable variability in reviewer perceptions

### Question 11: eNPS (Employee Net Promoter Score)

**Basic Scores:**
- **Peers Average**: 4.00 (based on 6 ratings)
- **Response Rate**: 6/6 peer reviewers (100%)
- **Self Score**: 5.0
- **Median Score**: 4.00

**Self-Awareness Deltas:**
- **Delta (Self - Peers)**: +1.00 ðŸ”´ (Overconfident)
- **Delta (Self - Level)**: +0.40 ðŸ”´ (Overconfident)
- **Delta (Self - Team)**: +0.40 ðŸ”´ (Overconfident)
- **Delta (Self - Department)**: +0.33 ðŸ”´ (Overconfident)
- **Delta (Self - Project)**: +0.27 ðŸ”´ (Overconfident)

**Performance Comparisons (Peer Avg vs Groups):**
- **vs Team Average**: -0.60 (Team avg: 4.60) - Below team
- **vs Project Average**: -0.73 (Project avg: 4.73) - Below project
- **vs Department Average**: -0.67 (Department avg: 4.67) - Below department
- **vs Company Average**: -0.67 (Company avg: 4.67) - Below company

**Statistical Analysis:**
- **Standard Deviation**: 1.00 (Mixed opinions)
- **Percentile Rank**: 5.6th percentile
- **Score Range**: 2.0 - 5.0 (spread: 3.0)

**Interpretation:**
- Scores in the **bottom 95%** on eNPS (Employee Net Promoter Score) company-wide (top 6%)
- Peer average (4.00) is **-0.73 below project average**
- **Mixed opinions** among reviewers (SD: 1.00)
- Score range (2.0-5.0) shows notable variability in reviewer perceptions

---

## Question 11: eNPS - Peer Comments Summary

### Synthesized Summary

*[AI synthesis needed - invoke rise8-assessment-reviewer agent with eNPS comments]*

<details>
<summary>View Raw eNPS Comments</summary>

**Steven Bair:**
Nick has acted as an anchor on LH and a force multiplier for the FORGE platform team. He embodies the Rise8 mentality by not just delivering individual contributions, but by providing guidance, pairing, and story writing to ensure the junior developers around him succeed. Since joining FORGE, Nick demonstrated incredible grit and a growth mindset by quickly getting up to speed on a new tech stack with little assistance. He immediately translated this into outcomes, delivering critical work on Istio research, GitLab build-outs, Red Hat IdM, configuring GitOps for the air-gapped platform, and more. He consistently demonstrates a bias for action that drives the program forward.

**Asare Nkansah:**
Nick is a wizard with the keyboard, and I've had the privilege of seeing his impressive range of skills up close. His heroics and leadership were vital in digging the Lighthouse program out of some severe holes during our time at the VA, demonstrating his capacity to be an absolute force when fully engaged. Since joining Rise8 on FORGE, he has continued to be very helpful with ArgoCD and has done well pairing with other team members.




However, his day-to-day engagement and presence have been inconsistent recently. When Nick is focused, he is a formidable asset; when his focus is divided, it's a noticeable loss for the team. My primary wish is for more proactive communication. Even a brief heads-up on his bandwidth or availability would allow the team to better plan around him and offer support where needed. Despite these recent challenges, I still have immense faith in his skills and believe he is a valuable asset. I am hoping for a renewed focus and full engagement at the start of the year.

**Brandon Shouse:**
- Great work so far, trying to work through the ambiguity that is FORGE right now
- Your scripting work has been above board
- You are easy to work with and always willing to pivot if needed

**Eric Whitman:**
Nick is a solid individual contributor on the team and gets a lot of work done. Notably he isn't afraid to dive into new challenges or own important pieces like automation. He has a wealth of technical knowledge that is valuable to the team.

**Nick Weiss:**
Nick is an exceptional problem-solver who thrives on tackling our toughest technical challenges. He has a unique talent for not only finding the right solution but also for masterfully aligning the team on the learnings and the path forward. His ideas are consistently strong, and I would be thrilled to work with him again or have him on any team I'm a part of.

**Dylan Bossie:**
Luckey's output in terms of technical contribution has been quite low compared to other team members. While time spent preparing for Security+ is expected and supported by the team, it's been his priority for at least a month while accomplishing little other work, which has resulted in additional workload on the rest of the team. 




He often misses meetings and usually stays camera off and mic muted when he attends, limiting the team's ability to collaborate or work with him.


</details>

---

## Question 12: Start/Stop/Keep Recommendations

### Synthesized Summary

**START:**
*[AI synthesis needed - invoke rise8-assessment-reviewer agent with START feedback]*

**STOP:**
*[AI synthesis needed - invoke rise8-assessment-reviewer agent with STOP feedback]*

**KEEP:**
*[AI synthesis needed - invoke rise8-assessment-reviewer agent with KEEP feedback]*

<details>
<summary>View Raw Start/Stop/Keep Feedback</summary>

**Steven Bair:**
- Keep ensuring the platformâ€™s success through fast, secure, and future-facing implementation. Your ability to deliver high-quality technical solutions is exactly what works.
- Keep bringing your specific knowledge from Lighthouse to the table. You have high trust in this domain; use that experience to inform us what to keep and what to improve from our other projects.
- Keep voicing your thoughts during architecture discussions. There is a massive overlap between the programs regarding "what good looks like." We need you to speak up to help us learn from the work already done at the VA, ensuring we maximize our learning velocity and avoid repeating past mistakes.

**Brandon Shouse:**
- Don't hesitate to jump and take charge of your assigned work; you have a lot of knowledge and skill; you just need to showcase it a bit more, move fast, learn things, fail forward fast, all the catch phrases

**Eric Whitman:**
Keep up with being a solid technical performer and being willing to pair. My only suggestion would be to not be afraid to speak up during any technical planning or any risks you might see. I would also try and knock out the Security+ ASAP so you can get back to making great contributions in IL5/etc.

**Nick Weiss:**
Please **continue** to be our go-to expert for complex technical problems. Your ability to dig into a difficult issue, find a robust solution, andâ€”just as importantlyâ€”align the entire team on your findings is a massive asset. We rely on your great ideas and your methodical approach to solving challenges that others are stuck on.




You have the deep technical know-how and strategic insight to be a primary driver of our team's direction. My only suggestion is to **start** acting on your instincts and believing in your voice more. You have absolutely earned the right to be more assertive; don't wait for the team to consensusâ€”be the one to propose the solution, advocate for your vision, and drive it forward. We trust your judgment and want to see you lead the charge more often.

**Dylan Bossie:**
Start:
- Being present/responsive and engaged with the team in Slack, meetings, pairing room, etc.
- Documenting finished work, leaving comments about what's getting done, and being clear about work status




Stop:
- Shell scripting when more robust tooling is available




Continue:
- Providing valuable insights on networking, technical knowledge, etc. that other team members miss or don't know


</details>

---

## Report Metadata

- **Generated**: 2025-12-04 17:48:04
- **Script Version**: 1.0.0
- **Data Sources**:
  - Assessment File: `assessments/Platform-Cyber/Nick_Luckey.md`
  - Team Mapping: `LatticeAPI/lattice_api_client/team_map.json`
  - Comprehensive Data: `docs/analysis-results/riser_data_detailed.csv`
  - Tier Assignments: `docs/analysis-results/tier_assignments.csv`
