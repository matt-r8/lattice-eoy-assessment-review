# Abbie Burton - Individual Assessment Report

## Employee Information
- **Name**: Abbie Burton
- **Department**: Product-Management
- **Level**: Senior Practitioner
- **Team**: Malibu
- **Project**: KM - Section 31 & Platform (Tecolote)
- **Assessment Period**: 2025 EOY
- **Tier Assignment**: A- (A Player Baseline)

---

## Overall Scores

- **Peers Average**: 3.82 (based on 38 ratings)
- **Response Rate**: 4/4 peer reviewers (100%)
- **Self Average**: 4.00
- **Delta (Self - Peers)**: +0.18 ğŸ”´ (Overconfident)
- **Delta (Self - Level)**: -0.07 ğŸŸ¡ (Well-calibrated) (vs Level Average 4.07)
- **Delta (Self - Team)**: +0.23 ğŸ”´ (Overconfident) (vs Team Average 3.77)
- **Delta (Self - Department)**: -0.16 ğŸŸ¢ (Humble) (vs Department Average 4.16)
- **Delta (Self - Project)**: -0.12 ğŸŸ¢ (Humble) (vs Project Average 4.12)

---

## Accomplishments Review (Self-Assessment Question 13)

### Synthesized Summary

*[AI synthesis needed - invoke rise8-assessment-reviewer agent with accomplishments text]*

<details>
<summary>View Raw Accomplishments Text</summary>

- **Trailblazer on Warp Core**
   - I served as an early pathfinder for WarpCore, helping establish clarity and processes that enabled our team and ultimately other teams to succeed. Malibu created the initial P2P process for WC so we had a functional starting point but it wasn't perfect. We finalized the WC Marketplace P2P using the traditional ARR process, collaborating with the platform team, to optimize the process, which included a comprehensive P2P guide for other teams to follow. Once additional teams adopt this new WC P2P process, we will be able to submit a strong supporting outcome.
   - As part of our delivery milestones, Malibu completed Vue "Milestone 1", which is everything leading up to running the algorithm (matching the SCCs with sites) and successfully deployed the WC Marketplace app from IL4 to IL6. We connected to two new data sources that are now automated and reliable, significantly improving the user experience by eliminating their previously manual process for retrieving this data. We also cataloged the full Vue algorithm to ensure we had a complete understanding before re-writing it on WC. Through this analysis, we identified two viable approaches for rewriting the algorithm (Polars-based Python Transforms vs. Compute Modules) and presented them to Anthony. Pending a successful Polars proof of concept, this approach will not only allow us to migrate the algorithm, but also significantly improve its performance.
- **Product Leader in S31**
   - As Malibu's product manager I iterated on our outcome oriented roadmap, VSM and impact maps up to meet Rise8's standards. I shared our VSM with the other S31 teams, walking them through how we successfully approached the process, including best practices and lessons learned, so they could replicate and adapt it for their own products.
   - I conducted an in-person site visit to NSDC in September, where we gathered baseline metrics on the current Vue experience on the KM platform and demoed the future state of Vue on WC. I reviewed and updated the VSM with our customer's input. Based on insights from that visit, I also refined Malibu's Impact Map, and Roadmap and gathered the context needed to craft a more meaningful mission impact statement. I also secured user-driven prioritization for upcoming features, ensuring our roadmap reflects real operational needs.
   - Additionally, I prepared Frank and Alex for a second site visit in October which focused on validating Vueâ€™s "Milestone 1" implementation on WC and meeting with Maj Matt Holland to better understand organizational measures of success. Because of the structure, content, and context I provided, they were able to confidently conduct all necessary research on our behalf. The insights from this visit allowed me to thoughtfully de-scope several items from the MVP based on direct user feedback, keeping the product focused, deliverable, and aligned with mission impact.
   - In addition to driving Vueâ€™s migration from KM to Warp Core, we also delivered meaningful enhancements based on the pain points uncovered during our first site visit. We resolved the issue with the â€œLoad TLEâ€ button on Vue in KM and successfully transitioned the backend data connection from the failing UDL source to a reliable data source on WC. Users have validated that the updated functionality works as intended, and we will be submitting an outcome in production for this enhancement.
- **PM/PD Offsite Planning**
   - I was selected to join the planning team for the PM/PD Offsite and played a key role in ensuring the eventâ€™s success. I helped determine the location, researched and selected the optimal hotel, and contributed to shaping the agenda, organizing speakers, coordinating meals and arranging networking events. The offsite, which hosted 38 Risers, went off without a hitch. We received significant positive feedback on the curated learning sessions and the value of collaborating in person, reflecting the impact of our thorough preparation and thoughtful design.

</details>

---

## Per-Question Breakdown

### Question 1: Be Bold

**Basic Scores:**
- **Peers Average**: 3.50 (based on 4 ratings)
- **Response Rate**: 4/4 peer reviewers (100%)
- **Self Score**: 4.0
- **Median Score**: 3.50

**Self-Awareness Deltas:**
- **Delta (Self - Peers)**: +0.50 ğŸ”´ (Overconfident)
- **Delta (Self - Level)**: -0.04 ğŸŸ¡ (Well-calibrated)
- **Delta (Self - Team)**: +0.50 ğŸ”´ (Overconfident)
- **Delta (Self - Department)**: -0.20 ğŸŸ¢ (Humble)
- **Delta (Self - Project)**: +0.23 ğŸ”´ (Overconfident)

**Performance Comparisons (Peer Avg vs Groups):**
- **vs Team Average**: +0.00 (Team avg: 3.50) - At team
- **vs Project Average**: -0.27 (Project avg: 3.77) - Below project
- **vs Department Average**: -0.70 (Department avg: 4.20) - Below department
- **vs Company Average**: -0.53 (Company avg: 4.03) - Below company

**Statistical Analysis:**
- **Standard Deviation**: 0.50 (Moderate agreement)
- **Percentile Rank**: 15.1th percentile
- **Score Range**: 3.0 - 4.0 (spread: 1.0)

**Interpretation:**
- Scores in the **15th percentile** on Be Bold company-wide (top 85%)
- Peer average (3.50) is **-0.70 below department average**
- **Moderate agreement** among reviewers (SD: 0.50)
- Score range (3.0-4.0) shows reasonable consistency in reviewer perceptions

### Question 2: Do The Right Thing

**Basic Scores:**
- **Peers Average**: 4.00 (based on 4 ratings)
- **Response Rate**: 4/4 peer reviewers (100%)
- **Self Score**: 4.0
- **Median Score**: 4.00

**Self-Awareness Deltas:**
- **Delta (Self - Peers)**: +0.00 ğŸŸ¡ (Well-calibrated)
- **Delta (Self - Level)**: -0.18 ğŸŸ¢ (Humble)
- **Delta (Self - Team)**: +0.17 ğŸ”´ (Overconfident)
- **Delta (Self - Department)**: -0.31 ğŸŸ¢ (Humble)
- **Delta (Self - Project)**: -0.29 ğŸŸ¢ (Humble)

**Performance Comparisons (Peer Avg vs Groups):**
- **vs Team Average**: +0.17 (Team avg: 3.83) - Above team
- **vs Project Average**: -0.29 (Project avg: 4.29) - Below project
- **vs Department Average**: -0.31 (Department avg: 4.31) - Below department
- **vs Company Average**: -0.22 (Company avg: 4.22) - Below company

**Statistical Analysis:**
- **Standard Deviation**: 0.00 (High consensus)
- **Percentile Rank**: 29.7th percentile
- **Score Range**: 4.0 - 4.0 (spread: 0.0)

*Perfect consensus - all reviewers gave identical scores*

### Question 3: Do What Works

**Basic Scores:**
- **Peers Average**: 3.33 (based on 3 ratings)
- **Response Rate**: 3/4 peer reviewers (75%)
- **Self Score**: 3.0
- **Median Score**: 3.00

**Self-Awareness Deltas:**
- **Delta (Self - Peers)**: -0.33 ğŸŸ¢ (Humble)
- **Delta (Self - Level)**: -0.97 ğŸŸ¢ (Humble)
- **Delta (Self - Team)**: -0.42 ğŸŸ¢ (Humble)
- **Delta (Self - Department)**: -1.03 ğŸŸ¢ (Humble)
- **Delta (Self - Project)**: -0.67 ğŸŸ¢ (Humble)

**Performance Comparisons (Peer Avg vs Groups):**
- **vs Team Average**: -0.08 (Team avg: 3.42) - Below team
- **vs Project Average**: -0.33 (Project avg: 3.67) - Below project
- **vs Department Average**: -0.69 (Department avg: 4.03) - Below department
- **vs Company Average**: -0.64 (Company avg: 3.97) - Below company

**Statistical Analysis:**
- **Standard Deviation**: 0.47 (Moderate agreement)
- **Percentile Rank**: 7.3th percentile
- **Score Range**: 3.0 - 4.0 (spread: 1.0)

**Interpretation:**
- Scores in the **bottom 93%** on Do What Works company-wide (top 7%)
- Peer average (3.33) is **-0.69 below department average**
- **Moderate agreement** among reviewers (SD: 0.47)
- Score range (3.0-4.0) shows reasonable consistency in reviewer perceptions

### Question 4: Do What is Required

**Basic Scores:**
- **Peers Average**: 3.67 (based on 3 ratings)
- **Response Rate**: 3/4 peer reviewers (75%)
- **Self Score**: 4.0
- **Median Score**: 4.00

**Self-Awareness Deltas:**
- **Delta (Self - Peers)**: +0.33 ğŸ”´ (Overconfident)
- **Delta (Self - Level)**: -0.09 ğŸŸ¡ (Well-calibrated)
- **Delta (Self - Team)**: +0.17 ğŸ”´ (Overconfident)
- **Delta (Self - Department)**: -0.08 ğŸŸ¡ (Well-calibrated)
- **Delta (Self - Project)**: -0.15 ğŸŸ¢ (Humble)

**Performance Comparisons (Peer Avg vs Groups):**
- **vs Team Average**: -0.17 (Team avg: 3.83) - Below team
- **vs Project Average**: -0.49 (Project avg: 4.15) - Below project
- **vs Department Average**: -0.41 (Department avg: 4.08) - Below department
- **vs Company Average**: -0.43 (Company avg: 4.10) - Below company

**Statistical Analysis:**
- **Standard Deviation**: 0.47 (Moderate agreement)
- **Percentile Rank**: 17.3th percentile
- **Score Range**: 3.0 - 4.0 (spread: 1.0)

**Interpretation:**
- Scores in the **17th percentile** on Do What is Required company-wide (top 83%)
- Peer average (3.67) is **-0.49 below project average**
- **Moderate agreement** among reviewers (SD: 0.47)
- Score range (3.0-4.0) shows reasonable consistency in reviewer perceptions

### Question 5: Always Be Kind

**Basic Scores:**
- **Peers Average**: 3.67 (based on 3 ratings)
- **Response Rate**: 3/4 peer reviewers (75%)
- **Self Score**: 5.0
- **Median Score**: 4.00

**Self-Awareness Deltas:**
- **Delta (Self - Peers)**: +1.33 ğŸ”´ (Overconfident)
- **Delta (Self - Level)**: +0.89 ğŸ”´ (Overconfident)
- **Delta (Self - Team)**: +1.17 ğŸ”´ (Overconfident)
- **Delta (Self - Department)**: +0.80 ğŸ”´ (Overconfident)
- **Delta (Self - Project)**: +1.04 ğŸ”´ (Overconfident)

**Performance Comparisons (Peer Avg vs Groups):**
- **vs Team Average**: -0.17 (Team avg: 3.83) - Below team
- **vs Project Average**: -0.30 (Project avg: 3.96) - Below project
- **vs Department Average**: -0.53 (Department avg: 4.20) - Below department
- **vs Company Average**: -0.48 (Company avg: 4.14) - Below company

**Statistical Analysis:**
- **Standard Deviation**: 0.47 (Moderate agreement)
- **Percentile Rank**: 17.1th percentile
- **Score Range**: 3.0 - 4.0 (spread: 1.0)

**Interpretation:**
- Scores in the **17th percentile** on Always Be Kind company-wide (top 83%)
- Peer average (3.67) is **-0.53 below department average**
- **Moderate agreement** among reviewers (SD: 0.47)
- Score range (3.0-4.0) shows reasonable consistency in reviewer perceptions

### Question 6: Keep it Real

**Basic Scores:**
- **Peers Average**: 3.67 (based on 3 ratings)
- **Response Rate**: 3/4 peer reviewers (75%)
- **Self Score**: 4.0
- **Median Score**: 4.00

**Self-Awareness Deltas:**
- **Delta (Self - Peers)**: +0.33 ğŸ”´ (Overconfident)
- **Delta (Self - Level)**: -0.17 ğŸŸ¢ (Humble)
- **Delta (Self - Team)**: +0.37 ğŸ”´ (Overconfident)
- **Delta (Self - Department)**: -0.25 ğŸŸ¢ (Humble)
- **Delta (Self - Project)**: -0.21 ğŸŸ¢ (Humble)

**Performance Comparisons (Peer Avg vs Groups):**
- **vs Team Average**: +0.03 (Team avg: 3.63) - At team
- **vs Project Average**: -0.55 (Project avg: 4.21) - Below project
- **vs Department Average**: -0.58 (Department avg: 4.25) - Below department
- **vs Company Average**: -0.50 (Company avg: 4.17) - Below company

**Statistical Analysis:**
- **Standard Deviation**: 0.47 (Moderate agreement)
- **Percentile Rank**: 15.0th percentile
- **Score Range**: 3.0 - 4.0 (spread: 1.0)

**Interpretation:**
- Scores in the **15th percentile** on Keep it Real company-wide (top 85%)
- Peer average (3.67) is **-0.58 below department average**
- **Moderate agreement** among reviewers (SD: 0.47)
- Score range (3.0-4.0) shows reasonable consistency in reviewer perceptions

### Question 7: Outcomes in Production

**Basic Scores:**
- **Peers Average**: 3.33 (based on 3 ratings)
- **Response Rate**: 3/4 peer reviewers (75%)
- **Self Score**: 3.0
- **Median Score**: 3.00

**Self-Awareness Deltas:**
- **Delta (Self - Peers)**: -0.33 ğŸŸ¢ (Humble)
- **Delta (Self - Level)**: -0.98 ğŸŸ¢ (Humble)
- **Delta (Self - Team)**: -0.37 ğŸŸ¢ (Humble)
- **Delta (Self - Department)**: -1.05 ğŸŸ¢ (Humble)
- **Delta (Self - Project)**: -0.60 ğŸŸ¢ (Humble)

**Performance Comparisons (Peer Avg vs Groups):**
- **vs Team Average**: -0.03 (Team avg: 3.37) - At team
- **vs Project Average**: -0.26 (Project avg: 3.60) - Below project
- **vs Department Average**: -0.72 (Department avg: 4.05) - Below department
- **vs Company Average**: -0.65 (Company avg: 3.98) - Below company

**Statistical Analysis:**
- **Standard Deviation**: 0.47 (Moderate agreement)
- **Percentile Rank**: 9.6th percentile
- **Score Range**: 3.0 - 4.0 (spread: 1.0)

**Interpretation:**
- Scores in the **bottom 91%** on Outcomes in Production company-wide (top 10%)
- Peer average (3.33) is **-0.72 below department average**
- **Moderate agreement** among reviewers (SD: 0.47)
- Score range (3.0-4.0) shows reasonable consistency in reviewer perceptions

### Question 8: Grit

**Basic Scores:**
- **Peers Average**: 3.75 (based on 4 ratings)
- **Response Rate**: 4/4 peer reviewers (100%)
- **Self Score**: 4.0
- **Median Score**: 4.00

**Self-Awareness Deltas:**
- **Delta (Self - Peers)**: +0.25 ğŸ”´ (Overconfident)
- **Delta (Self - Level)**: -0.12 ğŸŸ¢ (Humble)
- **Delta (Self - Team)**: +0.23 ğŸ”´ (Overconfident)
- **Delta (Self - Department)**: -0.20 ğŸŸ¢ (Humble)
- **Delta (Self - Project)**: -0.20 ğŸŸ¢ (Humble)

**Performance Comparisons (Peer Avg vs Groups):**
- **vs Team Average**: -0.02 (Team avg: 3.77) - At team
- **vs Project Average**: -0.45 (Project avg: 4.20) - Below project
- **vs Department Average**: -0.45 (Department avg: 4.20) - Below department
- **vs Company Average**: -0.41 (Company avg: 4.16) - Below company

**Statistical Analysis:**
- **Standard Deviation**: 0.43 (Moderate agreement)
- **Percentile Rank**: 19.6th percentile
- **Score Range**: 3.0 - 4.0 (spread: 1.0)

**Interpretation:**
- Scores in the **19th percentile** on Grit company-wide (top 80%)
- Peer average (3.75) is **-0.45 below project average**
- **Moderate agreement** among reviewers (SD: 0.43)
- Score range (3.0-4.0) shows reasonable consistency in reviewer perceptions

### Question 9: Growth Mindset

**Basic Scores:**
- **Peers Average**: 3.67 (based on 3 ratings)
- **Response Rate**: 3/4 peer reviewers (75%)
- **Self Score**: 4.0
- **Median Score**: 4.00

**Self-Awareness Deltas:**
- **Delta (Self - Peers)**: +0.33 ğŸ”´ (Overconfident)
- **Delta (Self - Level)**: -0.14 ğŸŸ¢ (Humble)
- **Delta (Self - Team)**: +0.17 ğŸ”´ (Overconfident)
- **Delta (Self - Department)**: -0.17 ğŸŸ¢ (Humble)
- **Delta (Self - Project)**: -0.20 ğŸŸ¢ (Humble)

**Performance Comparisons (Peer Avg vs Groups):**
- **vs Team Average**: -0.17 (Team avg: 3.83) - Below team
- **vs Project Average**: -0.53 (Project avg: 4.20) - Below project
- **vs Department Average**: -0.51 (Department avg: 4.17) - Below department
- **vs Company Average**: -0.52 (Company avg: 4.19) - Below company

**Statistical Analysis:**
- **Standard Deviation**: 0.47 (Moderate agreement)
- **Percentile Rank**: 13.9th percentile
- **Score Range**: 3.0 - 4.0 (spread: 1.0)

**Interpretation:**
- Scores in the **13th percentile** on Growth Mindset company-wide (top 86%)
- Peer average (3.67) is **-0.53 below project average**
- **Moderate agreement** among reviewers (SD: 0.47)
- Score range (3.0-4.0) shows reasonable consistency in reviewer perceptions

### Question 10: No Unnecessary Rules

**Basic Scores:**
- **Peers Average**: 4.00 (based on 4 ratings)
- **Response Rate**: 4/4 peer reviewers (100%)
- **Self Score**: 4.0
- **Median Score**: 4.00

**Self-Awareness Deltas:**
- **Delta (Self - Peers)**: +0.00 ğŸŸ¡ (Well-calibrated)
- **Delta (Self - Level)**: -0.09 ğŸŸ¡ (Well-calibrated)
- **Delta (Self - Team)**: +0.30 ğŸ”´ (Overconfident)
- **Delta (Self - Department)**: -0.22 ğŸŸ¢ (Humble)
- **Delta (Self - Project)**: -0.17 ğŸŸ¢ (Humble)

**Performance Comparisons (Peer Avg vs Groups):**
- **vs Team Average**: +0.30 (Team avg: 3.70) - Above team
- **vs Project Average**: -0.17 (Project avg: 4.17) - Below project
- **vs Department Average**: -0.22 (Department avg: 4.22) - Below department
- **vs Company Average**: -0.11 (Company avg: 4.11) - Below company

**Statistical Analysis:**
- **Standard Deviation**: 0.00 (High consensus)
- **Percentile Rank**: 39.5th percentile
- **Score Range**: 4.0 - 4.0 (spread: 0.0)

*Perfect consensus - all reviewers gave identical scores*

### Question 11: eNPS (Employee Net Promoter Score)

**Basic Scores:**
- **Peers Average**: 5.00 (based on 4 ratings)
- **Response Rate**: 4/4 peer reviewers (100%)
- **Self Score**: 5.0
- **Median Score**: 5.00

**Self-Awareness Deltas:**
- **Delta (Self - Peers)**: +0.00 ğŸŸ¡ (Well-calibrated)
- **Delta (Self - Level)**: +0.33 ğŸ”´ (Overconfident)
- **Delta (Self - Team)**: +0.17 ğŸ”´ (Overconfident)
- **Delta (Self - Department)**: +0.30 ğŸ”´ (Overconfident)
- **Delta (Self - Project)**: +0.12 ğŸ”´ (Overconfident)

**Performance Comparisons (Peer Avg vs Groups):**
- **vs Team Average**: +0.17 (Team avg: 4.83) - Above team
- **vs Project Average**: +0.12 (Project avg: 4.88) - Above project
- **vs Department Average**: +0.30 (Department avg: 4.70) - Above department
- **vs Company Average**: +0.33 (Company avg: 4.67) - Above company

**Statistical Analysis:**
- **Standard Deviation**: 0.00 (High consensus)
- **Percentile Rank**: 86.1th percentile
- **Score Range**: 5.0 - 5.0 (spread: 0.0)

*Perfect consensus - all reviewers gave identical scores*

---

## Question 11: eNPS - Peer Comments Summary

### Synthesized Summary

*[AI synthesis needed - invoke rise8-assessment-reviewer agent with eNPS comments]*

<details>
<summary>View Raw eNPS Comments</summary>

**Damon Redding:**
**1. Strategic Alignment and Communication:** Abbie excels in aligning strategy, she has a keen ability to identify and address communication gaps within the team. When communication from key team members is lacking, Abbie effectively translates complex ideas into clear, understandable language for everyone. This skill has been instrumental in ensuring team cohesion and understanding.
**2. Collaboration and Influence:** Since I've joined, Abbie has demonstrated strong performance by focusing on collaboration, pairing, and alignment. Abbie frequently engages with leadership and extends her expertise to other teams at Rise8, showcasing her willingness to share knowledge and foster a collaborative environment.
**3. Leadership and Engagement:** Abbie's proactive engagement with leadership and her ability to lend support to other teams highlight her leadership potential. Her willingness to communicate and collaborate across the organization is commendable and sets a positive example for others.

**Alex Berner:**
Abbie is the portfolio's most trustworthy and reliable PM who consistently spearheads portfolio initiatives while ensuring her team delivers on their responsibilities in an organized and timely fashion. I especially commend her ability to grow the sense of urgency and engagement among the SPA developers on her team - I have noticed a visible improvement over the past year and I know it has been a focus of hers and not the easiest undertaking. She keeps a cool calm head about unexpected changes and approaches every new challenge with a smile.

**Erica Chang:**
Abbie has continued to do a great job of breaking down work in a way that keeps the team focused and empowered to keep continuously delivering, despite the ambiguous nature of the Warp Core migration. Setting up a site visit with the NSDC users must have been an incredibly insightful experience for the team, especially since they were also dealing with onboarding a new designer at the time. The timing would've hopefully allowed the designer to onboard even quicker onto the team. Abbie also collaborated on important artifacts with the users, like the value stream map, which allowed the team to understand the bigger picture of their work directly with the users. Abbie keeps the team moving even during times of uncertainty and is integral leader to them.

**Riya Patel:**
Abbie is dependable, consistently does the hard work and institutes Rise8 practices in her work. It's been a tough year for the Section 31 teams and I'm always impressed with how Abbie takes it in stride and still works to make Vue an even better application for users while we are in the midst of refactoring. She's an A player through and through!


</details>

---

## Question 12: Start/Stop/Keep Recommendations

### Synthesized Summary

**START:**
*[AI synthesis needed - invoke rise8-assessment-reviewer agent with START feedback]*

**STOP:**
*[AI synthesis needed - invoke rise8-assessment-reviewer agent with STOP feedback]*

**KEEP:**
*[AI synthesis needed - invoke rise8-assessment-reviewer agent with KEEP feedback]*

<details>
<summary>View Raw Start/Stop/Keep Feedback</summary>

**Damon Redding:**
- Start:
   - Structured Project Management: Adopt a more structured approach to project management. This includes setting clear milestones, deadlines, and deliverables. 
- Stop:
   - Less Flexibility: Shift towards a more decisive and structured approach to ensure that the team remains focused and productive.
- Continue:
   - Balancing PM and Project Management Roles: Continue to balance the roles of product manager and project manager. This dual focus will help ensure that both the strategic vision and the day-to-day execution are aligned and progressing smoothly.
   - Attention to Detail: Maintain a strong focus on details
   - Encouraging Team Collaboration: Keep fostering a collaborative team environment where open communication and idea sharing are encouraged.

**Alex Berner:**
Keep working on growing your understanding of your product's domain in regard to the impact it provides to the broader mission of Space C2. I know it has been somewhat of a difficult rewiring process for you to really try to understand the "why" vs the "what" and you have done a great job putting in the time and effort to broaden your understanding. I would love to see over the next year this new mission focused mindset become your default when approaching any product or conversation, since I think that will really level you up as a master of the domain versus a manager of the process to which you have been assigned.




As a follow on to that, one suggestion is to start focusing more on storytelling when presenting your product or meeting with users and stakeholders. Being able to evangelize your product, an experiment, or an outcome - big or small, internal or external - is a superpower when it comes to building trust with users, stakeholders, and team members. I know I have given some feedback on this in the past, but some of your demos and presentations can feel a little too much like a rehash of the content on the screen which can come across as somebody having put words in your mouth versus you speaking directly from your knowledge with passion and enthusiasm. I'd love to see more of a cohesive narrative that can reference the content being presented but expands upon it instead of relying on it (if that distinction makes sense). I think the first step is to deeply understand and believe the content (which you're working on), and by doing so your confidence and understanding will come across more clearly and make all types of presentations and conversations more engaging, believable, and trust-building. I hope that feedback makes sense since it's a little tricky to articulate, but for an actionable first step maybe practicing demos of your app or VSM or recent learnings without any visual aids could force you to rely more on your personal narrative. This is a tricky but IMO enormously valuable skill, so I'm happy to pair on it more and provide feedback where I can

**Erica Chang:**
- **Keep** continuing to spread your influence within Section31, especially as the more experienced product manager and with non-Rise8 members. If the Malibu team is still the furthest ahead on the migration effort, it's a great opportunity to share learnings with other teams we well.

**Riya Patel:**
Hopefully, Abbie gets the opportunity to work on an application that isn't just being refactored and has the chance to manage a product from 0 to prod!


</details>

---

## Report Metadata

- **Generated**: 2025-12-04 17:12:01
- **Script Version**: 1.0.0
- **Data Sources**:
  - Assessment File: `assessments/Product-Management/Abbie_Burton.md`
  - Team Mapping: `LatticeAPI/lattice_api_client/team_map.json`
  - Comprehensive Data: `docs/analysis-results/riser_data_detailed.csv`
  - Tier Assignments: `docs/analysis-results/tier_assignments.csv`
