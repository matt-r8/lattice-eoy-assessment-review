# Tom Anastasio - Individual Assessment Report

## Employee Information
- **Name**: Tom Anastasio
- **Department**: Design
- **Level**: Senior Practitioner
- **Team**: Malibu
- **Project**: KM - Section 31 & Platform (Tecolote)
- **Assessment Period**: 2025 EOY
- **Tier Assignment**: A- (A Player Baseline)

---

## Overall Scores

- **Peers Average**: 3.73 (based on 59 ratings)
- **Response Rate**: 6/6 peer reviewers (100%)
- **Self Average**: 3.91
- **Delta (Self - Peers)**: +0.18 ðŸ”´ (Overconfident)
- **Delta (Self - Level)**: -0.16 ðŸŸ¢ (Humble) (vs Level Average 4.07)
- **Delta (Self - Team)**: +0.14 ðŸ”´ (Overconfident) (vs Team Average 3.77)
- **Delta (Self - Department)**: -0.21 ðŸŸ¢ (Humble) (vs Department Average 4.12)
- **Delta (Self - Project)**: -0.21 ðŸŸ¢ (Humble) (vs Project Average 4.12)

---

## Accomplishments Review (Self-Assessment Question 13)

### Synthesized Summary

*[AI synthesis needed - invoke rise8-assessment-reviewer agent with accomplishments text]*

<details>
<summary>View Raw Accomplishments Text</summary>

1. **Spearheading the Non-Coder AI Vibe Coding Onboarding and Standardizing its Practice:** I personally took ownership of the ambitious goal to onboard and coach all non-coding Risers on the R&D "Starter Container" and Vibe Coding tools, achieving **100% adoption** among designers and **55%** among PMs. I authored self-serve documentation and became the primary subject matter expert, providing critical feedback to R&D leadership. Most significantly, I designed and executed a radical experiment where a designer successfully used Vibe Coding to push real components to a production repository, which I then documented and shared. This not only transformed our internal software building capability but also **paved the way for Vibe Coding to become a new standard at Rise8**, directly increasing our velocity and ability to deliver on our brand promises to customers.
2. **Elevating Designer Competency and Collaboration through the Vibe Coding Workshop:** I conceived, planned, and executed a 1.5-hour workshop involving nearly every Rise8 designer. The **three-team design battle** successfully pushed the limits of how quickly our designers can deliver workable prototypes from context, serving as a highly engaging and educational experience for less experienced designers. This initiative significantly contributed to the continuous improvement of our internal skill base and **cultivated an environment of growth and technical excellence**, ensuring we maintain A Players in every position.
3. **Pivotal Leveling Up of PM/Design Capabilities at Company Offsites:** As a core team member for both company-wide and the PM/Design offsites, I provided valuable contributions, including key branding and planning engaging activities. Critically, the PM/Design offsite I helped run was a **pivotal leveling-up experience** for Risers, creating an environment that was fun, collaborative, and empowered designers and PMs to successfully tackle the **new push for Value Stream Maps and prepare for incoming contracts**. This direct effort in internal professional development ensures we are assembling **high-performing teams** and **placing A Players in every position**, directly supporting our ability to secure and deliver future mission-critical work.

</details>

---

## Per-Question Breakdown

### Question 1: Be Bold

**Basic Scores:**
- **Peers Average**: 3.50 (based on 6 ratings)
- **Response Rate**: 6/6 peer reviewers (100%)
- **Self Score**: 4.0
- **Median Score**: 3.50

**Self-Awareness Deltas:**
- **Delta (Self - Peers)**: +0.50 ðŸ”´ (Overconfident)
- **Delta (Self - Level)**: -0.04 ðŸŸ¡ (Well-calibrated)
- **Delta (Self - Team)**: +0.50 ðŸ”´ (Overconfident)
- **Delta (Self - Department)**: +0.04 ðŸŸ¡ (Well-calibrated)
- **Delta (Self - Project)**: +0.23 ðŸ”´ (Overconfident)

**Performance Comparisons (Peer Avg vs Groups):**
- **vs Team Average**: +0.00 (Team avg: 3.50) - At team
- **vs Project Average**: -0.27 (Project avg: 3.77) - Below project
- **vs Department Average**: -0.46 (Department avg: 3.96) - Below department
- **vs Company Average**: -0.53 (Company avg: 4.03) - Below company

**Statistical Analysis:**
- **Standard Deviation**: 0.50 (Moderate agreement)
- **Percentile Rank**: 15.1th percentile
- **Score Range**: 3.0 - 4.0 (spread: 1.0)

**Interpretation:**
- Scores in the **15th percentile** on Be Bold company-wide (top 85%)
- Peer average (3.50) is **-0.53 below company average**
- **Moderate agreement** among reviewers (SD: 0.50)
- Score range (3.0-4.0) shows reasonable consistency in reviewer perceptions

### Question 2: Do The Right Thing

**Basic Scores:**
- **Peers Average**: 3.67 (based on 6 ratings)
- **Response Rate**: 6/6 peer reviewers (100%)
- **Self Score**: 3.0
- **Median Score**: 4.00

**Self-Awareness Deltas:**
- **Delta (Self - Peers)**: -0.67 ðŸŸ¢ (Humble)
- **Delta (Self - Level)**: -1.18 ðŸŸ¢ (Humble)
- **Delta (Self - Team)**: -0.83 ðŸŸ¢ (Humble)
- **Delta (Self - Department)**: -1.22 ðŸŸ¢ (Humble)
- **Delta (Self - Project)**: -1.29 ðŸŸ¢ (Humble)

**Performance Comparisons (Peer Avg vs Groups):**
- **vs Team Average**: -0.17 (Team avg: 3.83) - Below team
- **vs Project Average**: -0.63 (Project avg: 4.29) - Below project
- **vs Department Average**: -0.55 (Department avg: 4.22) - Below department
- **vs Company Average**: -0.55 (Company avg: 4.22) - Below company

**Statistical Analysis:**
- **Standard Deviation**: 0.47 (Moderate agreement)
- **Percentile Rank**: 12.9th percentile
- **Score Range**: 3.0 - 4.0 (spread: 1.0)

**Interpretation:**
- Scores in the **12th percentile** on Do The Right Thing company-wide (top 87%)
- Peer average (3.67) is **-0.63 below project average**
- **Moderate agreement** among reviewers (SD: 0.47)
- Score range (3.0-4.0) shows reasonable consistency in reviewer perceptions

### Question 3: Do What Works

**Basic Scores:**
- **Peers Average**: 3.50 (based on 4 ratings)
- **Response Rate**: 4/6 peer reviewers (67%)
- **Self Score**: 4.0
- **Median Score**: 3.50

**Self-Awareness Deltas:**
- **Delta (Self - Peers)**: +0.50 ðŸ”´ (Overconfident)
- **Delta (Self - Level)**: +0.03 ðŸŸ¡ (Well-calibrated)
- **Delta (Self - Team)**: +0.58 ðŸ”´ (Overconfident)
- **Delta (Self - Department)**: -0.08 ðŸŸ¡ (Well-calibrated)
- **Delta (Self - Project)**: +0.33 ðŸ”´ (Overconfident)

**Performance Comparisons (Peer Avg vs Groups):**
- **vs Team Average**: +0.08 (Team avg: 3.42) - Above team
- **vs Project Average**: -0.17 (Project avg: 3.67) - Below project
- **vs Department Average**: -0.58 (Department avg: 4.08) - Below department
- **vs Company Average**: -0.47 (Company avg: 3.97) - Below company

**Statistical Analysis:**
- **Standard Deviation**: 0.50 (Moderate agreement)
- **Percentile Rank**: 16.4th percentile
- **Score Range**: 3.0 - 4.0 (spread: 1.0)

**Interpretation:**
- Scores in the **16th percentile** on Do What Works company-wide (top 84%)
- Peer average (3.50) is **-0.58 below department average**
- **Moderate agreement** among reviewers (SD: 0.50)
- Score range (3.0-4.0) shows reasonable consistency in reviewer perceptions

### Question 4: Do What is Required

**Basic Scores:**
- **Peers Average**: 4.00 (based on 4 ratings)
- **Response Rate**: 4/6 peer reviewers (67%)
- **Self Score**: 4.0
- **Median Score**: 4.00

**Self-Awareness Deltas:**
- **Delta (Self - Peers)**: +0.00 ðŸŸ¡ (Well-calibrated)
- **Delta (Self - Level)**: -0.09 ðŸŸ¡ (Well-calibrated)
- **Delta (Self - Team)**: +0.17 ðŸ”´ (Overconfident)
- **Delta (Self - Department)**: -0.04 ðŸŸ¡ (Well-calibrated)
- **Delta (Self - Project)**: -0.15 ðŸŸ¢ (Humble)

**Performance Comparisons (Peer Avg vs Groups):**
- **vs Team Average**: +0.17 (Team avg: 3.83) - Above team
- **vs Project Average**: -0.15 (Project avg: 4.15) - Below project
- **vs Department Average**: -0.04 (Department avg: 4.04) - At department
- **vs Company Average**: -0.10 (Company avg: 4.10) - Below company

**Statistical Analysis:**
- **Standard Deviation**: 0.71 (Mixed opinions)
- **Percentile Rank**: 40.1th percentile
- **Score Range**: 3.0 - 5.0 (spread: 2.0)

**Interpretation:**
- Scores in the **40th percentile** on Do What is Required company-wide (top 60%)
- Peer average (4.00) is **+0.17 above team average**
- **Mixed opinions** among reviewers (SD: 0.71)
- Score range (3.0-5.0) shows notable variability in reviewer perceptions

### Question 5: Always Be Kind

**Basic Scores:**
- **Peers Average**: 4.00 (based on 5 ratings)
- **Response Rate**: 5/6 peer reviewers (83%)
- **Self Score**: 4.0
- **Median Score**: 4.00

**Self-Awareness Deltas:**
- **Delta (Self - Peers)**: +0.00 ðŸŸ¡ (Well-calibrated)
- **Delta (Self - Level)**: -0.11 ðŸŸ¢ (Humble)
- **Delta (Self - Team)**: +0.17 ðŸ”´ (Overconfident)
- **Delta (Self - Department)**: -0.18 ðŸŸ¢ (Humble)
- **Delta (Self - Project)**: +0.04 ðŸŸ¡ (Well-calibrated)

**Performance Comparisons (Peer Avg vs Groups):**
- **vs Team Average**: +0.17 (Team avg: 3.83) - Above team
- **vs Project Average**: +0.04 (Project avg: 3.96) - At project
- **vs Department Average**: -0.18 (Department avg: 4.18) - Below department
- **vs Company Average**: -0.14 (Company avg: 4.14) - Below company

**Statistical Analysis:**
- **Standard Deviation**: 0.89 (Mixed opinions)
- **Percentile Rank**: 36.0th percentile
- **Score Range**: 3.0 - 5.0 (spread: 2.0)

**Interpretation:**
- Scores in the **36th percentile** on Always Be Kind company-wide (top 64%)
- Peer average (4.00) is **-0.18 below department average**
- **Mixed opinions** among reviewers (SD: 0.89)
- Score range (3.0-5.0) shows notable variability in reviewer perceptions

### Question 6: Keep it Real

**Basic Scores:**
- **Peers Average**: 3.60 (based on 5 ratings)
- **Response Rate**: 5/6 peer reviewers (83%)
- **Self Score**: 4.0
- **Median Score**: 4.00

**Self-Awareness Deltas:**
- **Delta (Self - Peers)**: +0.40 ðŸ”´ (Overconfident)
- **Delta (Self - Level)**: -0.17 ðŸŸ¢ (Humble)
- **Delta (Self - Team)**: +0.37 ðŸ”´ (Overconfident)
- **Delta (Self - Department)**: -0.09 ðŸŸ¡ (Well-calibrated)
- **Delta (Self - Project)**: -0.21 ðŸŸ¢ (Humble)

**Performance Comparisons (Peer Avg vs Groups):**
- **vs Team Average**: -0.03 (Team avg: 3.63) - At team
- **vs Project Average**: -0.61 (Project avg: 4.21) - Below project
- **vs Department Average**: -0.49 (Department avg: 4.09) - Below department
- **vs Company Average**: -0.57 (Company avg: 4.17) - Below company

**Statistical Analysis:**
- **Standard Deviation**: 0.49 (Moderate agreement)
- **Percentile Rank**: 12.2th percentile
- **Score Range**: 3.0 - 4.0 (spread: 1.0)

**Interpretation:**
- Scores in the **12th percentile** on Keep it Real company-wide (top 88%)
- Peer average (3.60) is **-0.61 below project average**
- **Moderate agreement** among reviewers (SD: 0.49)
- Score range (3.0-4.0) shows reasonable consistency in reviewer perceptions

### Question 7: Outcomes in Production

**Basic Scores:**
- **Peers Average**: 3.40 (based on 5 ratings)
- **Response Rate**: 5/6 peer reviewers (83%)
- **Self Score**: 0.0
- **Median Score**: 3.00

**Self-Awareness Deltas:**
- **Delta (Self - Peers)**: -3.40 ðŸŸ¢ (Humble)
- **Delta (Self - Level)**: -3.98 ðŸŸ¢ (Humble)
- **Delta (Self - Team)**: -3.37 ðŸŸ¢ (Humble)
- **Delta (Self - Department)**: -3.98 ðŸŸ¢ (Humble)
- **Delta (Self - Project)**: -3.60 ðŸŸ¢ (Humble)

**Performance Comparisons (Peer Avg vs Groups):**
- **vs Team Average**: +0.03 (Team avg: 3.37) - At team
- **vs Project Average**: -0.20 (Project avg: 3.60) - Below project
- **vs Department Average**: -0.58 (Department avg: 3.98) - Below department
- **vs Company Average**: -0.58 (Company avg: 3.98) - Below company

**Statistical Analysis:**
- **Standard Deviation**: 0.49 (Moderate agreement)
- **Percentile Rank**: 12.4th percentile
- **Score Range**: 3.0 - 4.0 (spread: 1.0)

**Interpretation:**
- Scores in the **12th percentile** on Outcomes in Production company-wide (top 88%)
- Peer average (3.40) is **-0.58 below department average**
- **Moderate agreement** among reviewers (SD: 0.49)
- Score range (3.0-4.0) shows reasonable consistency in reviewer perceptions

### Question 8: Grit

**Basic Scores:**
- **Peers Average**: 3.80 (based on 5 ratings)
- **Response Rate**: 5/6 peer reviewers (83%)
- **Self Score**: 4.0
- **Median Score**: 4.00

**Self-Awareness Deltas:**
- **Delta (Self - Peers)**: +0.20 ðŸ”´ (Overconfident)
- **Delta (Self - Level)**: -0.12 ðŸŸ¢ (Humble)
- **Delta (Self - Team)**: +0.23 ðŸ”´ (Overconfident)
- **Delta (Self - Department)**: -0.01 ðŸŸ¡ (Well-calibrated)
- **Delta (Self - Project)**: -0.20 ðŸŸ¢ (Humble)

**Performance Comparisons (Peer Avg vs Groups):**
- **vs Team Average**: +0.02 (Team avg: 3.77) - At team
- **vs Project Average**: -0.40 (Project avg: 4.20) - Below project
- **vs Department Average**: -0.21 (Department avg: 4.01) - Below department
- **vs Company Average**: -0.36 (Company avg: 4.16) - Below company

**Statistical Analysis:**
- **Standard Deviation**: 0.75 (Mixed opinions)
- **Percentile Rank**: 23.4th percentile
- **Score Range**: 3.0 - 5.0 (spread: 2.0)

**Interpretation:**
- Scores in the **23th percentile** on Grit company-wide (top 77%)
- Peer average (3.80) is **-0.40 below project average**
- **Mixed opinions** among reviewers (SD: 0.75)
- Score range (3.0-5.0) shows notable variability in reviewer perceptions

### Question 9: Growth Mindset

**Basic Scores:**
- **Peers Average**: 4.00 (based on 6 ratings)
- **Response Rate**: 6/6 peer reviewers (100%)
- **Self Score**: 4.0
- **Median Score**: 4.00

**Self-Awareness Deltas:**
- **Delta (Self - Peers)**: +0.00 ðŸŸ¡ (Well-calibrated)
- **Delta (Self - Level)**: -0.14 ðŸŸ¢ (Humble)
- **Delta (Self - Team)**: +0.17 ðŸ”´ (Overconfident)
- **Delta (Self - Department)**: -0.21 ðŸŸ¢ (Humble)
- **Delta (Self - Project)**: -0.20 ðŸŸ¢ (Humble)

**Performance Comparisons (Peer Avg vs Groups):**
- **vs Team Average**: +0.17 (Team avg: 3.83) - Above team
- **vs Project Average**: -0.20 (Project avg: 4.20) - Below project
- **vs Department Average**: -0.21 (Department avg: 4.21) - Below department
- **vs Company Average**: -0.19 (Company avg: 4.19) - Below company

**Statistical Analysis:**
- **Standard Deviation**: 0.82 (Mixed opinions)
- **Percentile Rank**: 33.7th percentile
- **Score Range**: 3.0 - 5.0 (spread: 2.0)

**Interpretation:**
- Scores in the **33th percentile** on Growth Mindset company-wide (top 66%)
- Peer average (4.00) is **-0.21 below department average**
- **Mixed opinions** among reviewers (SD: 0.82)
- Score range (3.0-5.0) shows notable variability in reviewer perceptions

### Question 10: No Unnecessary Rules

**Basic Scores:**
- **Peers Average**: 3.40 (based on 5 ratings)
- **Response Rate**: 5/6 peer reviewers (83%)
- **Self Score**: 5.0
- **Median Score**: 3.00

**Self-Awareness Deltas:**
- **Delta (Self - Peers)**: +1.60 ðŸ”´ (Overconfident)
- **Delta (Self - Level)**: +0.91 ðŸ”´ (Overconfident)
- **Delta (Self - Team)**: +1.30 ðŸ”´ (Overconfident)
- **Delta (Self - Department)**: +0.94 ðŸ”´ (Overconfident)
- **Delta (Self - Project)**: +0.83 ðŸ”´ (Overconfident)

**Performance Comparisons (Peer Avg vs Groups):**
- **vs Team Average**: -0.30 (Team avg: 3.70) - Below team
- **vs Project Average**: -0.77 (Project avg: 4.17) - Below project
- **vs Department Average**: -0.66 (Department avg: 4.06) - Below department
- **vs Company Average**: -0.71 (Company avg: 4.11) - Below company

**Statistical Analysis:**
- **Standard Deviation**: 0.49 (Moderate agreement)
- **Percentile Rank**: 5.9th percentile
- **Score Range**: 3.0 - 4.0 (spread: 1.0)

**Interpretation:**
- Scores in the **bottom 95%** on No Unnecessary Rules company-wide (top 6%)
- Peer average (3.40) is **-0.77 below project average**
- **Moderate agreement** among reviewers (SD: 0.49)
- Score range (3.0-4.0) shows reasonable consistency in reviewer perceptions

### Question 11: eNPS (Employee Net Promoter Score)

**Basic Scores:**
- **Peers Average**: 4.67 (based on 6 ratings)
- **Response Rate**: 6/6 peer reviewers (100%)
- **Self Score**: 5.0
- **Median Score**: 5.00

**Self-Awareness Deltas:**
- **Delta (Self - Peers)**: +0.33 ðŸ”´ (Overconfident)
- **Delta (Self - Level)**: +0.33 ðŸ”´ (Overconfident)
- **Delta (Self - Team)**: +0.17 ðŸ”´ (Overconfident)
- **Delta (Self - Department)**: +0.31 ðŸ”´ (Overconfident)
- **Delta (Self - Project)**: +0.12 ðŸ”´ (Overconfident)

**Performance Comparisons (Peer Avg vs Groups):**
- **vs Team Average**: -0.17 (Team avg: 4.83) - Below team
- **vs Project Average**: -0.22 (Project avg: 4.88) - Below project
- **vs Department Average**: -0.03 (Department avg: 4.69) - At department
- **vs Company Average**: -0.01 (Company avg: 4.67) - At company

**Statistical Analysis:**
- **Standard Deviation**: 0.47 (Moderate agreement)
- **Percentile Rank**: 40.6th percentile
- **Score Range**: 4.0 - 5.0 (spread: 1.0)

**Interpretation:**
- Scores in the **40th percentile** on eNPS (Employee Net Promoter Score) company-wide (top 59%)
- Peer average (4.67) is **-0.22 below project average**
- **Moderate agreement** among reviewers (SD: 0.47)
- Score range (4.0-5.0) shows reasonable consistency in reviewer perceptions

---

## Question 11: eNPS - Peer Comments Summary

### Synthesized Summary

*[AI synthesis needed - invoke rise8-assessment-reviewer agent with eNPS comments]*

<details>
<summary>View Raw eNPS Comments</summary>

**Mike Gehard:**
Tom did a great job in scaling Claude Code use across non-technical members of the Rise8 team by doing 1:1 sessions with everyone.

**Brian Jennings:**
Tom has been an amazing contributor bringing AI practices to the design department and truly embodies a growth mindset always seeking feedback and looking to improve as a practitioner. Tom helped me get up and running with AI coding which was a huge mental hurdle for me to overcome and allowed me to unlock next level impact with my newfound abilities.




There are a couple of things I would continue to work on:
1. Being more bold: Tom was in a tough environment on SLD-45, he had underperforming folks around him including at the portfolio level often pulling him in different directions. In those circumstances, it was easy for you to get pulled into the thrash and it would be great for you to build more confidence so that in those situations, you feel more confident being bold and standing up for what you believe is right.
2. Continue to push for outcomes and more outcomes - put points up on the scoreboard. Let that drive the work you do and push your team to do more!

**Matt O'Donnell:**
Thomas was a pleasure to work with, and he was always looking for ways to support those around him as they faced challenges. Although I didnâ€™t have the opportunity to problem solve with him on a specific project, I consistently saw his enthusiasm for tackling problems and thinking creatively. He brought others along in his process so they could share in the learning, which made his contributions even more impactful.

**Darius DeSpain:**
Tom is without a doubt an A-Player who embraces our company values and does what is required to create mission impact. While I've only had the opportunity to observe him since he joined the team about 3 weeks ago he's already making huge impacts and shows tons of potential for enabling our team to go further for mission impact.

**Damon Redding:**
Tom is not just a skilled practitioner, he excels in community, branding, leadership, and continuous learning. His ability to bring levity to the design practice while trusting his colleagues' agency and competencies makes working with him truly energizing. Even when tasks require extra effort, Tom's approach never feels burdensome. His style enhances our work environment. His experience and willingness to go the extra mile are testaments to his dedication and impact.

**Jeff Rodanski:**
I think you're doing great


</details>

---

## Question 12: Start/Stop/Keep Recommendations

### Synthesized Summary

**START:**
*[AI synthesis needed - invoke rise8-assessment-reviewer agent with START feedback]*

**STOP:**
*[AI synthesis needed - invoke rise8-assessment-reviewer agent with STOP feedback]*

**KEEP:**
*[AI synthesis needed - invoke rise8-assessment-reviewer agent with KEEP feedback]*

<details>
<summary>View Raw Start/Stop/Keep Feedback</summary>

**Mike Gehard:**
Keep: 
taking the charge on AI adoption on teams you work on. You passion was infectious and helped others come up the curve.




Start:
Documenting the learnings from your interactions and feeding them back into the process. You did a great job of getting people set up with white glove service but not many of the learnings made it back to the R&D team to help automate the process and making it easier for folks to self serve.

**Brian Jennings:**
Start: Asking peers for feedback as well if you are running an initiative - ask peers what they want to see/get out of it. See if your messaging is connecting with folks. Bring UX mindset to stuff you lead internally at Rise8 and validate your work.
Stop: (More of a warning) I love that you bring humor and play to work, that's a positive aspect! I would also be a bit guarded around when an audience would/wouldn't be receptive to that. I remember you making a joke in a town hall after Bryon had shared out something serious to the company. I knew you were trying to be sarcastic/funny but I'd be careful around the perception that gives off to others who may not know you well.
Keep: Pushing the bar for AI usage in design practices and leverage your ability to connect with people and make them feel at ease to help teach folks new skills. Also keep asking for feedback as you have been doing, it will serve you well in the long run!

**Matt O'Donnell:**
For next year, I would love to see him start thinking more deeply through problems and anticipating the guidance leadership might offer, then taking the initiative to implement that direction on his own. I donâ€™t have specific recommendations for what he should stop doing. For what he should keep doing, I strongly encourage him to continue helping others learn from his experience. This not only supports the team, but also strengthens his own understanding of how people can apply a particular skill set, which will help him communicate the practice even more effectively.

**Darius DeSpain:**
- start
   - Pair with Jen Ly to create UIs together live (when appropriate)
      - and generally trying to share Rise8 practices where you can
   - diving into more user workflow optimizations as we're building them out and refining/suggesting stories to close gaps (especially if your user research validates it). You're already sort of starting this, but you can dive in even more.
- stop
   - nothing I can think of
- keep doing
   - asking questions from different perspectives to help paint the full picture of user flows and mission impact
   - asking for feedback after any meaningful activity. It promotes this behavior within the team
   - supporting mission impact lines of effort like the VSM
   - offering to take on tasks that are burdening the devs (like the drumbeat). It frees up more time to work on features.

**Damon Redding:**
- Start:
   - Engage with Section 31 Designers: Your involvement could provide invaluable insights and mentorship, helping to elevate the team's design capabilities and fostering a stronger design culture.
- Stop:
   - Overextending Across Projects: While your contributions are highly valued, be mindful of spreading yourself too thin. 
- Continue:
   - Supporting Designers and Organization: Keep up the excellent work youâ€™re doing for our designers and the organization as a whole. Your leadership and support are crucial to our success, and your ability to inspire and guide others is a significant asset.

**Jeff Rodanski:**
Start looking for more opportunities to share/teach/advocate on how to use AI to add value to the design process
Stop (I dont have a stop for this 360)
Keep being a thought leader in AI-enabled design


</details>

---

## Report Metadata

- **Generated**: 2025-12-04 17:28:08
- **Script Version**: 1.0.0
- **Data Sources**:
  - Assessment File: `assessments/Design/Tom_Anastasio.md`
  - Team Mapping: `LatticeAPI/lattice_api_client/team_map.json`
  - Comprehensive Data: `docs/analysis-results/riser_data_detailed.csv`
  - Tier Assignments: `docs/analysis-results/tier_assignments.csv`
