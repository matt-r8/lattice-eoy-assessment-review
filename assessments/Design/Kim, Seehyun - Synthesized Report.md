# Seehyun Kim - Individual Assessment Report

## Employee Information
- **Name**: Seehyun Kim
- **Department**: Design
- **Level**: Senior Practitioner
- **Team**: Polaris
- **Project**: SSC/CGTM EM&C SATCOM (AP IDIQ)
- **Assessment Period**: 2025 EOY
- **Tier Assignment**: A- (A Player Baseline)

---

## Overall Scores

- **Peers Average**: 4.20 (based on 41 ratings)
- **Response Rate**: 4/4 peer reviewers (100%)
- **Self Average**: 4.00
- **Delta (Self - Peers)**: -0.20 ðŸŸ¢ (Humble)
- **Delta (Self - Level)**: -0.07 ðŸŸ¡ (Well-calibrated) (vs Level Average 4.07)
- **Delta (Self - Team)**: -0.04 ðŸŸ¡ (Well-calibrated) (vs Team Average 4.04)
- **Delta (Self - Department)**: -0.12 ðŸŸ¢ (Humble) (vs Department Average 4.12)
- **Delta (Self - Project)**: -0.21 ðŸŸ¢ (Humble) (vs Project Average 4.21)

---

## Accomplishments Review (Self-Assessment Question 13)

### Synthesized Summary

*[AI synthesis needed - invoke rise8-assessment-reviewer agent with accomplishments text]*

<details>
<summary>View Raw Accomplishments Text</summary>

**1. Delivering outcomes on an ambiguous EM&C project**
When I joined the team, the assigned project was ambiguous and not well-defined. Despite these challenges, our team delivered one Support Outcome and one User Outcome within three months. The previous PM and I contributed to shaping the work, ensuring alignment, and driving the team toward impact. This accomplishment not only demonstrated our ability to deliver in uncertain situations but also helped secure a follow-on project, the Narrowband project, extending our contribution to the EM&C enterprise.




**2. Supporting the PM transition and setup of the Narrowband project**
At the start of the Narrowband project, our previous PM left the company, creating a gap in Product leadership. I proactively supported the new PM by gathering critical information for the team and establishing stakeholder and user engagement processes. My efforts helped maintain momentum, enabled smooth project setup, and ensured continuity. 




**3. Building domain expertise and trust with SMEs and stakeholders**
I prioritized gaining deep domain knowledge, enabling me to communicate effectively with SMEs and users in their language. By demonstrating care and understanding of the problem space, I built trust and strengthened collaborative partnerships. This approach has resulted in recent positive feedback from both users and stakeholders, reinforcing confidence that the is headed in the right direction.

</details>

---

## Per-Question Breakdown

### Question 1: Be Bold

**Basic Scores:**
- **Peers Average**: 4.00 (based on 3 ratings)
- **Response Rate**: 3/4 peer reviewers (75%)
- **Self Score**: 3.0
- **Median Score**: 4.00

**Self-Awareness Deltas:**
- **Delta (Self - Peers)**: -1.00 ðŸŸ¢ (Humble)
- **Delta (Self - Level)**: -1.04 ðŸŸ¢ (Humble)
- **Delta (Self - Team)**: -0.88 ðŸŸ¢ (Humble)
- **Delta (Self - Department)**: -0.96 ðŸŸ¢ (Humble)
- **Delta (Self - Project)**: -1.13 ðŸŸ¢ (Humble)

**Performance Comparisons (Peer Avg vs Groups):**
- **vs Team Average**: +0.12 (Team avg: 3.88) - Above team
- **vs Project Average**: -0.13 (Project avg: 4.13) - Below project
- **vs Department Average**: +0.04 (Department avg: 3.96) - At department
- **vs Company Average**: -0.03 (Company avg: 4.03) - At company

**Statistical Analysis:**
- **Standard Deviation**: 0.82 (Mixed opinions)
- **Percentile Rank**: 46.8th percentile
- **Score Range**: 3.0 - 5.0 (spread: 2.0)

**Interpretation:**
- Scores in the **46th percentile** on Be Bold company-wide (top 53%)
- Peer average (4.00) is **-0.13 below project average**
- **Mixed opinions** among reviewers (SD: 0.82)
- Score range (3.0-5.0) shows notable variability in reviewer perceptions

### Question 2: Do The Right Thing

**Basic Scores:**
- **Peers Average**: 4.25 (based on 4 ratings)
- **Response Rate**: 4/4 peer reviewers (100%)
- **Self Score**: 4.0
- **Median Score**: 4.50

**Self-Awareness Deltas:**
- **Delta (Self - Peers)**: -0.25 ðŸŸ¢ (Humble)
- **Delta (Self - Level)**: -0.18 ðŸŸ¢ (Humble)
- **Delta (Self - Team)**: -0.11 ðŸŸ¢ (Humble)
- **Delta (Self - Department)**: -0.22 ðŸŸ¢ (Humble)
- **Delta (Self - Project)**: -0.31 ðŸŸ¢ (Humble)

**Performance Comparisons (Peer Avg vs Groups):**
- **vs Team Average**: +0.14 (Team avg: 4.11) - Above team
- **vs Project Average**: -0.06 (Project avg: 4.31) - Below project
- **vs Department Average**: +0.03 (Department avg: 4.22) - At department
- **vs Company Average**: +0.03 (Company avg: 4.22) - At company

**Statistical Analysis:**
- **Standard Deviation**: 0.83 (Mixed opinions)
- **Percentile Rank**: 50.0th percentile
- **Score Range**: 3.0 - 5.0 (spread: 2.0)

**Interpretation:**
- Scores in the **50th percentile** on Do The Right Thing company-wide (top 50%)
- Peer average (4.25) is **+0.14 above team average**
- **Mixed opinions** among reviewers (SD: 0.83)
- Score range (3.0-5.0) shows notable variability in reviewer perceptions

### Question 3: Do What Works

**Basic Scores:**
- **Peers Average**: 3.75 (based on 4 ratings)
- **Response Rate**: 4/4 peer reviewers (100%)
- **Self Score**: 5.0
- **Median Score**: 3.50

**Self-Awareness Deltas:**
- **Delta (Self - Peers)**: +1.25 ðŸ”´ (Overconfident)
- **Delta (Self - Level)**: +1.03 ðŸ”´ (Overconfident)
- **Delta (Self - Team)**: +1.19 ðŸ”´ (Overconfident)
- **Delta (Self - Department)**: +0.92 ðŸ”´ (Overconfident)
- **Delta (Self - Project)**: +1.04 ðŸ”´ (Overconfident)

**Performance Comparisons (Peer Avg vs Groups):**
- **vs Team Average**: -0.06 (Team avg: 3.81) - Below team
- **vs Project Average**: -0.21 (Project avg: 3.96) - Below project
- **vs Department Average**: -0.33 (Department avg: 4.08) - Below department
- **vs Company Average**: -0.22 (Company avg: 3.97) - Below company

**Statistical Analysis:**
- **Standard Deviation**: 0.83 (Mixed opinions)
- **Percentile Rank**: 32.5th percentile
- **Score Range**: 3.0 - 5.0 (spread: 2.0)

**Interpretation:**
- Scores in the **32th percentile** on Do What Works company-wide (top 68%)
- Peer average (3.75) is **-0.33 below department average**
- **Mixed opinions** among reviewers (SD: 0.83)
- Score range (3.0-5.0) shows notable variability in reviewer perceptions

### Question 4: Do What is Required

**Basic Scores:**
- **Peers Average**: 4.25 (based on 4 ratings)
- **Response Rate**: 4/4 peer reviewers (100%)
- **Self Score**: 3.0
- **Median Score**: 4.00

**Self-Awareness Deltas:**
- **Delta (Self - Peers)**: -1.25 ðŸŸ¢ (Humble)
- **Delta (Self - Level)**: -1.09 ðŸŸ¢ (Humble)
- **Delta (Self - Team)**: -0.93 ðŸŸ¢ (Humble)
- **Delta (Self - Department)**: -1.04 ðŸŸ¢ (Humble)
- **Delta (Self - Project)**: -1.09 ðŸŸ¢ (Humble)

**Performance Comparisons (Peer Avg vs Groups):**
- **vs Team Average**: +0.32 (Team avg: 3.93) - Above team
- **vs Project Average**: +0.16 (Project avg: 4.09) - Above project
- **vs Department Average**: +0.21 (Department avg: 4.04) - Above department
- **vs Company Average**: +0.15 (Company avg: 4.10) - Above company

**Statistical Analysis:**
- **Standard Deviation**: 0.43 (Moderate agreement)
- **Percentile Rank**: 61.6th percentile
- **Score Range**: 4.0 - 5.0 (spread: 1.0)

**Interpretation:**
- Scores in the **61th percentile** on Do What is Required company-wide (top 38%)
- Peer average (4.25) is **+0.32 above team average**
- **Moderate agreement** among reviewers (SD: 0.43)
- Score range (4.0-5.0) shows reasonable consistency in reviewer perceptions

### Question 5: Always Be Kind

**Basic Scores:**
- **Peers Average**: 4.50 (based on 4 ratings)
- **Response Rate**: 4/4 peer reviewers (100%)
- **Self Score**: 3.0
- **Median Score**: 5.00

**Self-Awareness Deltas:**
- **Delta (Self - Peers)**: -1.50 ðŸŸ¢ (Humble)
- **Delta (Self - Level)**: -1.11 ðŸŸ¢ (Humble)
- **Delta (Self - Team)**: -1.10 ðŸŸ¢ (Humble)
- **Delta (Self - Department)**: -1.18 ðŸŸ¢ (Humble)
- **Delta (Self - Project)**: -1.31 ðŸŸ¢ (Humble)

**Performance Comparisons (Peer Avg vs Groups):**
- **vs Team Average**: +0.40 (Team avg: 4.10) - Above team
- **vs Project Average**: +0.19 (Project avg: 4.31) - Above project
- **vs Department Average**: +0.32 (Department avg: 4.18) - Above department
- **vs Company Average**: +0.36 (Company avg: 4.14) - Above company

**Statistical Analysis:**
- **Standard Deviation**: 0.87 (Mixed opinions)
- **Percentile Rank**: 77.3th percentile
- **Score Range**: 3.0 - 5.0 (spread: 2.0)

**Interpretation:**
- Scores in the **77th percentile** on Always Be Kind company-wide (top 23%)
- Peer average (4.50) is **+0.40 above team average**
- **Mixed opinions** among reviewers (SD: 0.87)
- Score range (3.0-5.0) shows notable variability in reviewer perceptions

### Question 6: Keep it Real

**Basic Scores:**
- **Peers Average**: 3.75 (based on 4 ratings)
- **Response Rate**: 4/4 peer reviewers (100%)
- **Self Score**: 4.0
- **Median Score**: 4.00

**Self-Awareness Deltas:**
- **Delta (Self - Peers)**: +0.25 ðŸ”´ (Overconfident)
- **Delta (Self - Level)**: -0.17 ðŸŸ¢ (Humble)
- **Delta (Self - Team)**: +0.19 ðŸ”´ (Overconfident)
- **Delta (Self - Department)**: -0.09 ðŸŸ¡ (Well-calibrated)
- **Delta (Self - Project)**: -0.13 ðŸŸ¢ (Humble)

**Performance Comparisons (Peer Avg vs Groups):**
- **vs Team Average**: -0.06 (Team avg: 3.81) - Below team
- **vs Project Average**: -0.38 (Project avg: 4.13) - Below project
- **vs Department Average**: -0.34 (Department avg: 4.09) - Below department
- **vs Company Average**: -0.42 (Company avg: 4.17) - Below company

**Statistical Analysis:**
- **Standard Deviation**: 0.43 (Moderate agreement)
- **Percentile Rank**: 17.8th percentile
- **Score Range**: 3.0 - 4.0 (spread: 1.0)

**Interpretation:**
- Scores in the **17th percentile** on Keep it Real company-wide (top 82%)
- Peer average (3.75) is **-0.42 below company average**
- **Moderate agreement** among reviewers (SD: 0.43)
- Score range (3.0-4.0) shows reasonable consistency in reviewer perceptions

### Question 7: Outcomes in Production

**Basic Scores:**
- **Peers Average**: 3.67 (based on 3 ratings)
- **Response Rate**: 3/4 peer reviewers (75%)
- **Self Score**: 5.0
- **Median Score**: 4.00

**Self-Awareness Deltas:**
- **Delta (Self - Peers)**: +1.33 ðŸ”´ (Overconfident)
- **Delta (Self - Level)**: +1.02 ðŸ”´ (Overconfident)
- **Delta (Self - Team)**: +0.98 ðŸ”´ (Overconfident)
- **Delta (Self - Department)**: +1.02 ðŸ”´ (Overconfident)
- **Delta (Self - Project)**: +0.71 ðŸ”´ (Overconfident)

**Performance Comparisons (Peer Avg vs Groups):**
- **vs Team Average**: -0.35 (Team avg: 4.02) - Below team
- **vs Project Average**: -0.62 (Project avg: 4.29) - Below project
- **vs Department Average**: -0.32 (Department avg: 3.98) - Below department
- **vs Company Average**: -0.31 (Company avg: 3.98) - Below company

**Statistical Analysis:**
- **Standard Deviation**: 0.47 (Moderate agreement)
- **Percentile Rank**: 25.5th percentile
- **Score Range**: 3.0 - 4.0 (spread: 1.0)

**Interpretation:**
- Scores in the **25th percentile** on Outcomes in Production company-wide (top 74%)
- Peer average (3.67) is **-0.62 below project average**
- **Moderate agreement** among reviewers (SD: 0.47)
- Score range (3.0-4.0) shows reasonable consistency in reviewer perceptions

### Question 8: Grit

**Basic Scores:**
- **Peers Average**: 4.50 (based on 4 ratings)
- **Response Rate**: 4/4 peer reviewers (100%)
- **Self Score**: 5.0
- **Median Score**: 5.00

**Self-Awareness Deltas:**
- **Delta (Self - Peers)**: +0.50 ðŸ”´ (Overconfident)
- **Delta (Self - Level)**: +0.88 ðŸ”´ (Overconfident)
- **Delta (Self - Team)**: +0.95 ðŸ”´ (Overconfident)
- **Delta (Self - Department)**: +0.99 ðŸ”´ (Overconfident)
- **Delta (Self - Project)**: +0.82 ðŸ”´ (Overconfident)

**Performance Comparisons (Peer Avg vs Groups):**
- **vs Team Average**: +0.45 (Team avg: 4.05) - Above team
- **vs Project Average**: +0.32 (Project avg: 4.18) - Above project
- **vs Department Average**: +0.49 (Department avg: 4.01) - Above department
- **vs Company Average**: +0.34 (Company avg: 4.16) - Above company

**Statistical Analysis:**
- **Standard Deviation**: 0.87 (Mixed opinions)
- **Percentile Rank**: 73.8th percentile
- **Score Range**: 3.0 - 5.0 (spread: 2.0)

**Interpretation:**
- Scores in the **73th percentile** on Grit company-wide (top 26%)
- Peer average (4.50) is **+0.49 above department average**
- **Mixed opinions** among reviewers (SD: 0.87)
- Score range (3.0-5.0) shows notable variability in reviewer perceptions

### Question 9: Growth Mindset

**Basic Scores:**
- **Peers Average**: 4.50 (based on 4 ratings)
- **Response Rate**: 4/4 peer reviewers (100%)
- **Self Score**: 5.0
- **Median Score**: 4.50

**Self-Awareness Deltas:**
- **Delta (Self - Peers)**: +0.50 ðŸ”´ (Overconfident)
- **Delta (Self - Level)**: +0.86 ðŸ”´ (Overconfident)
- **Delta (Self - Team)**: +0.97 ðŸ”´ (Overconfident)
- **Delta (Self - Department)**: +0.79 ðŸ”´ (Overconfident)
- **Delta (Self - Project)**: +0.71 ðŸ”´ (Overconfident)

**Performance Comparisons (Peer Avg vs Groups):**
- **vs Team Average**: +0.47 (Team avg: 4.03) - Above team
- **vs Project Average**: +0.21 (Project avg: 4.29) - Above project
- **vs Department Average**: +0.29 (Department avg: 4.21) - Above department
- **vs Company Average**: +0.31 (Company avg: 4.19) - Above company

**Statistical Analysis:**
- **Standard Deviation**: 0.50 (Moderate agreement)
- **Percentile Rank**: 74.3th percentile
- **Score Range**: 4.0 - 5.0 (spread: 1.0)

**Interpretation:**
- Scores in the **74th percentile** on Growth Mindset company-wide (top 26%)
- Peer average (4.50) is **+0.47 above team average**
- **Moderate agreement** among reviewers (SD: 0.50)
- Score range (4.0-5.0) shows reasonable consistency in reviewer perceptions

### Question 10: No Unnecessary Rules

**Basic Scores:**
- **Peers Average**: 4.00 (based on 3 ratings)
- **Response Rate**: 3/4 peer reviewers (75%)
- **Self Score**: 3.0
- **Median Score**: 4.00

**Self-Awareness Deltas:**
- **Delta (Self - Peers)**: -1.00 ðŸŸ¢ (Humble)
- **Delta (Self - Level)**: -1.09 ðŸŸ¢ (Humble)
- **Delta (Self - Team)**: -1.13 ðŸŸ¢ (Humble)
- **Delta (Self - Department)**: -1.06 ðŸŸ¢ (Humble)
- **Delta (Self - Project)**: -1.23 ðŸŸ¢ (Humble)

**Performance Comparisons (Peer Avg vs Groups):**
- **vs Team Average**: -0.13 (Team avg: 4.13) - Below team
- **vs Project Average**: -0.23 (Project avg: 4.23) - Below project
- **vs Department Average**: -0.06 (Department avg: 4.06) - Below department
- **vs Company Average**: -0.11 (Company avg: 4.11) - Below company

**Statistical Analysis:**
- **Standard Deviation**: 0.82 (Mixed opinions)
- **Percentile Rank**: 39.5th percentile
- **Score Range**: 3.0 - 5.0 (spread: 2.0)

**Interpretation:**
- Scores in the **39th percentile** on No Unnecessary Rules company-wide (top 60%)
- Peer average (4.00) is **-0.23 below project average**
- **Mixed opinions** among reviewers (SD: 0.82)
- Score range (3.0-5.0) shows notable variability in reviewer perceptions

### Question 11: eNPS (Employee Net Promoter Score)

**Basic Scores:**
- **Peers Average**: 4.75 (based on 4 ratings)
- **Response Rate**: 4/4 peer reviewers (100%)
- **Self Score**: 4.0
- **Median Score**: 5.00

**Self-Awareness Deltas:**
- **Delta (Self - Peers)**: -0.75 ðŸŸ¢ (Humble)
- **Delta (Self - Level)**: -0.67 ðŸŸ¢ (Humble)
- **Delta (Self - Team)**: -0.67 ðŸŸ¢ (Humble)
- **Delta (Self - Department)**: -0.69 ðŸŸ¢ (Humble)
- **Delta (Self - Project)**: -0.77 ðŸŸ¢ (Humble)

**Performance Comparisons (Peer Avg vs Groups):**
- **vs Team Average**: +0.08 (Team avg: 4.67) - Above team
- **vs Project Average**: -0.02 (Project avg: 4.77) - At project
- **vs Department Average**: +0.06 (Department avg: 4.69) - Above department
- **vs Company Average**: +0.08 (Company avg: 4.67) - Above company

**Statistical Analysis:**
- **Standard Deviation**: 0.43 (Moderate agreement)
- **Percentile Rank**: 50.0th percentile
- **Score Range**: 4.0 - 5.0 (spread: 1.0)

**Interpretation:**
- Scores in the **50th percentile** on eNPS (Employee Net Promoter Score) company-wide (top 50%)
- Peer average (4.75) is **+0.08 above company average**
- **Moderate agreement** among reviewers (SD: 0.43)
- Score range (4.0-5.0) shows reasonable consistency in reviewer perceptions

---

## Question 11: eNPS - Peer Comments Summary

### Synthesized Summary

*[AI synthesis needed - invoke rise8-assessment-reviewer agent with eNPS comments]*

<details>
<summary>View Raw eNPS Comments</summary>

**Norman Sharpe:**
Seehyun is a "one-of-a-kind" hire who brings an A-Player mindset to every interaction. She operates at a level of talent as a designer and researcher that is rare to find. She consistently produces high quality artifacts such as Service Blueprints, Value Stream Maps, Design Studios, and Figma wireframes, that are immediately useful for our daily delivery and engineering decisions; she takes no shortcuts.




Beyond her outputs, her behavior is exemplary. She offers actionable feedback, remains patient during complex technical discussions, and proactively upskills in technical domains (specifically regarding Certificate Health and Event Monitoring). She achieves all of this while maintaining a great sense of humor and a positive presence on the team.

**Shubham Goel:**
Seehyun has been an incredible teammate and a strong strategic partner throughout our Narrowband work. Pairing with her is always pleasant, productive, and thought-provoking. She has been a key sounding board for product direction and helped get Narrowband off the ground with clarity and momentum. 




Iâ€™ve been consistently impressed by her ability to guide four distinct RSSC user groups through biweekly prototyping sessions while simultaneously balancing the broader design constraints of the EM&C ecosystem.




Her participation in the last Program Increment was also great - she helped lead discovery around the most important problem areas for Narrowband, ensuring we are focusing on outcomes that truly matter. She naturally strengthens relationships across the program, helping us build trust with KBR, the various RSSCs, and other vendors.




Seehyun is always available to pair, and she provides thoughtful feedback during demos, roadmap conversations, and facilitation sessions. She is an excellent facilitator who deeply understands user pain points and navigates complex problem spaces with empathy and precision. Her service blueprint was especially strong, demonstrating her ability to map a highly complex operational workflow in a way that both design and product could act on. Her design iterations are fast, responsive to feedback, and grounded in real operational needs.




Iâ€™d encourage Seehyun to occasionally deprioritize a lower-value workstream in order to increase overall product velocity across multiple epics rather than optimizing locally for one. Now that Narrowband is gaining maturity, her involvement in outcome refinement, experiment design, and helping us define which metrics we should collect will be very valuable. Overall, Seehyun is a thoughtful, user-centered, and highly impactful teammate who adds immense value to our work.

**Ben Adinata:**
I would enthusiastically rehire Seehyun. She does a great job balancing user needs, engineering constraints, and stakeholder requirements. As a designer, she speeds up our development by using reusable components and giving us clear specs, which stops us from guessing.




She acts like a true owner; a prime example was during our PM transition when she proactively filled the gap and helped onboard our new PM. She is approachable and practical, prioritizing getting results into prod over design perfection. She is willing to adapt her designs to fit our timeline. Also, her drive to learn is motivatingâ€”she picked up the project context quickly and is already looking into how AI can improve her workflow.

**Chris Wang:**
I would put Strongly Agree, but I feel like our team is too small for someone with your talents. I imagine there isn't enough design work at this level, and what you has been putting together would ultimately benefit a team at the portfolio level. The designs and maps show how our work fits into larger user flows. As well, much of the design that we see for Narrowband Mission Workup could be inferred from the implementation of Wideband Mission Workup.


</details>

---

## Question 12: Start/Stop/Keep Recommendations

### Synthesized Summary

**START:**
*[AI synthesis needed - invoke rise8-assessment-reviewer agent with START feedback]*

**STOP:**
*[AI synthesis needed - invoke rise8-assessment-reviewer agent with STOP feedback]*

**KEEP:**
*[AI synthesis needed - invoke rise8-assessment-reviewer agent with KEEP feedback]*

<details>
<summary>View Raw Start/Stop/Keep Feedback</summary>

**Norman Sharpe:**
**Keep Doing:**
- Keep setting the standard for high-fidelity artifacts. Your Service Blueprints and Value Stream Maps are foundational tools that the team relies on to understand the system and user domain.
- Keep bridging the gap between design and engineering. Your willingness to learn the technical details (like Certificate Health) allows you to design solutions that are grounded in reality, which is a massive asset to the team.
**Stop Doing:**
- Stop accepting silence as agreement. When you present, don't assume that a lack of questions means everyone is aligned.
**Start Doing:**
- Start voicing your perspective in larger forums even more. You sometimes remain quieter than expected during group discussions. Trust your instincts and voice your opinion earlier, even if it feels like you are interrupting.
- Start practicing "Active Validation" during presentations. Move away from binary checks like "Does this make sense?" (which usually get a default "yes"). Instead, use guided checkpoints with open-ended questions like, "What risks do you see in this flow?" or "How does this interpret our previous requirement?" to ensure the audience is truly tracking your logic.

**Shubham Goel:**
**Start:**
â€“ Engaging more in outcome refinement and experiment design as Narrowband matures; her perspective will help ensure our metrics and hypotheses are well-shaped.
â€“ Applying her strong user-empathy lens to help define what data and metrics we should collect to validate outcomes.




**Keep:**
â€“ Providing thoughtful, strategic product feedback and being a strong sounding board for roadmap and direction decisions.
â€“ Facilitating user sessions with calmness, empathy, and clarity especially across the four RSSCs.
â€“ Producing high-quality design work that incorporates feedback quickly and remains grounded in user pain points.
â€“ Positive relationships with KBR, RSSCs, and other vendors through collaboration and professionalism.
â€“ Leading structured discovery and turning complex workflows into digestible artifacts like the service blueprint.

**Ben Adinata:**
**Keep:** Please keep your designs clear and focused on user outcomes. It makes a huge difference in how fast we can build. I also really appreciate how you stepped up during the PM transitionâ€”keep that level of ownership. Finally, keep learning! Your drive to understand the project and explore new tools like AI is motivating.




**Start/Stop:** I've noticed you sometimes apologize for interrupting when you join our pairing sessions. Please stop apologizing! We are always available to help you. I want you to start feeling completely comfortable hopping into our pairing rooms anytime. You can even start scheduling dedicated time with us to pair if you need to. We are one team.

**Chris Wang:**
Start: Packaging your research for the long-term. You are doing an incredible job synthesizing user pains. The next step might be to package these insights as a "Future State" vision. This will give your hard work a life beyond our current project and establish you as a strategic voice for the entire portfolio.




Keep: Being diligent and persistent. I see you in so many meetings, engaging with users and stakeholders. It's clear you are "squeezing the lemon" to get every last bit of insight. I know that must be a grind and feel repetitive, but that hard work is a huge asset to the team.




Keep: Backing up every decision with evidence. Your ability to do primary research, synthesize the data, and connect it directly to design decisions is amazing. Your grasp of these details gives your work authority and makes our product better.




Keep: Trusting your design instincts. Please keep empathizing with the user and pushing for what's right, even when it seems like there's little room to innovate. 




Keep: Asking questions in the flow of conversation. I've noticed you've recently stopped saving all your questions for the end of meetings. This is a fantastic change. It helps us resolve issues in real-time, keeps the discussion moving, and makes our meetings much more efficient.




Stop: Apologizing for doing your job. No need to add phrases like "Sorry, just one more question" or "Sorry to take more time." Your questions show you are thinking deeply, and they are a critical part of the design process.


</details>

---

## Report Metadata

- **Generated**: 2025-12-04 17:28:08
- **Script Version**: 1.0.0
- **Data Sources**:
  - Assessment File: `assessments/Design/Seehyun_Kim.md`
  - Team Mapping: `LatticeAPI/lattice_api_client/team_map.json`
  - Comprehensive Data: `docs/analysis-results/riser_data_detailed.csv`
  - Tier Assignments: `docs/analysis-results/tier_assignments.csv`
