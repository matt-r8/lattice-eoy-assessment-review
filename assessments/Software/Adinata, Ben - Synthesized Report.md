# Ben Adinata - Individual Assessment Report

## Employee Information
- **Name**: Ben Adinata
- **Department**: Software
- **Level**: Practitioner III
- **Team**: Polaris
- **Project**: SSC/CGTM EM&C SATCOM (AP IDIQ)
- **Assessment Period**: 2025 EOY
- **Tier Assignment**: B (Developing)

---

## Overall Scores

- **Peers Average**: 4.15 (based on 54 ratings)
- **Response Rate**: 5/5 peer reviewers (100%)
- **Self Average**: 3.18
- **Delta (Self - Peers)**: -0.97 ðŸŸ¢ (Humble)
- **Delta (Self - Level)**: -0.82 ðŸŸ¢ (Humble) (vs Level Average 4.00)
- **Delta (Self - Team)**: -0.86 ðŸŸ¢ (Humble) (vs Team Average 4.04)
- **Delta (Self - Department)**: -0.79 ðŸŸ¢ (Humble) (vs Department Average 3.97)
- **Delta (Self - Project)**: -1.05 ðŸŸ¢ (Humble) (vs Project Average 4.23)

---

## Accomplishments Review (Self-Assessment Question 13)

### Synthesized Summary

*[AI synthesis needed - invoke rise8-assessment-reviewer agent with accomplishments text]*

<details>
<summary>View Raw Accomplishments Text</summary>

**1. Delivering Quickly and Gaining Client Trust** My team was tasked with building a certificate monitoring solution to prevent service outages. despite having zero experience with the required tech stack (Helm, Angular), I dove in, learned the architecture, and identified a key technical blocker regarding data access. I took the initiative to configure the Helm deployments, which unblocked the team and allowed us to deliver the full solution in just a few months. This early success directly built the client's trust in our capabilities and secured a larger project for the team.




**2. Learned to "Be Bold" to Improve Team Dynamics** As a new member, I found myself in a difficult pairing dynamic where I felt I had to walk on eggshells. My natural tendency was to avoid conflict, but I recognized this was hurting the team. I chose to "Be Bold" and initiated a one-on-one conversation to understand my teammate's perspective. This immediately cleared the air. We gained mutual understanding, and our pairing sessions transformed from tense to enjoyable and highly productive.




**3. Enhanced Team Workflow with a New E2E Solution** Our workflow was severely hindered by an unstable shared cloud E2E environment that took over 15 minutes to deploy and was prone to being overwritten. This allowed integration bugs to slip through to our dev environment, blocking our PM and Designer. I took ownership of this issue and built a local E2E testing solution that developers can launch in under 2 minutes. We now catch integration bugs before they merge, which protects our dev stability and unblocks our entire Acceptance Testing process.

</details>

---

## Per-Question Breakdown

### Question 1: Be Bold

**Basic Scores:**
- **Peers Average**: 3.60 (based on 5 ratings)
- **Response Rate**: 5/5 peer reviewers (100%)
- **Self Score**: 0.0
- **Median Score**: 4.00

**Self-Awareness Deltas:**
- **Delta (Self - Peers)**: -3.60 ðŸŸ¢ (Humble)
- **Delta (Self - Level)**: -3.83 ðŸŸ¢ (Humble)
- **Delta (Self - Team)**: -3.88 ðŸŸ¢ (Humble)
- **Delta (Self - Department)**: -3.84 ðŸŸ¢ (Humble)
- **Delta (Self - Project)**: -4.13 ðŸŸ¢ (Humble)

**Performance Comparisons (Peer Avg vs Groups):**
- **vs Team Average**: -0.28 (Team avg: 3.88) - Below team
- **vs Project Average**: -0.53 (Project avg: 4.13) - Below project
- **vs Department Average**: -0.24 (Department avg: 3.84) - Below department
- **vs Company Average**: -0.43 (Company avg: 4.03) - Below company

**Statistical Analysis:**
- **Standard Deviation**: 0.49 (Moderate agreement)
- **Percentile Rank**: 19.7th percentile
- **Score Range**: 3.0 - 4.0 (spread: 1.0)

**Interpretation:**
- Scores in the **19th percentile** on Be Bold company-wide (top 80%)
- Peer average (3.60) is **-0.53 below project average**
- **Moderate agreement** among reviewers (SD: 0.49)
- Score range (3.0-4.0) shows reasonable consistency in reviewer perceptions

### Question 2: Do The Right Thing

**Basic Scores:**
- **Peers Average**: 4.20 (based on 5 ratings)
- **Response Rate**: 5/5 peer reviewers (100%)
- **Self Score**: 3.0
- **Median Score**: 4.00

**Self-Awareness Deltas:**
- **Delta (Self - Peers)**: -1.20 ðŸŸ¢ (Humble)
- **Delta (Self - Level)**: -1.15 ðŸŸ¢ (Humble)
- **Delta (Self - Team)**: -1.11 ðŸŸ¢ (Humble)
- **Delta (Self - Department)**: -1.02 ðŸŸ¢ (Humble)
- **Delta (Self - Project)**: -1.31 ðŸŸ¢ (Humble)

**Performance Comparisons (Peer Avg vs Groups):**
- **vs Team Average**: +0.09 (Team avg: 4.11) - Above team
- **vs Project Average**: -0.11 (Project avg: 4.31) - Below project
- **vs Department Average**: +0.18 (Department avg: 4.02) - Above department
- **vs Company Average**: -0.02 (Company avg: 4.22) - At company

**Statistical Analysis:**
- **Standard Deviation**: 0.75 (Mixed opinions)
- **Percentile Rank**: 43.7th percentile
- **Score Range**: 3.0 - 5.0 (spread: 2.0)

**Interpretation:**
- Scores in the **43th percentile** on Do The Right Thing company-wide (top 56%)
- Peer average (4.20) is **+0.18 above department average**
- **Mixed opinions** among reviewers (SD: 0.75)
- Score range (3.0-5.0) shows notable variability in reviewer perceptions

### Question 3: Do What Works

**Basic Scores:**
- **Peers Average**: 3.60 (based on 5 ratings)
- **Response Rate**: 5/5 peer reviewers (100%)
- **Self Score**: 3.0
- **Median Score**: 3.00

**Self-Awareness Deltas:**
- **Delta (Self - Peers)**: -0.60 ðŸŸ¢ (Humble)
- **Delta (Self - Level)**: -0.79 ðŸŸ¢ (Humble)
- **Delta (Self - Team)**: -0.81 ðŸŸ¢ (Humble)
- **Delta (Self - Department)**: -0.74 ðŸŸ¢ (Humble)
- **Delta (Self - Project)**: -0.96 ðŸŸ¢ (Humble)

**Performance Comparisons (Peer Avg vs Groups):**
- **vs Team Average**: -0.21 (Team avg: 3.81) - Below team
- **vs Project Average**: -0.36 (Project avg: 3.96) - Below project
- **vs Department Average**: -0.14 (Department avg: 3.74) - Below department
- **vs Company Average**: -0.37 (Company avg: 3.97) - Below company

**Statistical Analysis:**
- **Standard Deviation**: 0.80 (Mixed opinions)
- **Percentile Rank**: 23.1th percentile
- **Score Range**: 3.0 - 5.0 (spread: 2.0)

**Interpretation:**
- Scores in the **23th percentile** on Do What Works company-wide (top 77%)
- Peer average (3.60) is **-0.37 below company average**
- **Mixed opinions** among reviewers (SD: 0.80)
- Score range (3.0-5.0) shows notable variability in reviewer perceptions

### Question 4: Do What is Required

**Basic Scores:**
- **Peers Average**: 4.20 (based on 5 ratings)
- **Response Rate**: 5/5 peer reviewers (100%)
- **Self Score**: 3.0
- **Median Score**: 4.00

**Self-Awareness Deltas:**
- **Delta (Self - Peers)**: -1.20 ðŸŸ¢ (Humble)
- **Delta (Self - Level)**: -1.03 ðŸŸ¢ (Humble)
- **Delta (Self - Team)**: -0.93 ðŸŸ¢ (Humble)
- **Delta (Self - Department)**: -0.95 ðŸŸ¢ (Humble)
- **Delta (Self - Project)**: -1.09 ðŸŸ¢ (Humble)

**Performance Comparisons (Peer Avg vs Groups):**
- **vs Team Average**: +0.27 (Team avg: 3.93) - Above team
- **vs Project Average**: +0.11 (Project avg: 4.09) - Above project
- **vs Department Average**: +0.25 (Department avg: 3.95) - Above department
- **vs Company Average**: +0.10 (Company avg: 4.10) - Above company

**Statistical Analysis:**
- **Standard Deviation**: 0.40 (Moderate agreement)
- **Percentile Rank**: 57.4th percentile
- **Score Range**: 4.0 - 5.0 (spread: 1.0)

**Interpretation:**
- Scores in the **57th percentile** on Do What is Required company-wide (top 43%)
- Peer average (4.20) is **+0.27 above team average**
- **Moderate agreement** among reviewers (SD: 0.40)
- Score range (4.0-5.0) shows reasonable consistency in reviewer perceptions

### Question 5: Always Be Kind

**Basic Scores:**
- **Peers Average**: 4.40 (based on 5 ratings)
- **Response Rate**: 5/5 peer reviewers (100%)
- **Self Score**: 3.0
- **Median Score**: 4.00

**Self-Awareness Deltas:**
- **Delta (Self - Peers)**: -1.40 ðŸŸ¢ (Humble)
- **Delta (Self - Level)**: -1.11 ðŸŸ¢ (Humble)
- **Delta (Self - Team)**: -1.10 ðŸŸ¢ (Humble)
- **Delta (Self - Department)**: -0.94 ðŸŸ¢ (Humble)
- **Delta (Self - Project)**: -1.31 ðŸŸ¢ (Humble)

**Performance Comparisons (Peer Avg vs Groups):**
- **vs Team Average**: +0.30 (Team avg: 4.10) - Above team
- **vs Project Average**: +0.09 (Project avg: 4.31) - Above project
- **vs Department Average**: +0.46 (Department avg: 3.94) - Above department
- **vs Company Average**: +0.26 (Company avg: 4.14) - Above company

**Statistical Analysis:**
- **Standard Deviation**: 0.49 (Moderate agreement)
- **Percentile Rank**: 70.3th percentile
- **Score Range**: 4.0 - 5.0 (spread: 1.0)

**Interpretation:**
- Scores in the **70th percentile** on Always Be Kind company-wide (top 30%)
- Peer average (4.40) is **+0.46 above department average**
- **Moderate agreement** among reviewers (SD: 0.49)
- Score range (4.0-5.0) shows reasonable consistency in reviewer perceptions

### Question 6: Keep it Real

**Basic Scores:**
- **Peers Average**: 3.60 (based on 5 ratings)
- **Response Rate**: 5/5 peer reviewers (100%)
- **Self Score**: 3.0
- **Median Score**: 4.00

**Self-Awareness Deltas:**
- **Delta (Self - Peers)**: -0.60 ðŸŸ¢ (Humble)
- **Delta (Self - Level)**: -1.11 ðŸŸ¢ (Humble)
- **Delta (Self - Team)**: -0.81 ðŸŸ¢ (Humble)
- **Delta (Self - Department)**: -0.97 ðŸŸ¢ (Humble)
- **Delta (Self - Project)**: -1.13 ðŸŸ¢ (Humble)

**Performance Comparisons (Peer Avg vs Groups):**
- **vs Team Average**: -0.21 (Team avg: 3.81) - Below team
- **vs Project Average**: -0.53 (Project avg: 4.13) - Below project
- **vs Department Average**: -0.37 (Department avg: 3.97) - Below department
- **vs Company Average**: -0.57 (Company avg: 4.17) - Below company

**Statistical Analysis:**
- **Standard Deviation**: 0.49 (Moderate agreement)
- **Percentile Rank**: 12.2th percentile
- **Score Range**: 3.0 - 4.0 (spread: 1.0)

**Interpretation:**
- Scores in the **12th percentile** on Keep it Real company-wide (top 88%)
- Peer average (3.60) is **-0.57 below company average**
- **Moderate agreement** among reviewers (SD: 0.49)
- Score range (3.0-4.0) shows reasonable consistency in reviewer perceptions

### Question 7: Outcomes in Production

**Basic Scores:**
- **Peers Average**: 4.25 (based on 4 ratings)
- **Response Rate**: 4/5 peer reviewers (80%)
- **Self Score**: 3.0
- **Median Score**: 4.00

**Self-Awareness Deltas:**
- **Delta (Self - Peers)**: -1.25 ðŸŸ¢ (Humble)
- **Delta (Self - Level)**: -0.89 ðŸŸ¢ (Humble)
- **Delta (Self - Team)**: -1.02 ðŸŸ¢ (Humble)
- **Delta (Self - Department)**: -0.92 ðŸŸ¢ (Humble)
- **Delta (Self - Project)**: -1.29 ðŸŸ¢ (Humble)

**Performance Comparisons (Peer Avg vs Groups):**
- **vs Team Average**: +0.23 (Team avg: 4.02) - Above team
- **vs Project Average**: -0.04 (Project avg: 4.29) - At project
- **vs Department Average**: +0.33 (Department avg: 3.92) - Above department
- **vs Company Average**: +0.27 (Company avg: 3.98) - Above company

**Statistical Analysis:**
- **Standard Deviation**: 0.43 (Moderate agreement)
- **Percentile Rank**: 70.6th percentile
- **Score Range**: 4.0 - 5.0 (spread: 1.0)

**Interpretation:**
- Scores in the **70th percentile** on Outcomes in Production company-wide (top 29%)
- Peer average (4.25) is **+0.33 above department average**
- **Moderate agreement** among reviewers (SD: 0.43)
- Score range (4.0-5.0) shows reasonable consistency in reviewer perceptions

### Question 8: Grit

**Basic Scores:**
- **Peers Average**: 4.60 (based on 5 ratings)
- **Response Rate**: 5/5 peer reviewers (100%)
- **Self Score**: 3.0
- **Median Score**: 5.00

**Self-Awareness Deltas:**
- **Delta (Self - Peers)**: -1.60 ðŸŸ¢ (Humble)
- **Delta (Self - Level)**: -1.04 ðŸŸ¢ (Humble)
- **Delta (Self - Team)**: -1.05 ðŸŸ¢ (Humble)
- **Delta (Self - Department)**: -1.05 ðŸŸ¢ (Humble)
- **Delta (Self - Project)**: -1.18 ðŸŸ¢ (Humble)

**Performance Comparisons (Peer Avg vs Groups):**
- **vs Team Average**: +0.55 (Team avg: 4.05) - Above team
- **vs Project Average**: +0.42 (Project avg: 4.18) - Above project
- **vs Department Average**: +0.55 (Department avg: 4.05) - Above department
- **vs Company Average**: +0.44 (Company avg: 4.16) - Above company

**Statistical Analysis:**
- **Standard Deviation**: 0.49 (Moderate agreement)
- **Percentile Rank**: 83.2th percentile
- **Score Range**: 4.0 - 5.0 (spread: 1.0)

**Interpretation:**
- Scores in the **83th percentile** on Grit company-wide (top 17%)
- Peer average (4.60) is **+0.55 above department average**
- **Moderate agreement** among reviewers (SD: 0.49)
- Score range (4.0-5.0) shows reasonable consistency in reviewer perceptions

### Question 9: Growth Mindset

**Basic Scores:**
- **Peers Average**: 4.40 (based on 5 ratings)
- **Response Rate**: 5/5 peer reviewers (100%)
- **Self Score**: 4.0
- **Median Score**: 4.00

**Self-Awareness Deltas:**
- **Delta (Self - Peers)**: -0.40 ðŸŸ¢ (Humble)
- **Delta (Self - Level)**: -0.16 ðŸŸ¢ (Humble)
- **Delta (Self - Team)**: -0.03 ðŸŸ¡ (Well-calibrated)
- **Delta (Self - Department)**: -0.07 ðŸŸ¡ (Well-calibrated)
- **Delta (Self - Project)**: -0.29 ðŸŸ¢ (Humble)

**Performance Comparisons (Peer Avg vs Groups):**
- **vs Team Average**: +0.37 (Team avg: 4.03) - Above team
- **vs Project Average**: +0.11 (Project avg: 4.29) - Above project
- **vs Department Average**: +0.33 (Department avg: 4.07) - Above department
- **vs Company Average**: +0.21 (Company avg: 4.19) - Above company

**Statistical Analysis:**
- **Standard Deviation**: 0.49 (Moderate agreement)
- **Percentile Rank**: 60.4th percentile
- **Score Range**: 4.0 - 5.0 (spread: 1.0)

**Interpretation:**
- Scores in the **60th percentile** on Growth Mindset company-wide (top 40%)
- Peer average (4.40) is **+0.37 above team average**
- **Moderate agreement** among reviewers (SD: 0.49)
- Score range (4.0-5.0) shows reasonable consistency in reviewer perceptions

### Question 10: No Unnecessary Rules

**Basic Scores:**
- **Peers Average**: 4.00 (based on 5 ratings)
- **Response Rate**: 5/5 peer reviewers (100%)
- **Self Score**: 3.0
- **Median Score**: 4.00

**Self-Awareness Deltas:**
- **Delta (Self - Peers)**: -1.00 ðŸŸ¢ (Humble)
- **Delta (Self - Level)**: -1.03 ðŸŸ¢ (Humble)
- **Delta (Self - Team)**: -1.13 ðŸŸ¢ (Humble)
- **Delta (Self - Department)**: -0.98 ðŸŸ¢ (Humble)
- **Delta (Self - Project)**: -1.23 ðŸŸ¢ (Humble)

**Performance Comparisons (Peer Avg vs Groups):**
- **vs Team Average**: -0.13 (Team avg: 4.13) - Below team
- **vs Project Average**: -0.23 (Project avg: 4.23) - Below project
- **vs Department Average**: +0.02 (Department avg: 3.98) - At department
- **vs Company Average**: -0.11 (Company avg: 4.11) - Below company

**Statistical Analysis:**
- **Standard Deviation**: 0.00 (High consensus)
- **Percentile Rank**: 39.5th percentile
- **Score Range**: 4.0 - 4.0 (spread: 0.0)

*Perfect consensus - all reviewers gave identical scores*

### Question 11: eNPS (Employee Net Promoter Score)

**Basic Scores:**
- **Peers Average**: 4.80 (based on 5 ratings)
- **Response Rate**: 5/5 peer reviewers (100%)
- **Self Score**: 5.0
- **Median Score**: 5.00

**Self-Awareness Deltas:**
- **Delta (Self - Peers)**: +0.20 ðŸ”´ (Overconfident)
- **Delta (Self - Level)**: +0.40 ðŸ”´ (Overconfident)
- **Delta (Self - Team)**: +0.33 ðŸ”´ (Overconfident)
- **Delta (Self - Department)**: +0.38 ðŸ”´ (Overconfident)
- **Delta (Self - Project)**: +0.23 ðŸ”´ (Overconfident)

**Performance Comparisons (Peer Avg vs Groups):**
- **vs Team Average**: +0.12 (Team avg: 4.67) - Above team
- **vs Project Average**: +0.03 (Project avg: 4.77) - At project
- **vs Department Average**: +0.18 (Department avg: 4.62) - Above department
- **vs Company Average**: +0.13 (Company avg: 4.67) - Above company

**Statistical Analysis:**
- **Standard Deviation**: 0.40 (Moderate agreement)
- **Percentile Rank**: 58.3th percentile
- **Score Range**: 4.0 - 5.0 (spread: 1.0)

**Interpretation:**
- Scores in the **58th percentile** on eNPS (Employee Net Promoter Score) company-wide (top 42%)
- Peer average (4.80) is **+0.18 above department average**
- **Moderate agreement** among reviewers (SD: 0.40)
- Score range (4.0-5.0) shows reasonable consistency in reviewer perceptions

---

## Question 11: eNPS - Peer Comments Summary

### Synthesized Summary

*[AI synthesis needed - invoke rise8-assessment-reviewer agent with eNPS comments]*

<details>
<summary>View Raw eNPS Comments</summary>

**Drew Fugate:**
Yes, I would enthusiastically rehire Ben based on his strong engineering practices and highly collaborative nature.
- **Engineering Excellence & Initiative:** They produce high-quality, thoroughly tested code and have skillfully embraced AI-assisted development to improve both the speed and quality of our work. A prime example of their impact is the shared local testing solution they created. They identified a team bottleneck (waiting on the enterprise pipeline) and built a solution to integrate our frontend and backend services with our local databases, which has significantly improved our team's feedback loop. Instead of relying completely on API interceptors that return mock data, we can actually test our entire application interactions locally.
- **Collaboration & Team Health:** They are an excellent collaborator and pairing partner, proactively sharing knowledge and ensuring their partners feel valued. I've seen them handle technical disagreements by focusing objectively on pros and cons, not by ego or otherwise doubling down on their own ideals. They also give clear, concise, and immediate feedback during code reviews, which helps maintain our team's high standard of quality.
- **Delivery Focus:** When they take on a story, they see it through to completion, implementing the simplest solution first and ensuring it has adequate test coverage before moving on without overcomplicating things.

**Chris Wang:**
Ben is the MVP of our team. He goes above and beyond to deliver not just on stories but on improvements that  improve the ease and efficiency of our engineering in general. Recent examples: creating a mechanism so that we can test our work locally, instead of having to deploy through the pipeline; refactoring our mappers from a single monolithic mapper into component pieces that are more easily managed and understood.

**Norman Sharpe:**
Ben is has been an excellent hire for Rise8, and I have **zero hesitation recommending him** for any team that requires hard work. He is always kind, listening and understanding, patient, and observant. He is very quick to learn new skills, coming from a much more low level engineering background, he uses his foundational CS knowledge to fill in the gaps on web development to include learning Go, python, java, javascript, SQL, and k8s, all while keeping pace with his peers who've had much more experience in this area. He actively volunteers for hard tasks, and completes his tasks without compromise. His work ethic is that of an A-Player.

**Seehyun Kim:**
I would love to be on the same team with Ben because he is accountable, reliable, consistent, and thoughtful,  qualities that are truly invaluable. As a skilled collaborator, he delivers solid work while asking insightful questions, such as those around change request SARs, that encourage the team to consider multiple perspectives and make stronger decisions. His approachable and easygoing nature makes him a pleasure to work with, and his steady contributions create a positive, supportive, and collaborative team environment.

**Shubham Goel:**
Ben has been a great teammate this year. He  brings a positive, collaborative presence and sharp technical insight that elevates the teamâ€™s work. He speaks up with thoughtful, technical feedback such as identifying redundancies in our upload toast messaging during a Pre-IPM and always offers perspectives that strengthen product decisions. 




Ben  volunteered to join product and design for PI planning, demonstrating initiative and ownership beyond his core responsibilities. His contributions to Narrowband discovery have been impactful; he centers the team around the SAR data we have, provides  implementation feedback, and helps shape well-structured acceptance test stories. Ben is always available to pair and dependable during Pre-IPM, where he provides accurate sizing and strong technical reasoning. 




When our Gather pairing space went away, he immediately stepped up to create new Google Meet pairing rooms, ensuring continuity for the team. Ben has an acute and articulate viewpoint on technical challenges, and his insights  help validate and refine product direction. 




Iâ€™d encourage him to continue being the  implementer he already is while leaning even more into sharing his long-term strategic thinking for outcomes; his perspective has real influence and will be critical as we size and plan future Narrowband work streams. Overall, Ben is a solid asset to the team, and I trust and enjoy working with him.


</details>

---

## Question 12: Start/Stop/Keep Recommendations

### Synthesized Summary

**START:**
*[AI synthesis needed - invoke rise8-assessment-reviewer agent with START feedback]*

**STOP:**
*[AI synthesis needed - invoke rise8-assessment-reviewer agent with STOP feedback]*

**KEEP:**
*[AI synthesis needed - invoke rise8-assessment-reviewer agent with KEEP feedback]*

<details>
<summary>View Raw Start/Stop/Keep Feedback</summary>

**Drew Fugate:**
- **Keep:** Keep being such a strong collaborator and pairing partner. Your ability to rapidly develop high-quality, thouroughly tested code while maintaining clear communication is a huge asset to the team. I also want you to keep that proactive, "outside-the-box" mindset that led you to build our new local testing solution, it's incredibly valuable.
- **Start:** I would like to see you start taking a more active role in *shaping* our work. This has two parts:
   1. **Product Focus:** Before implementing, start by validating the "why" behind the acceptance criteria. If a design or requirement doesn't seem to provide clear user value, I encourage you to proactively pull in the PM and Designer for clarification. This will help shift your focus from just *completing tickets* to *driving outcomes*.
   2. **Ritual Engagement:** Start speaking up more in our team rituals. Your technical insights are excellent, and the team would benefit from hearing your perspective more often during planning, refinements, and retros.
- **Stop:** This is more of a "start less" to enable the point above. I would recommend you stop holding back your questions and insights in group settings. Often, a select few people can guide the conversation, but your voice is needed to ensure we're making the best decisions. Don't wait to be asked, your perspective is key!

**Chris Wang:**
Start: Thinking and serving as an anchor. Identify risks and opportunities that could impact team success. What kinds of support or information would benefit product and design? Bring to mind the perspectives of customer success, desired mission/business impact, and Rise8 goals, and from that lens speak up about engineering concerns, risks, opportunities.




Start: Setting and voicing your boundaries. Work ethic is important, but it's just as important to protect your time and focus. If you're getting unsolicited advice or feedback that isn't helpful, it's perfectly OK (and healthy!) to say something like, "Thank you for looking out for me, but I'm good."




Keep: Being the team's MVP. Your work consistently goes above and beyond. When you do things like create a mechanism for local testing or refactor our mappers, you're improving the ease and efficiency of the entire team.




Keep: Your deep, thoughtful approach to systemic improvements. You don't just solve the story in front of you; you think about how to make the circumstances of our work better. This "platform" mindset is rare and incredibly valuable.




Stop: Working so much "off-screen" when pairing. This is a "hero mentality" trait and an anti-goal for pairing; not only does it rob the team of the chance to learn from you, your pair will notice the change in the level of engagement.

**Norman Sharpe:**
**Keep Doing:**
- Keep volunteering for the complex, highly technical tasks. Your ability to rapidly learn new stacks (Go, K8s, Java, and Javascript/Angular) and immediately apply them is valuable behavior for a software engineer.
- Keep being a patient and observant teammate. Your kindness makes you approachable, which is a critical anchor for the team culture.
**Stop Doing:**
- Stop going "rogue" or silent during pair programming sessions. This is mostly a problem when you are driving, and I recommend that you communicate more of your thought process.
**Start Doing:**
- Start/keep taking visible ownership of specific technical domains (like the K8s or Angular). You have the skills to be a Subject Matter Expert, and I want to see you step into that leadership space more confidently.
- Start/keep initiating technical discussions rather than just responding to them. Your background gives you a unique perspective. Be the one to suggest the architectural improvement or the optimization (just like the local ui network mocking toggle solution, but for domain/business problems).

**Seehyun Kim:**
- Keep speaking up and sharing your perspectives, as your insights consistently add value to the teamâ€™s understanding and decision-making.
- Keep providing active feedback, whether through acknowledgments in chat, responses in meetings, or 1:1 conversations, in a kind and thoughtful way. This approach truly strengthens the team and helps enhance internal collaboration and alignment.

**Shubham Goel:**
**Start:**
â€“ Sharing more of his strategic thinking in the process. Ben has a strong product and technical mind, and voicing that perspective more proactively would help the team shape direction sooner.
â€“ Leading more technical sizing discussions, especially for future Narrowband workstreams where his depth of knowledge is highly valuable.
-Facilitating retro to help get some more reps in facilitation




**Keep:**
â€“ Bringing thoughtful, high-quality implementation feedback that improves product decisions.
â€“ Being available to pair, collaborate, and support the team with positivity and clarity.
â€“ Providing accurate sizing and clear technical reasoning during Pre-IPM and IPM.
â€“ Staying grounded in data (like SAR inputs) and ensuring technical decisions map to realistic constraints and outcomes.
â€“ Maintaining the same pleasant, dependable, and solution-oriented energy that makes him a strong teammate.


</details>

---

## Report Metadata

- **Generated**: 2025-12-04 17:47:59
- **Script Version**: 1.0.0
- **Data Sources**:
  - Assessment File: `assessments/Software/Ben_Adinata.md`
  - Team Mapping: `LatticeAPI/lattice_api_client/team_map.json`
  - Comprehensive Data: `docs/analysis-results/riser_data_detailed.csv`
  - Tier Assignments: `docs/analysis-results/tier_assignments.csv`
