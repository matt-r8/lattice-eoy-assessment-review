# Drew Fugate - Individual Assessment Report

## Employee Information
- **Name**: Drew Fugate
- **Department**: Software
- **Level**: Practitioner III
- **Team**: Polaris
- **Project**: SSC/CGTM EM&C SATCOM (AP IDIQ)
- **Assessment Period**: 2025 EOY
- **Tier Assignment**: C (Needs Immediate Improvement)

---

## Overall Scores

- **Peers Average**: 3.88 (based on 51 ratings)
- **Response Rate**: 5/5 peer reviewers (100%)
- **Self Average**: 4.00
- **Delta (Self - Peers)**: +0.12 ðŸ”´ (Overconfident)
- **Delta (Self - Level)**: +0.00 ðŸŸ¡ (Well-calibrated) (vs Level Average 4.00)
- **Delta (Self - Team)**: -0.04 ðŸŸ¡ (Well-calibrated) (vs Team Average 4.04)
- **Delta (Self - Department)**: +0.03 ðŸŸ¡ (Well-calibrated) (vs Department Average 3.97)
- **Delta (Self - Project)**: -0.23 ðŸŸ¢ (Humble) (vs Project Average 4.23)

---

## Accomplishments Review (Self-Assessment Question 13)

### Synthesized Summary

*[AI synthesis needed - invoke rise8-assessment-reviewer agent with accomplishments text]*

<details>
<summary>View Raw Accomplishments Text</summary>

In response to direct user feedback on the MOSS app, I investigated and resolved a major performance bottleneck by reducing the app's bundle size by ~70% and average API call size by ~80%. This cut the first meaningful paint time from 3.4 seconds down to 0.4 seconds, which in turn fostered trust with our users and led to a more complete adoption of the application, ensuring the mission value we were building was not undermined by a poor user experience.




Our team pioneered and scaled the integration of AI within our XP framework, aligning with Rise8's stance on being ahead of the game with using AI to boost productivity. I helped drive this by first incorporating it into my own TDD workflow for refactoring complex logic, which improved our code's stability. I then worked to scale this by proactively scheduling 1:1s with our designer and PM on Polaris, helping them integrate AI into their own daily workflows. This collaboration is evolving into sort of a â€œdesigner + engineer pairing" ritual and helped uplift the entire team's skills and velocity.




I was a key driver in delivering high-value outcomes for the 15th SPSS, which was part of a highly productive period where our MOSS team delivered 12 distinct outcomes in production from January to July. This contribution was a massive driver of Rise8's mission, accounting for nearly one-third (31.6%) of the entire company's 38 outcomes for the first half of the year. My primary focus this year was delivering the Daily Status Report (DSR) and shift schedule integration. I worked closely with users, including an off-site visit, to solve one of their biggest pain points by integrating their convoluted, manual data-entry process directly into the MOSS application. This specific outcome saved operators time, reduced errors, and directly improved mission capabilities, while also enabling data collection for a stakeholder dashboard that will help leadership prioritize Rise8 for future contracts.

</details>

---

## Per-Question Breakdown

### Question 1: Be Bold

**Basic Scores:**
- **Peers Average**: 3.67 (based on 3 ratings)
- **Response Rate**: 3/5 peer reviewers (60%)
- **Self Score**: 4.0
- **Median Score**: 4.00

**Self-Awareness Deltas:**
- **Delta (Self - Peers)**: +0.33 ðŸ”´ (Overconfident)
- **Delta (Self - Level)**: +0.17 ðŸ”´ (Overconfident)
- **Delta (Self - Team)**: +0.12 ðŸ”´ (Overconfident)
- **Delta (Self - Department)**: +0.16 ðŸ”´ (Overconfident)
- **Delta (Self - Project)**: -0.13 ðŸŸ¢ (Humble)

**Performance Comparisons (Peer Avg vs Groups):**
- **vs Team Average**: -0.21 (Team avg: 3.88) - Below team
- **vs Project Average**: -0.46 (Project avg: 4.13) - Below project
- **vs Department Average**: -0.17 (Department avg: 3.84) - Below department
- **vs Company Average**: -0.36 (Company avg: 4.03) - Below company

**Statistical Analysis:**
- **Standard Deviation**: 0.47 (Moderate agreement)
- **Percentile Rank**: 22.5th percentile
- **Score Range**: 3.0 - 4.0 (spread: 1.0)

**Interpretation:**
- Scores in the **22th percentile** on Be Bold company-wide (top 78%)
- Peer average (3.67) is **-0.46 below project average**
- **Moderate agreement** among reviewers (SD: 0.47)
- Score range (3.0-4.0) shows reasonable consistency in reviewer perceptions

### Question 2: Do The Right Thing

**Basic Scores:**
- **Peers Average**: 4.00 (based on 5 ratings)
- **Response Rate**: 5/5 peer reviewers (100%)
- **Self Score**: 4.0
- **Median Score**: 4.00

**Self-Awareness Deltas:**
- **Delta (Self - Peers)**: +0.00 ðŸŸ¡ (Well-calibrated)
- **Delta (Self - Level)**: -0.15 ðŸŸ¢ (Humble)
- **Delta (Self - Team)**: -0.11 ðŸŸ¢ (Humble)
- **Delta (Self - Department)**: -0.02 ðŸŸ¡ (Well-calibrated)
- **Delta (Self - Project)**: -0.31 ðŸŸ¢ (Humble)

**Performance Comparisons (Peer Avg vs Groups):**
- **vs Team Average**: -0.11 (Team avg: 4.11) - Below team
- **vs Project Average**: -0.31 (Project avg: 4.31) - Below project
- **vs Department Average**: -0.02 (Department avg: 4.02) - At department
- **vs Company Average**: -0.22 (Company avg: 4.22) - Below company

**Statistical Analysis:**
- **Standard Deviation**: 0.63 (Mixed opinions)
- **Percentile Rank**: 29.7th percentile
- **Score Range**: 3.0 - 5.0 (spread: 2.0)

**Interpretation:**
- Scores in the **29th percentile** on Do The Right Thing company-wide (top 70%)
- Peer average (4.00) is **-0.31 below project average**
- **Mixed opinions** among reviewers (SD: 0.63)
- Score range (3.0-5.0) shows notable variability in reviewer perceptions

### Question 3: Do What Works

**Basic Scores:**
- **Peers Average**: 3.50 (based on 4 ratings)
- **Response Rate**: 4/5 peer reviewers (80%)
- **Self Score**: 4.0
- **Median Score**: 3.50

**Self-Awareness Deltas:**
- **Delta (Self - Peers)**: +0.50 ðŸ”´ (Overconfident)
- **Delta (Self - Level)**: +0.21 ðŸ”´ (Overconfident)
- **Delta (Self - Team)**: +0.19 ðŸ”´ (Overconfident)
- **Delta (Self - Department)**: +0.26 ðŸ”´ (Overconfident)
- **Delta (Self - Project)**: +0.04 ðŸŸ¡ (Well-calibrated)

**Performance Comparisons (Peer Avg vs Groups):**
- **vs Team Average**: -0.31 (Team avg: 3.81) - Below team
- **vs Project Average**: -0.46 (Project avg: 3.96) - Below project
- **vs Department Average**: -0.24 (Department avg: 3.74) - Below department
- **vs Company Average**: -0.47 (Company avg: 3.97) - Below company

**Statistical Analysis:**
- **Standard Deviation**: 0.50 (Moderate agreement)
- **Percentile Rank**: 16.4th percentile
- **Score Range**: 3.0 - 4.0 (spread: 1.0)

**Interpretation:**
- Scores in the **16th percentile** on Do What Works company-wide (top 84%)
- Peer average (3.50) is **-0.47 below company average**
- **Moderate agreement** among reviewers (SD: 0.50)
- Score range (3.0-4.0) shows reasonable consistency in reviewer perceptions

### Question 4: Do What is Required

**Basic Scores:**
- **Peers Average**: 3.40 (based on 5 ratings)
- **Response Rate**: 5/5 peer reviewers (100%)
- **Self Score**: 4.0
- **Median Score**: 3.00

**Self-Awareness Deltas:**
- **Delta (Self - Peers)**: +0.60 ðŸ”´ (Overconfident)
- **Delta (Self - Level)**: -0.03 ðŸŸ¡ (Well-calibrated)
- **Delta (Self - Team)**: +0.07 ðŸŸ¡ (Well-calibrated)
- **Delta (Self - Department)**: +0.05 ðŸŸ¡ (Well-calibrated)
- **Delta (Self - Project)**: -0.09 ðŸŸ¡ (Well-calibrated)

**Performance Comparisons (Peer Avg vs Groups):**
- **vs Team Average**: -0.53 (Team avg: 3.93) - Below team
- **vs Project Average**: -0.69 (Project avg: 4.09) - Below project
- **vs Department Average**: -0.55 (Department avg: 3.95) - Below department
- **vs Company Average**: -0.70 (Company avg: 4.10) - Below company

**Statistical Analysis:**
- **Standard Deviation**: 0.49 (Moderate agreement)
- **Percentile Rank**: 11.3th percentile
- **Score Range**: 3.0 - 4.0 (spread: 1.0)

**Interpretation:**
- Scores in the **11th percentile** on Do What is Required company-wide (top 89%)
- Peer average (3.40) is **-0.70 below company average**
- **Moderate agreement** among reviewers (SD: 0.49)
- Score range (3.0-4.0) shows reasonable consistency in reviewer perceptions

### Question 5: Always Be Kind

**Basic Scores:**
- **Peers Average**: 4.00 (based on 5 ratings)
- **Response Rate**: 5/5 peer reviewers (100%)
- **Self Score**: 4.0
- **Median Score**: 4.00

**Self-Awareness Deltas:**
- **Delta (Self - Peers)**: +0.00 ðŸŸ¡ (Well-calibrated)
- **Delta (Self - Level)**: -0.11 ðŸŸ¢ (Humble)
- **Delta (Self - Team)**: -0.10 ðŸŸ¡ (Well-calibrated)
- **Delta (Self - Department)**: +0.06 ðŸŸ¡ (Well-calibrated)
- **Delta (Self - Project)**: -0.31 ðŸŸ¢ (Humble)

**Performance Comparisons (Peer Avg vs Groups):**
- **vs Team Average**: -0.10 (Team avg: 4.10) - Below team
- **vs Project Average**: -0.31 (Project avg: 4.31) - Below project
- **vs Department Average**: +0.06 (Department avg: 3.94) - Above department
- **vs Company Average**: -0.14 (Company avg: 4.14) - Below company

**Statistical Analysis:**
- **Standard Deviation**: 0.89 (Mixed opinions)
- **Percentile Rank**: 36.0th percentile
- **Score Range**: 3.0 - 5.0 (spread: 2.0)

**Interpretation:**
- Scores in the **36th percentile** on Always Be Kind company-wide (top 64%)
- Peer average (4.00) is **-0.31 below project average**
- **Mixed opinions** among reviewers (SD: 0.89)
- Score range (3.0-5.0) shows notable variability in reviewer perceptions

### Question 6: Keep it Real

**Basic Scores:**
- **Peers Average**: 3.60 (based on 5 ratings)
- **Response Rate**: 5/5 peer reviewers (100%)
- **Self Score**: 3.0
- **Median Score**: 4.00

**Self-Awareness Deltas:**
- **Delta (Self - Peers)**: -0.60 ðŸŸ¢ (Humble)
- **Delta (Self - Level)**: -1.11 ðŸŸ¢ (Humble)
- **Delta (Self - Team)**: -0.81 ðŸŸ¢ (Humble)
- **Delta (Self - Department)**: -0.97 ðŸŸ¢ (Humble)
- **Delta (Self - Project)**: -1.13 ðŸŸ¢ (Humble)

**Performance Comparisons (Peer Avg vs Groups):**
- **vs Team Average**: -0.21 (Team avg: 3.81) - Below team
- **vs Project Average**: -0.53 (Project avg: 4.13) - Below project
- **vs Department Average**: -0.37 (Department avg: 3.97) - Below department
- **vs Company Average**: -0.57 (Company avg: 4.17) - Below company

**Statistical Analysis:**
- **Standard Deviation**: 0.49 (Moderate agreement)
- **Percentile Rank**: 12.2th percentile
- **Score Range**: 3.0 - 4.0 (spread: 1.0)

**Interpretation:**
- Scores in the **12th percentile** on Keep it Real company-wide (top 88%)
- Peer average (3.60) is **-0.57 below company average**
- **Moderate agreement** among reviewers (SD: 0.49)
- Score range (3.0-4.0) shows reasonable consistency in reviewer perceptions

### Question 7: Outcomes in Production

**Basic Scores:**
- **Peers Average**: 4.00 (based on 4 ratings)
- **Response Rate**: 4/5 peer reviewers (80%)
- **Self Score**: 4.0
- **Median Score**: 4.00

**Self-Awareness Deltas:**
- **Delta (Self - Peers)**: +0.00 ðŸŸ¡ (Well-calibrated)
- **Delta (Self - Level)**: +0.11 ðŸ”´ (Overconfident)
- **Delta (Self - Team)**: -0.02 ðŸŸ¡ (Well-calibrated)
- **Delta (Self - Department)**: +0.08 ðŸŸ¡ (Well-calibrated)
- **Delta (Self - Project)**: -0.29 ðŸŸ¢ (Humble)

**Performance Comparisons (Peer Avg vs Groups):**
- **vs Team Average**: -0.02 (Team avg: 4.02) - At team
- **vs Project Average**: -0.29 (Project avg: 4.29) - Below project
- **vs Department Average**: +0.08 (Department avg: 3.92) - Above department
- **vs Company Average**: +0.02 (Company avg: 3.98) - At company

**Statistical Analysis:**
- **Standard Deviation**: 0.71 (Mixed opinions)
- **Percentile Rank**: 49.3th percentile
- **Score Range**: 3.0 - 5.0 (spread: 2.0)

**Interpretation:**
- Scores in the **49th percentile** on Outcomes in Production company-wide (top 51%)
- Peer average (4.00) is **-0.29 below project average**
- **Mixed opinions** among reviewers (SD: 0.71)
- Score range (3.0-5.0) shows notable variability in reviewer perceptions

### Question 8: Grit

**Basic Scores:**
- **Peers Average**: 3.60 (based on 5 ratings)
- **Response Rate**: 5/5 peer reviewers (100%)
- **Self Score**: 4.0
- **Median Score**: 4.00

**Self-Awareness Deltas:**
- **Delta (Self - Peers)**: +0.40 ðŸ”´ (Overconfident)
- **Delta (Self - Level)**: -0.04 ðŸŸ¡ (Well-calibrated)
- **Delta (Self - Team)**: -0.05 ðŸŸ¡ (Well-calibrated)
- **Delta (Self - Department)**: -0.05 ðŸŸ¡ (Well-calibrated)
- **Delta (Self - Project)**: -0.18 ðŸŸ¢ (Humble)

**Performance Comparisons (Peer Avg vs Groups):**
- **vs Team Average**: -0.45 (Team avg: 4.05) - Below team
- **vs Project Average**: -0.58 (Project avg: 4.18) - Below project
- **vs Department Average**: -0.45 (Department avg: 4.05) - Below department
- **vs Company Average**: -0.56 (Company avg: 4.16) - Below company

**Statistical Analysis:**
- **Standard Deviation**: 0.49 (Moderate agreement)
- **Percentile Rank**: 13.3th percentile
- **Score Range**: 3.0 - 4.0 (spread: 1.0)

**Interpretation:**
- Scores in the **13th percentile** on Grit company-wide (top 87%)
- Peer average (3.60) is **-0.58 below project average**
- **Moderate agreement** among reviewers (SD: 0.49)
- Score range (3.0-4.0) shows reasonable consistency in reviewer perceptions

### Question 9: Growth Mindset

**Basic Scores:**
- **Peers Average**: 4.20 (based on 5 ratings)
- **Response Rate**: 5/5 peer reviewers (100%)
- **Self Score**: 4.0
- **Median Score**: 4.00

**Self-Awareness Deltas:**
- **Delta (Self - Peers)**: -0.20 ðŸŸ¢ (Humble)
- **Delta (Self - Level)**: -0.16 ðŸŸ¢ (Humble)
- **Delta (Self - Team)**: -0.03 ðŸŸ¡ (Well-calibrated)
- **Delta (Self - Department)**: -0.07 ðŸŸ¡ (Well-calibrated)
- **Delta (Self - Project)**: -0.29 ðŸŸ¢ (Humble)

**Performance Comparisons (Peer Avg vs Groups):**
- **vs Team Average**: +0.17 (Team avg: 4.03) - Above team
- **vs Project Average**: -0.09 (Project avg: 4.29) - Below project
- **vs Department Average**: +0.13 (Department avg: 4.07) - Above department
- **vs Company Average**: +0.01 (Company avg: 4.19) - At company

**Statistical Analysis:**
- **Standard Deviation**: 0.40 (Moderate agreement)
- **Percentile Rank**: 46.5th percentile
- **Score Range**: 4.0 - 5.0 (spread: 1.0)

**Interpretation:**
- Scores in the **46th percentile** on Growth Mindset company-wide (top 54%)
- Peer average (4.20) is **+0.17 above team average**
- **Moderate agreement** among reviewers (SD: 0.40)
- Score range (4.0-5.0) shows reasonable consistency in reviewer perceptions

### Question 10: No Unnecessary Rules

**Basic Scores:**
- **Peers Average**: 4.00 (based on 5 ratings)
- **Response Rate**: 5/5 peer reviewers (100%)
- **Self Score**: 4.0
- **Median Score**: 4.00

**Self-Awareness Deltas:**
- **Delta (Self - Peers)**: +0.00 ðŸŸ¡ (Well-calibrated)
- **Delta (Self - Level)**: -0.03 ðŸŸ¡ (Well-calibrated)
- **Delta (Self - Team)**: -0.13 ðŸŸ¢ (Humble)
- **Delta (Self - Department)**: +0.02 ðŸŸ¡ (Well-calibrated)
- **Delta (Self - Project)**: -0.23 ðŸŸ¢ (Humble)

**Performance Comparisons (Peer Avg vs Groups):**
- **vs Team Average**: -0.13 (Team avg: 4.13) - Below team
- **vs Project Average**: -0.23 (Project avg: 4.23) - Below project
- **vs Department Average**: +0.02 (Department avg: 3.98) - At department
- **vs Company Average**: -0.11 (Company avg: 4.11) - Below company

**Statistical Analysis:**
- **Standard Deviation**: 0.63 (Mixed opinions)
- **Percentile Rank**: 39.5th percentile
- **Score Range**: 3.0 - 5.0 (spread: 2.0)

**Interpretation:**
- Scores in the **39th percentile** on No Unnecessary Rules company-wide (top 60%)
- Peer average (4.00) is **-0.23 below project average**
- **Mixed opinions** among reviewers (SD: 0.63)
- Score range (3.0-5.0) shows notable variability in reviewer perceptions

### Question 11: eNPS (Employee Net Promoter Score)

**Basic Scores:**
- **Peers Average**: 4.60 (based on 5 ratings)
- **Response Rate**: 5/5 peer reviewers (100%)
- **Self Score**: 5.0
- **Median Score**: 5.00

**Self-Awareness Deltas:**
- **Delta (Self - Peers)**: +0.40 ðŸ”´ (Overconfident)
- **Delta (Self - Level)**: +0.40 ðŸ”´ (Overconfident)
- **Delta (Self - Team)**: +0.33 ðŸ”´ (Overconfident)
- **Delta (Self - Department)**: +0.38 ðŸ”´ (Overconfident)
- **Delta (Self - Project)**: +0.23 ðŸ”´ (Overconfident)

**Performance Comparisons (Peer Avg vs Groups):**
- **vs Team Average**: -0.08 (Team avg: 4.67) - Below team
- **vs Project Average**: -0.17 (Project avg: 4.77) - Below project
- **vs Department Average**: -0.02 (Department avg: 4.62) - At department
- **vs Company Average**: -0.07 (Company avg: 4.67) - Below company

**Statistical Analysis:**
- **Standard Deviation**: 0.49 (Moderate agreement)
- **Percentile Rank**: 32.6th percentile
- **Score Range**: 4.0 - 5.0 (spread: 1.0)

**Interpretation:**
- Scores in the **32th percentile** on eNPS (Employee Net Promoter Score) company-wide (top 67%)
- Peer average (4.60) is **-0.17 below project average**
- **Moderate agreement** among reviewers (SD: 0.49)
- Score range (4.0-5.0) shows reasonable consistency in reviewer perceptions

---

## Question 11: eNPS - Peer Comments Summary

### Synthesized Summary

*[AI synthesis needed - invoke rise8-assessment-reviewer agent with eNPS comments]*

<details>
<summary>View Raw eNPS Comments</summary>

**Ben Adinata:**
I would enthusiastically rehire Drew. He joined us mid-project and picked up our complex architecture incredibly fast. He had to learn Angular at the same time but still asked the right questions to really understand the system. He quickly went from following along to driving our pairing sessions, which allowed him to contribute value almost immediately. He is also very proactive; he often spots bugs, creates tickets for them, and helps us fix them before they ever reach production.

**Chris Wang:**
This Riser has the right fundamentals for a strong developer: He shows consistent initiative, has good instincts, and is willing to take feedback and apply it.

**Shubham Goel:**
Drew has been a wonderful teammate on both MOSS and Narrowband. He  brings a calm, thoughtful presence and a deep technical understanding that grounds our conversations in reality, especially when working with SAR data.




 Drew played a key role in helping deliver the **12 approved MOSS outcomes** this year, contributing to their implementation, refinement, and success. His work directly supported outcomes like health monitoring, audit logging, auto-populated DSR logs, and incident reportingâ€”each of which improved mission readiness and reduced operator burden.




Beyond delivery, Drew naturally steps into leadership. He took initiative in educating product and design on new tech tooling, helping us understand whatâ€™s feasible and how the system behaves. Pairing with Drew is always a pleasant and productive experience. He creates an easy, low-friction environment that helps the entire team work more effectively. He also implemented metric collection on the MOSS contract, which became a major unlock, and bringing that same rigor into Narrowband will be incredibly valuable.




Iâ€™d encourage Drew to continue leaning into his leadership qualities and to voice his perspective even more during strategic conversations. Overall, Drew is a natural leader, a strong engineer, and a great teammate to work with.

**Seehyun Kim:**
I would enthusiastically rehire Drew because he brings not only strong technical ability but also a positive impact on team dynamics. Since he joined, team interactions have become more engaging, with more dialogue and thoughtful responses in meetings, small shifts that have meaningfully improved the teamâ€™s collaboration and energy. Drew is inviting, approachable, and an excellent collaborator; for example, he generously extends his AI practice time and provides technical mentoring to PM/Design. I would love to be on the same team with Drew again.

**Norman Sharpe:**
Although my time working with Drew has been limited due to his recent start on the project, he has already established himself as a dependable and hardworking teammate who consistently executes on tasks.




Drew possesses a unique and valuable skill set in pair programming. While he is often quiet, he does a lot of background research - constantly looking up relevant APIs, researching error messages, and reproducing buggy behaviors. He pulls his weight effectively and has demonstrated an ability to learn new concepts rapidly, becoming productive very early in his time on the team. I look forward to seeing his continued growth at Rise8!


</details>

---

## Question 12: Start/Stop/Keep Recommendations

### Synthesized Summary

**START:**
*[AI synthesis needed - invoke rise8-assessment-reviewer agent with START feedback]*

**STOP:**
*[AI synthesis needed - invoke rise8-assessment-reviewer agent with STOP feedback]*

**KEEP:**
*[AI synthesis needed - invoke rise8-assessment-reviewer agent with KEEP feedback]*

<details>
<summary>View Raw Start/Stop/Keep Feedback</summary>

**Ben Adinata:**
**Start:** I want to see you start speaking up more during Pre-IPM and IPM. You ramped up fast and clearly understand the problems we are solving. The team needs to hear your perspective more often.




**Stop:** Iâ€™ve noticed you sometimes hesitate or just go along with the team even when you seem to disagree. I suggest you stop holding back. Your perspective is valuable, so please have the confidence to speak up when you see things differently.




**Keep:** Please keep being diligent about product quality. The way you find and ticket bugs before they hit production is a huge help. I also really appreciate how much you care about clean code and that you push for refactors whenever you see the chance.

**Chris Wang:**
Start: Being more present in group meetings. I know it can feel efficient to clear out small tasks during meetings, but it would be great to have your full focus during those meetings. Following the thread of the conversation helps you catch the "why" behind decisions, and hearing what your take on things is helps us understand where you're coming from.




Keep: Your willingness to adapt. It makes pairing and iterating with you really easy and productive because you take feedback so well. Thatâ€™s a huge asset to the team.




Keep: Iâ€™ve noticed lately that youâ€™re asking more questions rather than asserting knowledge. This is awesome; it builds trust and helps us move faster.




Stop: Feeling the need to "prove" your contributions. Iâ€™ve noticed you doing this less lately, and you can totally let this go. We all see the value you're adding.

**Shubham Goel:**
**Start:**
â€“ Leaning more into his leadership strengths by vocalizing to high-level prioritization, technical direction, and strategic decision discussions.
â€“ Bringing the same data-driven metric collection approach used on MOSS into the Narrowband contract.




**Keep:**
â€“ Bringing a grounding, technically thorough understanding to implementation conversations.
â€“ Maintaining his calm, positive, and collaborative presence across both teams.
â€“ Pairing frequently and creating a smooth, easy environment for feedback and development.
â€“ Sharing insights on tooling, tech choices, and system mechanics in a way that helps product and design learn quickly.
â€“ Contributing to high-quality, high-impact outcomes just as he did across all 12 MOSS outcomes.
â€“ Continuing to guide the team on tooling and system behaviors, especially for newer product members.

**Seehyun Kim:**
- Keep speaking up because your perspectives bring valuable insights to the team.
- Keep giving honest feedback in a thoughtful and kind way, as it strengthens both the team and the overall project.
- Continue helping the team, especially other developers, maintain a user-centered perspective in development

**Norman Sharpe:**
**Keep Doing:**
- Keep functioning as a high-utility "background processor" during pairing. Your ability to parallel-process (researching APIs, hunting down error messages, reproducing bugs) while your partner drives is a massive asset to the team's velocity.
- Keep following up with the team, learning the domain, and participating in context sharing. Your ability to absorb context and contribute code during pairing and thoughts during team meetings immediately is helpful.
**Stop Doing:**
- Stop initiating background work silently - While you are doing valuable work, your partner can sometimes feel like they are working alone if they don't know what you are looking at.
**Start Doing:**
- Start providing architectural feedback in PRs/pairing sessions. I want to see you asking questions about design patterns, testability, and long-term maintainability - even if it's just a thought exercise.
- Start volunteering to lead certain epics - ask early to pair up with the design/pm team to get early preview of what's coming up next, and how we might tackle it. Or volunteer to take on a technical tasks that might make you uncomfortable.
- Start trying to innovate how we do work as a team - find pain points that are brought up in retro, and do some research online (podcasts, blogs, gemini/chatgpt) for solutions. Bring those ideas to the team, and see if we can measure results.


</details>

---

## Report Metadata

- **Generated**: 2025-12-04 17:48:02
- **Script Version**: 1.0.0
- **Data Sources**:
  - Assessment File: `assessments/Software/Drew_Fugate.md`
  - Team Mapping: `LatticeAPI/lattice_api_client/team_map.json`
  - Comprehensive Data: `docs/analysis-results/riser_data_detailed.csv`
  - Tier Assignments: `docs/analysis-results/tier_assignments.csv`
